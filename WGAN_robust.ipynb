{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "#import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN:\n",
    "    \n",
    "    def __init__(self, dim_x):\n",
    "        self.dim_x = dim_x\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "        self.generator = self.generator_model(dim_x)\n",
    "        self.discriminator = self.discriminator_model(dim_x)\n",
    "    \n",
    "    def generator_model(self, dim):\n",
    "        inputs = layers.Input(shape=(dim,))\n",
    "        out = LocationAdd(dim)(inputs)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    def discriminator_model(self, dim):\n",
    "        inputs = layers.Input(shape=(dim,))\n",
    "        dense1 = layers.Dense(2*dim, activation=tf.nn.sigmoid)(inputs)\n",
    "        out = layers.Dense(1, activation=tf.nn.sigmoid)(dense1)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator_loss(fake_output):\n",
    "        cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    \n",
    "    #@tf.function\n",
    "        \n",
    "       \n",
    "    def train(self, dataset, epochs, batch_size):\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            for i in range(dataset.shape[0]//batch_size):\n",
    "                noise = tf.random.normal([batch_size, self.dim_x])\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    generated = self.generator(noise, training=True)\n",
    "                    real_output = self.discriminator(dataset[i*batch_size:(i+1)*batch_size], training=True)\n",
    "                    fake_output = self.discriminator(generated, training=True)\n",
    "\n",
    "                    gen_loss = WGAN.generator_loss(fake_output)\n",
    "                    disc_loss = WGAN.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "                    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                    self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "    \n",
    "            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))   \n",
    "            print(gen_loss.numpy())\n",
    "            print(disc_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99529953, 1.92939267, 3.01097462, 3.94599283])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.normal(size=(100,4)) + np.array([1,2,3,4])\n",
    "np.mean(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(dim_x=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 3.3591878414154053 sec\n",
      "0.5054419\n",
      "1.3544945\n",
      "Time for epoch 2 is 3.2857930660247803 sec\n",
      "0.516328\n",
      "1.3370297\n",
      "Time for epoch 3 is 3.1390159130096436 sec\n",
      "0.5053599\n",
      "1.3523097\n",
      "Time for epoch 4 is 3.0858688354492188 sec\n",
      "0.5021736\n",
      "1.3567147\n",
      "Time for epoch 5 is 3.0744709968566895 sec\n",
      "0.51222926\n",
      "1.3425151\n",
      "Time for epoch 6 is 3.082953929901123 sec\n",
      "0.5023988\n",
      "1.3556579\n",
      "Time for epoch 7 is 3.0775959491729736 sec\n",
      "0.5154084\n",
      "1.3354335\n",
      "Time for epoch 8 is 3.1023900508880615 sec\n",
      "0.51107216\n",
      "1.3417393\n",
      "Time for epoch 9 is 3.053039073944092 sec\n",
      "0.5245622\n",
      "1.3215666\n",
      "Time for epoch 10 is 2.948643922805786 sec\n",
      "0.5189909\n",
      "1.3280925\n",
      "Time for epoch 11 is 2.962409019470215 sec\n",
      "0.51082146\n",
      "1.3395875\n",
      "Time for epoch 12 is 2.93243408203125 sec\n",
      "0.52686954\n",
      "1.3153996\n",
      "Time for epoch 13 is 3.005797863006592 sec\n",
      "0.5183601\n",
      "1.32805\n",
      "Time for epoch 14 is 2.9892020225524902 sec\n",
      "0.52795935\n",
      "1.3125584\n",
      "Time for epoch 15 is 2.933979034423828 sec\n",
      "0.51648676\n",
      "1.3271403\n",
      "Time for epoch 16 is 2.989013910293579 sec\n",
      "0.5530788\n",
      "1.2742748\n",
      "Time for epoch 17 is 2.9419357776641846 sec\n",
      "0.5528352\n",
      "1.2751997\n",
      "Time for epoch 18 is 2.928666114807129 sec\n",
      "0.52819794\n",
      "1.3097712\n",
      "Time for epoch 19 is 3.0161662101745605 sec\n",
      "0.5524341\n",
      "1.2747991\n",
      "Time for epoch 20 is 2.9287290573120117 sec\n",
      "0.5621935\n",
      "1.2615151\n",
      "Time for epoch 21 is 2.9430978298187256 sec\n",
      "0.54513896\n",
      "1.2820704\n",
      "Time for epoch 22 is 3.018981695175171 sec\n",
      "0.55216515\n",
      "1.2737379\n",
      "Time for epoch 23 is 3.6381309032440186 sec\n",
      "0.5436903\n",
      "1.2881377\n",
      "Time for epoch 24 is 2.9685847759246826 sec\n",
      "0.55546516\n",
      "1.2705287\n",
      "Time for epoch 25 is 3.0039680004119873 sec\n",
      "0.55777204\n",
      "1.2679143\n",
      "Time for epoch 26 is 3.105498790740967 sec\n",
      "0.55118513\n",
      "1.2756712\n",
      "Time for epoch 27 is 2.981886148452759 sec\n",
      "0.5581248\n",
      "1.2651095\n",
      "Time for epoch 28 is 2.9893951416015625 sec\n",
      "0.5731344\n",
      "1.2443938\n",
      "Time for epoch 29 is 2.9737319946289062 sec\n",
      "0.5510746\n",
      "1.271925\n",
      "Time for epoch 30 is 3.0485188961029053 sec\n",
      "0.5612154\n",
      "1.2588263\n",
      "Time for epoch 31 is 2.970945119857788 sec\n",
      "0.54409015\n",
      "1.2781715\n",
      "Time for epoch 32 is 2.94449782371521 sec\n",
      "0.5737864\n",
      "1.2399335\n",
      "Time for epoch 33 is 2.9983558654785156 sec\n",
      "0.53977174\n",
      "1.2846246\n",
      "Time for epoch 34 is 2.967041015625 sec\n",
      "0.567976\n",
      "1.247514\n",
      "Time for epoch 35 is 2.9506590366363525 sec\n",
      "0.5692193\n",
      "1.2458265\n",
      "Time for epoch 36 is 2.9602649211883545 sec\n",
      "0.5820387\n",
      "1.2304924\n",
      "Time for epoch 37 is 3.0472640991210938 sec\n",
      "0.5748655\n",
      "1.2354677\n",
      "Time for epoch 38 is 2.9729089736938477 sec\n",
      "0.57915306\n",
      "1.2293793\n",
      "Time for epoch 39 is 2.987740993499756 sec\n",
      "0.57552826\n",
      "1.2342145\n",
      "Time for epoch 40 is 2.9779977798461914 sec\n",
      "0.5767277\n",
      "1.2301159\n",
      "Time for epoch 41 is 2.97900128364563 sec\n",
      "0.58897656\n",
      "1.2175677\n",
      "Time for epoch 42 is 2.9659781455993652 sec\n",
      "0.55802166\n",
      "1.2558408\n",
      "Time for epoch 43 is 3.041163206100464 sec\n",
      "0.58864045\n",
      "1.2167239\n",
      "Time for epoch 44 is 3.013213872909546 sec\n",
      "0.5957238\n",
      "1.2045392\n",
      "Time for epoch 45 is 2.94450306892395 sec\n",
      "0.5722328\n",
      "1.2344161\n",
      "Time for epoch 46 is 3.010701894760132 sec\n",
      "0.60644054\n",
      "1.1904984\n",
      "Time for epoch 47 is 2.9935128688812256 sec\n",
      "0.5905945\n",
      "1.2091116\n",
      "Time for epoch 48 is 2.944448947906494 sec\n",
      "0.6049895\n",
      "1.1926727\n",
      "Time for epoch 49 is 2.9845731258392334 sec\n",
      "0.61061114\n",
      "1.1846296\n",
      "Time for epoch 50 is 3.0256659984588623 sec\n",
      "0.6048447\n",
      "1.1923604\n",
      "Time for epoch 51 is 2.972273826599121 sec\n",
      "0.588473\n",
      "1.2098672\n",
      "Time for epoch 52 is 2.979574203491211 sec\n",
      "0.56677943\n",
      "1.2438707\n",
      "Time for epoch 53 is 3.057210922241211 sec\n",
      "0.57157195\n",
      "1.2354416\n",
      "Time for epoch 54 is 2.981778860092163 sec\n",
      "0.5511116\n",
      "1.2593949\n",
      "Time for epoch 55 is 3.003243923187256 sec\n",
      "0.57256114\n",
      "1.231621\n",
      "Time for epoch 56 is 2.9834139347076416 sec\n",
      "0.60444987\n",
      "1.1947896\n",
      "Time for epoch 57 is 2.9286210536956787 sec\n",
      "0.590119\n",
      "1.2110285\n",
      "Time for epoch 58 is 2.968235969543457 sec\n",
      "0.60205984\n",
      "1.1973362\n",
      "Time for epoch 59 is 2.956225872039795 sec\n",
      "0.59160256\n",
      "1.2050052\n",
      "Time for epoch 60 is 2.959851026535034 sec\n",
      "0.6023237\n",
      "1.1907617\n",
      "Time for epoch 61 is 2.943206787109375 sec\n",
      "0.5611616\n",
      "1.2467468\n",
      "Time for epoch 62 is 3.031141996383667 sec\n",
      "0.605396\n",
      "1.1856058\n",
      "Time for epoch 63 is 3.455933094024658 sec\n",
      "0.5851717\n",
      "1.2103055\n",
      "Time for epoch 64 is 2.9956328868865967 sec\n",
      "0.60926867\n",
      "1.1829886\n",
      "Time for epoch 65 is 2.9601290225982666 sec\n",
      "0.60273635\n",
      "1.1862094\n",
      "Time for epoch 66 is 3.0565409660339355 sec\n",
      "0.59179515\n",
      "1.2039194\n",
      "Time for epoch 67 is 2.9646642208099365 sec\n",
      "0.6092455\n",
      "1.1771357\n",
      "Time for epoch 68 is 2.9803037643432617 sec\n",
      "0.57952774\n",
      "1.2190267\n",
      "Time for epoch 69 is 2.947751998901367 sec\n",
      "0.5995741\n",
      "1.1938705\n",
      "Time for epoch 70 is 2.961354970932007 sec\n",
      "0.6128723\n",
      "1.1738311\n",
      "Time for epoch 71 is 3.0186829566955566 sec\n",
      "0.5685852\n",
      "1.2351996\n",
      "Time for epoch 72 is 2.9387247562408447 sec\n",
      "0.59502476\n",
      "1.1971604\n",
      "Time for epoch 73 is 3.0966031551361084 sec\n",
      "0.6012502\n",
      "1.1941586\n",
      "Time for epoch 74 is 2.964545726776123 sec\n",
      "0.6214305\n",
      "1.1644137\n",
      "Time for epoch 75 is 2.9414169788360596 sec\n",
      "0.5690032\n",
      "1.2321252\n",
      "Time for epoch 76 is 2.9984841346740723 sec\n",
      "0.6154621\n",
      "1.1737534\n",
      "Time for epoch 77 is 2.9719700813293457 sec\n",
      "0.5864517\n",
      "1.2081435\n",
      "Time for epoch 78 is 2.9841911792755127 sec\n",
      "0.58045596\n",
      "1.2162856\n",
      "Time for epoch 79 is 2.960676908493042 sec\n",
      "0.60485315\n",
      "1.1862304\n",
      "Time for epoch 80 is 3.6623921394348145 sec\n",
      "0.5974589\n",
      "1.195122\n",
      "Time for epoch 81 is 4.092026948928833 sec\n",
      "0.5959482\n",
      "1.1995254\n",
      "Time for epoch 82 is 3.5168731212615967 sec\n",
      "0.5953147\n",
      "1.1989607\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-fcee1fa5b8a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-171-1e237c59d3b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, epochs, batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mgradients_of_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_Log1pGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    651\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxdivy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreciprocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m   \u001b[0;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/software/anaconda3/envs/tf2.1/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    531\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m    532\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AddV2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wgan.train(data, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36738652, 0.85674286, 1.2384297 , 1.3773217 ], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgan.generator.trainable_variables[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_30/kernel:0' shape=(4, 8) dtype=float32, numpy=\n",
       " array([[-0.6359079 ,  0.27903283,  0.3251408 , -0.33258304, -0.46013683,\n",
       "         -0.03362629, -0.11999964, -0.68613636],\n",
       "        [ 0.31575486, -0.15137747,  0.07577345,  0.6530666 , -0.02372789,\n",
       "         -0.3033418 ,  0.14564754,  0.18740919],\n",
       "        [ 0.03144262,  0.32063976,  0.49154648,  0.01006212,  0.2869891 ,\n",
       "          0.13385305,  0.15458485, -0.18987782],\n",
       "        [ 0.41043004, -0.29030252, -0.41184142, -0.46537015,  0.39706612,\n",
       "          0.5605985 , -0.03498659, -0.29714814]], dtype=float32)>,\n",
       " <tf.Variable 'dense_30/bias:0' shape=(8,) dtype=float32, numpy=\n",
       " array([-0.04864352,  0.05003172,  0.04958793, -0.04678346, -0.04907757,\n",
       "        -0.04912923, -0.04610546,  0.05006593], dtype=float32)>,\n",
       " <tf.Variable 'dense_31/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
       " array([[ 0.48923495],\n",
       "        [-0.67075557],\n",
       "        [-0.59104705],\n",
       "        [ 0.40814173],\n",
       "        [ 0.6741846 ],\n",
       "        [ 0.72662413],\n",
       "        [ 0.12240683],\n",
       "        [-0.86328787]], dtype=float32)>,\n",
       " <tf.Variable 'dense_31/bias:0' shape=(1,) dtype=float32, numpy=array([-0.04920084], dtype=float32)>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgan.discriminator.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LocationAdd, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim,), dtype='float32'), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.add(inputs, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([-0.00664021,  0.0288209 , -0.02498679, -0.0802893 ], dtype=float32)>]\n",
      "[<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([-0.00662157, -0.03866563,  0.00385501, -0.03999352], dtype=float32)>]\n",
      "Train on 100 samples\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 24.2214\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 23.2429\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 22.2905\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 21.3581\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 20.4456\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 19.5531\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 18.6806\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 17.8280\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 16.9953\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 16.1827\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 15.3899\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 14.6172\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 13.8644\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 13.1315\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 12.4186\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 11.7256\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 11.0526\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 10.3995\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 9.7664\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 9.1532\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 8.5599\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 7.9867\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 7.4333\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 6.8998\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 6.3863\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 5.8928\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 5.4191\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 4.9654\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 4.5316\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 4.1177\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 3.7237\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 3.3496\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.9955\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.6612\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.3468\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.0523\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 1.7777\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 1.5229\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 1.2880\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 1.0729\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.8777\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.7022\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.5466\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.4107\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.2945\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.1979\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.1210\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.0635\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.0253\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 0.0055\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4787e-04\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.1963e-07\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4989e-07\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4982e-07\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4977e-07\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4976e-07\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4983e-07\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4982e-07\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4977e-07\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4983e-07\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4976e-07\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4982e-07\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4982e-07\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4978e-07\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4977e-07\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4983e-07\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07 0s - loss: 2.4983e\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4983e-07\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4978e-07\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4978e-07\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4982e-07\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4980e-07\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4979e-07\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/sample - loss: 2.4981e-07\n",
      "[<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([-5.0004997, -5.0004983, -4.999503 , -4.999497 ], dtype=float32)>]\n",
      "[<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([-0.00662157, -0.03866563,  0.00385501, -0.03999352], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# correct test version of model with self defined layers\n",
    "def build_model():\n",
    "    a = tf.keras.Input(shape=(4,))\n",
    "    out = LocationAdd(input_dim=4)(a+5)\n",
    "    model = tf.keras.Model(inputs=a, outputs=out)\n",
    "    return model\n",
    "model = build_model()\n",
    "model2 = build_model()\n",
    "print(model.trainable_variables)\n",
    "print(model2.trainable_variables)\n",
    "model.compile(optimizer='rmsprop', loss=tf.keras.losses.MeanSquaredError())\n",
    "model.fit(x=data,y=data, batch_size=1, epochs=100)\n",
    "print(model.trainable_variables)\n",
    "print(model2.trainable_variables)\n",
    "\n",
    "## tf.keras.layers.add can make variables not trainable, below is not correct\n",
    "# a = tf.keras.Input(shape=(4,))\n",
    "# b = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(4,)), trainable=True)\n",
    "# out = tf.keras.layers.add([a+5,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
