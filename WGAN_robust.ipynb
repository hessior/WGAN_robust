{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom-defined layers\n",
    "\n",
    "class LocationAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LocationAdd, self).__init__()\n",
    "        w_init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim,)), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.add(inputs, self.w)\n",
    "    \n",
    "class RegressionAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionAdd, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        w_init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim-1,)), trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_X, input_z = tf.split(inputs, [self.input_dim-1, 1], axis=1)\n",
    "        return tf.concat([input_X, tf.add(tf.reshape(tf.linalg.matvec(input_X, self.w),[-1,1]),input_z)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom-defined constraints\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "class Constraint(object):\n",
    "    def __call__(self, w):\n",
    "        return w\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "class Max1Norm(Constraint):\n",
    "    \"\"\"1-Norm weight constraint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_value=2, axis=0):\n",
    "        self.max_value = max_value\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, w):\n",
    "        norms = math_ops.reduce_sum(math_ops.abs(w), axis=self.axis, keepdims=True)\n",
    "        desired = K.clip(norms, 0, self.max_value)\n",
    "        return w * (desired / (K.epsilon() + norms))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'max_value': self.max_value, 'axis': self.axis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WganError(tf.keras.losses.Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        #y_pred = ops.convert_to_tensor(y_pred)\n",
    "        #y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "        return K.mean(y_pred - y_true, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN:\n",
    "    \n",
    "    ''' A static model, with fixed input size.\n",
    "        Model should not be defined in train(), so it should not depend on dataset dimension.\n",
    "        Model API has an advantage that it can save weights between different calls of train.\n",
    "        Instead of using tf.Session() as before, where only one training can happen, next will refresh,\n",
    "        using Model() API avoids this, it provides a model which saves weights outside tf.Session()!\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dim_x, target):\n",
    "        self.dim_x = dim_x\n",
    "        self.target = target\n",
    "        self.generator = self.generator_model(dim_x, target)\n",
    "        self.discriminator = self.discriminator_model(dim_x)\n",
    "\n",
    "    \n",
    "    def generator_model(self, dim, target):\n",
    "        if target == \"location\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = LocationAdd(dim)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "        elif target == \"cov-matrix\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = layers.Dense(units=dim, use_bias=False)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "        elif target == \"regression\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = RegressionAdd(dim)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "    \n",
    "    def discriminator_model(self, dim):        \n",
    "        inputs = tf.keras.Input(shape=(dim,))\n",
    "        dense1 = layers.Dense(units=2*dim, activation=tf.keras.activations.sigmoid, \n",
    "                              kernel_constraint=tf.keras.constraints.MaxNorm(max_value=1, axis=0))(inputs)\n",
    "        dense2 = layers.Dense(units=4*dim, activation=tf.keras.activations.relu, \n",
    "                              kernel_constraint=tf.keras.constraints.MaxNorm(max_value=1, axis=0))(dense1)\n",
    "        out = layers.Dense(units=1, activation=None, \n",
    "                           kernel_constraint=Max1Norm(max_value=1,axis=0))(dense2)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        #real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        #fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        #total_loss = real_loss + fake_loss\n",
    "        total_loss = WganError()(real_output, fake_output)\n",
    "        return total_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator_loss(fake_output):\n",
    "        # cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        # loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        loss = WganError()(fake_output, tf.zeros_like(fake_output))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def train(self, dataset, epochs, batch_size, step_size):\n",
    "        self.generator_optimizer = tf.keras.optimizers.RMSprop(step_size)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.RMSprop(step_size)\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            for i in range(dataset.shape[0]//batch_size):\n",
    "                noise = tf.random.normal([batch_size, self.dim_x])\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    generated = self.generator(noise, training=True)\n",
    "                    real_output = self.discriminator(dataset[i*batch_size:(i+1)*batch_size], training=True)\n",
    "                    fake_output = self.discriminator(generated, training=True)\n",
    "\n",
    "                    gen_loss = WGAN.generator_loss(fake_output)\n",
    "                    disc_loss = WGAN.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "                    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                    self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "    \n",
    "            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "            A = self.generator.trainable_variables[0].numpy()\n",
    "            if self.target == \"estimation\" or \"regression\":\n",
    "                print(A)\n",
    "            elif self.target == \"cov-matrix\":\n",
    "                print(np.matmul(A, A.T))\n",
    "            print(\"generator loss:\", gen_loss.numpy(), \"discriminator loss: \", disc_loss.numpy())\n",
    "            # print(np.linalg.norm(self.discriminator.trainable_variables[0].numpy(), ord=1, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance matrix estimation\n",
    "\n",
    "https://stackoverflow.com/questions/56201185/how-to-find-a-variable-by-name-in-tensorflow2-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample covariance: \n",
      " [[ 1.06207285  0.03006412  0.00372015 -0.04736984]\n",
      " [ 0.03006412  1.01144075 -0.06582223  0.00390109]\n",
      " [ 0.00372015 -0.06582223  1.00023798 -0.01642981]\n",
      " [-0.04736984  0.00390109 -0.01642981  0.96230879]]\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "p = 4\n",
    "\n",
    "data = np.random.normal(size=(N,p)).astype(np.float32) ## change to float32 for tensorflow\n",
    "print(\"sample covariance: \\n\", np.cov(data.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 8.711712121963501 sec\n",
      "[[ 0.9999624  -0.01137087  0.29432845  0.07042147]\n",
      " [-0.01137087  0.4587177   0.24475011  0.3217195 ]\n",
      " [ 0.29432845  0.24475011  1.0532123  -0.68895334]\n",
      " [ 0.07042147  0.3217195  -0.68895334  1.2594512 ]]\n",
      "generator loss: 0.006464634 discriminator loss:  -0.015455792\n",
      "Time for epoch 2 is 8.898500204086304 sec\n",
      "[[ 1.1726494  -0.06395453  0.2813566  -0.0968382 ]\n",
      " [-0.06395453  0.8004384   0.53677464  0.5472659 ]\n",
      " [ 0.2813566   0.53677464  1.0877877  -0.04575237]\n",
      " [-0.0968382   0.5472659  -0.04575237  1.1446836 ]]\n",
      "generator loss: -0.06882776 discriminator loss:  -0.077590466\n",
      "Time for epoch 3 is 9.164647102355957 sec\n",
      "[[ 1.23648     0.29594547  0.08317912 -0.28725505]\n",
      " [ 0.29594547  1.2908907  -0.09132874 -0.06942075]\n",
      " [ 0.08317912 -0.09132874  1.3612378   0.3130958 ]\n",
      " [-0.28725505 -0.06942075  0.3130958   1.5620112 ]]\n",
      "generator loss: 0.011176802 discriminator loss:  -0.016457537\n",
      "Time for epoch 4 is 10.340165138244629 sec\n",
      "[[ 1.1685554   0.21455106  0.1958428   0.03975868]\n",
      " [ 0.21455106  1.0198553  -0.02665538  0.23114237]\n",
      " [ 0.1958428  -0.02665538  0.80914515 -0.21160087]\n",
      " [ 0.03975868  0.23114237 -0.21160087  0.90279585]]\n",
      "generator loss: 0.11129363 discriminator loss:  -0.0022987835\n",
      "Time for epoch 5 is 9.047795057296753 sec\n",
      "[[ 1.2003007   0.21888278  0.01343249  0.04698551]\n",
      " [ 0.21888278  1.077269   -0.27898756  0.16479963]\n",
      " [ 0.01343249 -0.27898756  1.1021527  -0.13078989]\n",
      " [ 0.04698551  0.16479963 -0.13078989  1.0272775 ]]\n",
      "generator loss: 0.20171589 discriminator loss:  0.015499555\n",
      "Time for epoch 6 is 9.344044208526611 sec\n",
      "[[ 1.0262153   0.02127214  0.16894183  0.14428876]\n",
      " [ 0.02127214  0.9341062  -0.31165558  0.15003093]\n",
      " [ 0.16894183 -0.31165558  1.1635007  -0.2554771 ]\n",
      " [ 0.14428876  0.15003093 -0.2554771   0.97098386]]\n",
      "generator loss: 0.18861046 discriminator loss:  -0.010423346\n",
      "Time for epoch 7 is 8.947640895843506 sec\n",
      "[[ 9.6773821e-01  6.8286397e-02  1.6219319e-01  4.7912166e-02]\n",
      " [ 6.8286397e-02  9.8052132e-01 -2.9762477e-01 -9.1083325e-04]\n",
      " [ 1.6219319e-01 -2.9762477e-01  1.1749209e+00 -7.5363830e-02]\n",
      " [ 4.7912166e-02 -9.1083325e-04 -7.5363830e-02  1.2425677e+00]]\n",
      "generator loss: 0.10137416 discriminator loss:  -0.02143432\n",
      "Time for epoch 8 is 9.228492021560669 sec\n",
      "[[ 0.9297994   0.06009535  0.21735734 -0.00254293]\n",
      " [ 0.06009535  0.9334419  -0.24679296 -0.00128545]\n",
      " [ 0.21735734 -0.24679296  1.060394   -0.07008092]\n",
      " [-0.00254293 -0.00128545 -0.07008092  1.2685741 ]]\n",
      "generator loss: 0.19899711 discriminator loss:  -0.022334628\n",
      "Time for epoch 9 is 8.952221155166626 sec\n",
      "[[ 0.95226943  0.04592977  0.22749056  0.01293643]\n",
      " [ 0.04592977  0.81843823 -0.06281433  0.14146814]\n",
      " [ 0.22749056 -0.06281433  0.88188887 -0.17157869]\n",
      " [ 0.01293643  0.14146814 -0.17157869  1.1480584 ]]\n",
      "generator loss: 0.17830941 discriminator loss:  -0.002988657\n",
      "Time for epoch 10 is 8.674150943756104 sec\n",
      "[[ 1.0695192   0.1884877   0.06621901 -0.19905594]\n",
      " [ 0.1884877   0.90807176 -0.26475635  0.03207929]\n",
      " [ 0.06621901 -0.26475635  1.0236096   0.05752861]\n",
      " [-0.19905594  0.03207929  0.05752861  1.3412088 ]]\n",
      "generator loss: 0.09615801 discriminator loss:  0.10636322\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "step_size = 0.01\n",
    "\n",
    "wgan = WGAN(dim_x=p, target=\"cov-matrix\")\n",
    "wgan.train(data, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wgan.generator.trainable_variables[0].numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(data, epochs=10, batch_size=32, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean: \n",
      " [0.99701434 2.0107696  2.9953964  4.015985  ]\n",
      "noisy sample mean: \n",
      " [1.1916729 2.0027666 2.8022332 3.6162524]\n"
     ]
    }
   ],
   "source": [
    "N = 5000\n",
    "p = 4\n",
    "theta = np.array([1,2,3,4])\n",
    "\n",
    "data = np.random.normal(size=(N, p)) + theta\n",
    "data = data.astype(np.float32)\n",
    "print(\"sample mean: \\n\", np.mean(data, axis=0))\n",
    "\n",
    "z = np.random.binomial(n=1,p=0.2,size=(N,1))\n",
    "# noise = np.random.standard_cauchy(size=(N,p))\n",
    "noise = np.random.normal(2,size=(N,p))\n",
    "# noise = np.random.normal(0.5, size=(N,p))\n",
    "# A = np.random.uniform(size=(p,p))\n",
    "# noise = np.random.normal(size=(N,p)) @ A\n",
    "# noise = np.random.gumbel(size=(N,p))\n",
    "data_perturbed = data * (1-z) + noise * z\n",
    "data_perturbed = data_perturbed.astype(np.float32)\n",
    "print(\"noisy sample mean: \\n\", np.mean(data_perturbed, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 29.003483295440674 sec\n",
      "[0.4535497 0.6870302 0.6390408 1.1055124]\n",
      "generator loss: 0.037562158 discriminator loss:  -1.0952256\n",
      "Time for epoch 2 is 33.32768797874451 sec\n",
      "[0.85386467 1.2539865  1.4552437  1.89116   ]\n",
      "generator loss: -0.3286356 discriminator loss:  -0.7370982\n",
      "Time for epoch 3 is 22.98968482017517 sec\n",
      "[1.0228375 1.6214466 2.2097487 2.702838 ]\n",
      "generator loss: -0.23509274 discriminator loss:  -0.58243877\n",
      "Time for epoch 4 is 22.16685390472412 sec\n",
      "[0.92840004 1.7144139  2.835507   3.5027754 ]\n",
      "generator loss: 0.22496402 discriminator loss:  -0.108134165\n",
      "Time for epoch 5 is 21.950858116149902 sec\n",
      "[1.0724608 1.9234142 2.8319707 3.6522148]\n",
      "generator loss: -0.5801804 discriminator loss:  -0.0024489122\n",
      "Time for epoch 6 is 22.227005004882812 sec\n",
      "[1.1213565 1.890195  2.6502862 3.6915383]\n",
      "generator loss: -0.30359524 discriminator loss:  -0.054681316\n",
      "Time for epoch 7 is 22.055262327194214 sec\n",
      "[1.16311   1.9313855 2.694643  3.7282803]\n",
      "generator loss: -0.2701497 discriminator loss:  -0.119184494\n",
      "Time for epoch 8 is 22.16174602508545 sec\n",
      "[1.0805702 1.9766744 2.7549474 3.6845248]\n",
      "generator loss: -0.24280468 discriminator loss:  -0.07571228\n",
      "Time for epoch 9 is 22.852644205093384 sec\n",
      "[1.0736452 2.0019262 2.7937865 3.6248176]\n",
      "generator loss: -0.3205331 discriminator loss:  -0.050478533\n",
      "Time for epoch 10 is 21.781335830688477 sec\n",
      "[1.1269464 1.9028114 2.838205  3.63739  ]\n",
      "generator loss: -0.19083254 discriminator loss:  -0.10090855\n",
      "Time for epoch 11 is 22.898925065994263 sec\n",
      "[1.1522995 1.9833984 2.8137374 3.6574204]\n",
      "generator loss: -0.28513494 discriminator loss:  -0.08275883\n",
      "Time for epoch 12 is 22.19612407684326 sec\n",
      "[1.1645558 2.089487  2.782204  3.6937065]\n",
      "generator loss: -0.3199481 discriminator loss:  -0.091156155\n",
      "Time for epoch 13 is 22.044917106628418 sec\n",
      "[1.1590468 2.029726  2.8376684 3.726731 ]\n",
      "generator loss: -0.26730454 discriminator loss:  -0.077154875\n",
      "Time for epoch 14 is 21.933777332305908 sec\n",
      "[1.2242441 2.039935  2.7854385 3.6564994]\n",
      "generator loss: -0.20114897 discriminator loss:  -0.121499576\n",
      "Time for epoch 15 is 22.022045850753784 sec\n",
      "[1.2083079 2.0141683 2.8151636 3.6177695]\n",
      "generator loss: -0.3140004 discriminator loss:  -0.09572235\n",
      "Time for epoch 16 is 22.730897188186646 sec\n",
      "[1.1804891 1.9354665 2.8795602 3.6519308]\n",
      "generator loss: -0.24039516 discriminator loss:  -0.09330247\n",
      "Time for epoch 17 is 22.898133754730225 sec\n",
      "[1.1504838 2.0905735 2.8606195 3.6589637]\n",
      "generator loss: -0.23041707 discriminator loss:  -0.09248617\n",
      "Time for epoch 18 is 25.425073862075806 sec\n",
      "[1.0651343 1.9346708 2.8852503 3.7753563]\n",
      "generator loss: -0.3265785 discriminator loss:  -0.038485453\n",
      "Time for epoch 19 is 22.940029859542847 sec\n",
      "[1.180663  2.0796509 2.7772017 3.714669 ]\n",
      "generator loss: -0.27638757 discriminator loss:  -0.057958562\n",
      "Time for epoch 20 is 23.59213638305664 sec\n",
      "[1.1861378 1.9800317 2.8209991 3.7156487]\n",
      "generator loss: -0.2329769 discriminator loss:  -0.099248916\n",
      "Time for epoch 21 is 23.2106831073761 sec\n",
      "[1.1156156 2.0632565 2.9040437 3.7254026]\n",
      "generator loss: -0.29451445 discriminator loss:  -0.06963192\n",
      "Time for epoch 22 is 22.31162190437317 sec\n",
      "[1.1273363 2.0978172 2.9030032 3.7196596]\n",
      "generator loss: -0.37080973 discriminator loss:  -0.051948436\n",
      "Time for epoch 23 is 24.745753049850464 sec\n",
      "[1.1254895 2.062785  2.860187  3.719985 ]\n",
      "generator loss: -0.21301305 discriminator loss:  -0.09331378\n",
      "Time for epoch 24 is 30.86688208580017 sec\n",
      "[1.1922972 1.9995334 2.7632577 3.6499772]\n",
      "generator loss: -0.29491866 discriminator loss:  -0.08642715\n",
      "Time for epoch 25 is 31.627280712127686 sec\n",
      "[1.0978072 1.9941126 2.851717  3.7332106]\n",
      "generator loss: -0.26553398 discriminator loss:  -0.09601175\n",
      "Time for epoch 26 is 36.18375587463379 sec\n",
      "[1.1981639 2.0407097 2.7617528 3.6212072]\n",
      "generator loss: -0.20164084 discriminator loss:  -0.09262173\n",
      "Time for epoch 27 is 32.586780309677124 sec\n",
      "[1.1527596 1.9406016 2.833189  3.6764226]\n",
      "generator loss: -0.22173987 discriminator loss:  -0.05934161\n",
      "Time for epoch 28 is 27.813194036483765 sec\n",
      "[1.0876459 2.1958597 2.8973622 3.7352731]\n",
      "generator loss: -0.27790073 discriminator loss:  -0.09603907\n",
      "Time for epoch 29 is 25.2964928150177 sec\n",
      "[1.1959152 1.896471  2.78661   3.6476521]\n",
      "generator loss: -0.23835857 discriminator loss:  -0.093129195\n",
      "Time for epoch 30 is 25.832441091537476 sec\n",
      "[1.1766577 2.207339  2.7665086 3.6699407]\n",
      "generator loss: -0.23903582 discriminator loss:  -0.09918454\n",
      "Time for epoch 31 is 25.235973119735718 sec\n",
      "[1.0968611 1.9112308 2.837056  3.722288 ]\n",
      "generator loss: -0.27500355 discriminator loss:  -0.07345725\n",
      "Time for epoch 32 is 28.562186002731323 sec\n",
      "[1.1349086 2.0675075 2.7997692 3.6863067]\n",
      "generator loss: -0.29981643 discriminator loss:  -0.04337518\n",
      "Time for epoch 33 is 31.452161073684692 sec\n",
      "[1.2148734 2.0197592 2.7523093 3.6477015]\n",
      "generator loss: -0.2417131 discriminator loss:  -0.07099545\n",
      "Time for epoch 34 is 26.055904150009155 sec\n",
      "[1.1360816 1.9242703 2.8545814 3.7290206]\n",
      "generator loss: -0.20534194 discriminator loss:  -0.11996024\n",
      "Time for epoch 35 is 26.07008409500122 sec\n",
      "[1.1957141 2.2020743 2.8352165 3.6859283]\n",
      "generator loss: -0.26446804 discriminator loss:  -0.10428416\n",
      "Time for epoch 36 is 27.460626125335693 sec\n",
      "[1.174024  1.9361771 2.8663876 3.6879253]\n",
      "generator loss: -0.29862368 discriminator loss:  -0.090120375\n",
      "Time for epoch 37 is 23.8747980594635 sec\n",
      "[1.1845437 2.0484679 2.8114989 3.6145837]\n",
      "generator loss: -0.27059495 discriminator loss:  -0.11411728\n",
      "Time for epoch 38 is 25.92228603363037 sec\n",
      "[1.107012  2.0396721 2.8757336 3.674235 ]\n",
      "generator loss: -0.24488044 discriminator loss:  -0.04935992\n",
      "Time for epoch 39 is 27.955449104309082 sec\n",
      "[1.104833  2.1287196 2.8022907 3.6922596]\n",
      "generator loss: -0.2718374 discriminator loss:  -0.088143736\n",
      "Time for epoch 40 is 27.622199058532715 sec\n",
      "[1.1879898 1.9254705 2.7597282 3.658515 ]\n",
      "generator loss: -0.24056755 discriminator loss:  -0.08214788\n",
      "Time for epoch 41 is 27.675812005996704 sec\n",
      "[1.151576  1.970808  2.8130503 3.687175 ]\n",
      "generator loss: -0.2827788 discriminator loss:  -0.08126335\n",
      "Time for epoch 42 is 29.018858909606934 sec\n",
      "[1.1932759 2.034537  2.808988  3.6369631]\n",
      "generator loss: -0.2886742 discriminator loss:  -0.06276218\n",
      "Time for epoch 43 is 26.5034441947937 sec\n",
      "[1.1709574 1.991619  2.845447  3.6459806]\n",
      "generator loss: -0.26947743 discriminator loss:  -0.09133943\n",
      "Time for epoch 44 is 25.000516891479492 sec\n",
      "[1.1481198 2.0176275 2.8615959 3.670204 ]\n",
      "generator loss: -0.2586416 discriminator loss:  -0.08788452\n",
      "Time for epoch 45 is 24.72253680229187 sec\n",
      "[1.1115596 1.8731943 2.860381  3.7166057]\n",
      "generator loss: -0.23245518 discriminator loss:  -0.060297646\n",
      "Time for epoch 46 is 24.23497176170349 sec\n",
      "[1.1158754 2.0080867 2.8566532 3.7312765]\n",
      "generator loss: -0.22834194 discriminator loss:  -0.08890814\n",
      "Time for epoch 47 is 24.717251777648926 sec\n",
      "[1.1757641 2.0801444 2.8198972 3.6799572]\n",
      "generator loss: -0.24186575 discriminator loss:  -0.036557883\n",
      "Time for epoch 48 is 25.57316303253174 sec\n",
      "[1.1401577 1.9634608 2.8518863 3.7111661]\n",
      "generator loss: -0.21599703 discriminator loss:  -0.067281894\n",
      "Time for epoch 49 is 24.32653522491455 sec\n",
      "[1.1542099 2.0825627 2.8154826 3.6692564]\n",
      "generator loss: -0.24336964 discriminator loss:  -0.101120606\n",
      "Time for epoch 50 is 23.56245517730713 sec\n",
      "[1.142019  2.0798151 2.8559415 3.704965 ]\n",
      "generator loss: -0.20309886 discriminator loss:  -0.0928759\n",
      "Time for epoch 51 is 24.03779411315918 sec\n",
      "[1.1416283 2.1492312 2.803692  3.6926646]\n",
      "generator loss: -0.2138786 discriminator loss:  -0.0928788\n",
      "Time for epoch 52 is 23.45598006248474 sec\n",
      "[1.112375  1.954004  2.820122  3.7245204]\n",
      "generator loss: -0.24139178 discriminator loss:  -0.086058095\n",
      "Time for epoch 53 is 23.70787286758423 sec\n",
      "[1.1591935 1.8373963 2.8230007 3.6789248]\n",
      "generator loss: -0.23524946 discriminator loss:  -0.0810924\n",
      "Time for epoch 54 is 23.689064264297485 sec\n",
      "[1.25688   1.9523112 2.7878845 3.5990076]\n",
      "generator loss: -0.21403691 discriminator loss:  -0.10733243\n",
      "Time for epoch 55 is 24.31039571762085 sec\n",
      "[1.1901128 1.9879527 2.8325922 3.668198 ]\n",
      "generator loss: -0.22503266 discriminator loss:  -0.07485141\n",
      "Time for epoch 56 is 24.261425971984863 sec\n",
      "[1.1498548 2.0926948 2.7931378 3.705489 ]\n",
      "generator loss: -0.2391237 discriminator loss:  -0.07884869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 57 is 23.811458826065063 sec\n",
      "[1.1407484 1.9643689 2.8223836 3.7156243]\n",
      "generator loss: -0.2515583 discriminator loss:  -0.09727265\n",
      "Time for epoch 58 is 24.005218982696533 sec\n",
      "[1.1460395 2.0859642 2.8398166 3.6941166]\n",
      "generator loss: -0.25935018 discriminator loss:  -0.08927377\n",
      "Time for epoch 59 is 23.8347909450531 sec\n",
      "[1.0952758 2.063984  2.8953922 3.7181756]\n",
      "generator loss: -0.31479025 discriminator loss:  -0.039402623\n",
      "Time for epoch 60 is 24.774132013320923 sec\n",
      "[1.1077834 1.8826039 2.8482616 3.6904967]\n",
      "generator loss: -0.15876679 discriminator loss:  -0.055227846\n",
      "Time for epoch 61 is 30.008628129959106 sec\n",
      "[1.0552206 1.911976  2.8490214 3.7349517]\n",
      "generator loss: -0.2792907 discriminator loss:  -0.0442369\n",
      "Time for epoch 62 is 24.48963689804077 sec\n",
      "[1.181842  2.135667  2.8120084 3.6734874]\n",
      "generator loss: -0.20525613 discriminator loss:  -0.0962314\n",
      "Time for epoch 63 is 25.187015056610107 sec\n",
      "[1.2088329 2.0743668 2.8338804 3.7042341]\n",
      "generator loss: -0.24668668 discriminator loss:  -0.07796711\n",
      "Time for epoch 64 is 24.00756001472473 sec\n",
      "[1.1610776 2.175189  2.8643012 3.7398489]\n",
      "generator loss: -0.20458153 discriminator loss:  -0.09868021\n",
      "Time for epoch 65 is 23.675511837005615 sec\n",
      "[1.1726344 1.966433  2.8051624 3.6693056]\n",
      "generator loss: -0.21759172 discriminator loss:  -0.09387062\n",
      "Time for epoch 66 is 23.69615387916565 sec\n",
      "[1.1503986 2.0245345 2.807262  3.6466434]\n",
      "generator loss: -0.20961675 discriminator loss:  -0.10176506\n",
      "Time for epoch 67 is 23.776456832885742 sec\n",
      "[1.1391    1.9557877 2.8697233 3.6686344]\n",
      "generator loss: -0.28760803 discriminator loss:  -0.091634005\n",
      "Time for epoch 68 is 24.6291766166687 sec\n",
      "[1.204553  2.0265672 2.8151355 3.6407723]\n",
      "generator loss: -0.20124884 discriminator loss:  -0.07112607\n",
      "Time for epoch 69 is 23.910948276519775 sec\n",
      "[1.1805705 2.086286  2.8063455 3.6857243]\n",
      "generator loss: -0.19658068 discriminator loss:  -0.08722247\n",
      "Time for epoch 70 is 23.789915323257446 sec\n",
      "[1.1890281 1.9260889 2.7858276 3.6873634]\n",
      "generator loss: -0.2173692 discriminator loss:  -0.08683256\n",
      "Time for epoch 71 is 24.27736210823059 sec\n",
      "[1.2146707 1.9737908 2.767513  3.6452684]\n",
      "generator loss: -0.1885607 discriminator loss:  -0.07036156\n",
      "Time for epoch 72 is 25.335763931274414 sec\n",
      "[1.136189  2.0523298 2.8762267 3.7233093]\n",
      "generator loss: -0.23029514 discriminator loss:  -0.10739602\n",
      "Time for epoch 73 is 24.221001863479614 sec\n",
      "[1.1744263 2.1157575 2.8431854 3.6785657]\n",
      "generator loss: -0.2332501 discriminator loss:  -0.11302221\n",
      "Time for epoch 74 is 30.501440048217773 sec\n",
      "[1.0905098 2.0705416 2.8769817 3.7397563]\n",
      "generator loss: -0.26236707 discriminator loss:  -0.050618663\n",
      "Time for epoch 75 is 26.308454036712646 sec\n",
      "[1.1539398 1.8959503 2.8200161 3.6750846]\n",
      "generator loss: -0.20665495 discriminator loss:  -0.07775149\n",
      "Time for epoch 76 is 23.383081912994385 sec\n",
      "[1.1361259 1.970487  2.8556983 3.700305 ]\n",
      "generator loss: -0.26899105 discriminator loss:  -0.056117844\n",
      "Time for epoch 77 is 23.721781015396118 sec\n",
      "[1.2010494 2.0580373 2.7906046 3.6622288]\n",
      "generator loss: -0.25202304 discriminator loss:  -0.09353407\n",
      "Time for epoch 78 is 23.889804124832153 sec\n",
      "[1.2166852 1.9490268 2.7878704 3.6506648]\n",
      "generator loss: -0.26510972 discriminator loss:  -0.1114538\n",
      "Time for epoch 79 is 23.537768840789795 sec\n",
      "[1.14199   2.0595188 2.8471088 3.7028718]\n",
      "generator loss: -0.28230086 discriminator loss:  -0.08143703\n",
      "Time for epoch 80 is 23.731281757354736 sec\n",
      "[1.1215521 2.003694  2.8543062 3.70856  ]\n",
      "generator loss: -0.28830913 discriminator loss:  -0.03206846\n",
      "Time for epoch 81 is 23.74778175354004 sec\n",
      "[1.1657237 2.0474107 2.8078666 3.6439703]\n",
      "generator loss: -0.29526907 discriminator loss:  -0.07869174\n",
      "Time for epoch 82 is 24.599854707717896 sec\n",
      "[1.1867951 2.019291  2.825946  3.6310303]\n",
      "generator loss: -0.18639252 discriminator loss:  -0.07478839\n",
      "Time for epoch 83 is 24.77909207344055 sec\n",
      "[1.2108005 2.0537407 2.788528  3.6436753]\n",
      "generator loss: -0.23118606 discriminator loss:  -0.08747889\n",
      "Time for epoch 84 is 25.22842288017273 sec\n",
      "[1.2319102 1.9100482 2.7519987 3.6408024]\n",
      "generator loss: -0.17691419 discriminator loss:  -0.07819347\n",
      "Time for epoch 85 is 24.626540184020996 sec\n",
      "[1.2070345 1.938855  2.7485476 3.6234686]\n",
      "generator loss: -0.19204892 discriminator loss:  -0.10543092\n",
      "Time for epoch 86 is 23.634360790252686 sec\n",
      "[1.1600541 2.031745  2.8686576 3.6878834]\n",
      "generator loss: -0.25539717 discriminator loss:  -0.080569945\n",
      "Time for epoch 87 is 23.733060121536255 sec\n",
      "[1.2220126 2.091765  2.82709   3.63197  ]\n",
      "generator loss: -0.2916271 discriminator loss:  -0.09606024\n",
      "Time for epoch 88 is 23.854063272476196 sec\n",
      "[1.1325821 2.008681  2.8774686 3.7317207]\n",
      "generator loss: -0.22018577 discriminator loss:  -0.08505775\n",
      "Time for epoch 89 is 24.774788856506348 sec\n",
      "[1.223207  2.1069922 2.751243  3.6193264]\n",
      "generator loss: -0.19642352 discriminator loss:  -0.052958257\n",
      "Time for epoch 90 is 24.457876920700073 sec\n",
      "[1.1068282 1.956701  2.8613596 3.7479908]\n",
      "generator loss: -0.29093212 discriminator loss:  -0.055512544\n",
      "Time for epoch 91 is 23.82068705558777 sec\n",
      "[1.2357427 2.0648417 2.7472825 3.6013758]\n",
      "generator loss: -0.24686365 discriminator loss:  -0.09416089\n",
      "Time for epoch 92 is 23.555837869644165 sec\n",
      "[1.1735262 2.1588156 2.7927117 3.6317623]\n",
      "generator loss: -0.20811418 discriminator loss:  -0.074961625\n",
      "Time for epoch 93 is 23.298943042755127 sec\n",
      "[1.1196134 2.0744162 2.8538249 3.7255425]\n",
      "generator loss: -0.26958922 discriminator loss:  -0.07412154\n",
      "Time for epoch 94 is 24.760554313659668 sec\n",
      "[1.1734589 2.0425088 2.7602634 3.6733637]\n",
      "generator loss: -0.16430959 discriminator loss:  -0.082617044\n",
      "Time for epoch 95 is 25.094393014907837 sec\n",
      "[1.0731076 2.0232253 2.8634663 3.7748804]\n",
      "generator loss: -0.24703261 discriminator loss:  -0.07279751\n",
      "Time for epoch 96 is 25.06350588798523 sec\n",
      "[1.1895068 2.0400128 2.7689285 3.6485994]\n",
      "generator loss: -0.2874353 discriminator loss:  -0.085201904\n",
      "Time for epoch 97 is 23.435532808303833 sec\n",
      "[1.1114912 1.8902477 2.870822  3.6854205]\n",
      "generator loss: -0.23928419 discriminator loss:  -0.12497677\n",
      "Time for epoch 98 is 26.794604063034058 sec\n",
      "[1.1232002 1.9691277 2.8796058 3.6605723]\n",
      "generator loss: -0.22504552 discriminator loss:  -0.08703916\n",
      "Time for epoch 99 is 25.207274913787842 sec\n",
      "[1.1233722 2.192512  2.8974235 3.6934447]\n",
      "generator loss: -0.23262854 discriminator loss:  -0.09583524\n",
      "Time for epoch 100 is 23.362514972686768 sec\n",
      "[1.2075197 1.8802174 2.7852988 3.6381292]\n",
      "generator loss: -0.27162573 discriminator loss:  -0.10171421\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "step_size = 0.01\n",
    "\n",
    "wgan = WGAN(dim_x=p, target=\"location\")\n",
    "wgan.train(data_perturbed, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 0.9796490669250488 sec\n",
      "[0.77604896 1.5157262  2.1762435  3.2488031 ]\n",
      "generator loss: -0.3662386 discriminator loss:  -0.2911882\n",
      "Time for epoch 2 is 0.9468278884887695 sec\n",
      "[0.8036269 1.5173982 2.201513  3.273699 ]\n",
      "generator loss: -0.21841952 discriminator loss:  -0.3735035\n",
      "Time for epoch 3 is 0.9065437316894531 sec\n",
      "[0.825439  1.4986236 2.2198682 3.2916005]\n",
      "generator loss: -0.19563393 discriminator loss:  -0.39427704\n",
      "Time for epoch 4 is 0.9309597015380859 sec\n",
      "[0.84795   1.4758803 2.2386518 3.3100014]\n",
      "generator loss: -0.29642737 discriminator loss:  -0.2552811\n",
      "Time for epoch 5 is 0.9330430030822754 sec\n",
      "[0.8671304 1.4601793 2.2544427 3.3258483]\n",
      "generator loss: -0.17755479 discriminator loss:  -0.37688398\n",
      "Time for epoch 6 is 0.8796870708465576 sec\n",
      "[0.8862762 1.4557648 2.270294  3.3419034]\n",
      "generator loss: -0.2164856 discriminator loss:  -0.34871703\n",
      "Time for epoch 7 is 0.894524097442627 sec\n",
      "[0.9046401 1.4650825 2.285781  3.357752 ]\n",
      "generator loss: -0.2714462 discriminator loss:  -0.3023104\n",
      "Time for epoch 8 is 0.9022531509399414 sec\n",
      "[0.92131793 1.4816691  2.300552   3.3725486 ]\n",
      "generator loss: -0.2625289 discriminator loss:  -0.2860611\n",
      "Time for epoch 9 is 0.8610928058624268 sec\n",
      "[0.93773985 1.500995   2.3158567  3.387938  ]\n",
      "generator loss: -0.25008547 discriminator loss:  -0.27145407\n",
      "Time for epoch 10 is 0.8590097427368164 sec\n",
      "[0.9546168 1.518558  2.3319242 3.4038715]\n",
      "generator loss: -0.25444013 discriminator loss:  -0.204725\n",
      "Time for epoch 11 is 0.8606181144714355 sec\n",
      "[0.9687359 1.5343403 2.3449695 3.4165506]\n",
      "generator loss: -0.11357269 discriminator loss:  -0.34990835\n",
      "Time for epoch 12 is 0.8821439743041992 sec\n",
      "[0.98361903 1.5540165  2.358475   3.4300842 ]\n",
      "generator loss: -0.211102 discriminator loss:  -0.29114228\n",
      "Time for epoch 13 is 1.1058409214019775 sec\n",
      "[0.99946237 1.5774734  2.372639   3.444412  ]\n",
      "generator loss: -0.11881017 discriminator loss:  -0.39850733\n",
      "Time for epoch 14 is 0.9514980316162109 sec\n",
      "[1.0167214 1.6006069 2.3882382 3.4600024]\n",
      "generator loss: -0.17505771 discriminator loss:  -0.3333536\n",
      "Time for epoch 15 is 0.998568058013916 sec\n",
      "[1.0328703 1.6178344 2.4028535 3.4743161]\n",
      "generator loss: -0.089035705 discriminator loss:  -0.39699897\n",
      "Time for epoch 16 is 1.047922134399414 sec\n",
      "[1.0504744 1.6358075 2.4187171 3.4899254]\n",
      "generator loss: -0.253559 discriminator loss:  -0.22154531\n",
      "Time for epoch 17 is 1.1054909229278564 sec\n",
      "[1.0668596 1.6464397 2.4341185 3.5048923]\n",
      "generator loss: -0.12447185 discriminator loss:  -0.28496072\n",
      "Time for epoch 18 is 1.0637609958648682 sec\n",
      "[1.0805423 1.6586312 2.447497  3.518128 ]\n",
      "generator loss: -0.12665208 discriminator loss:  -0.30732614\n",
      "Time for epoch 19 is 1.0550918579101562 sec\n",
      "[1.0941014 1.6722311 2.4610913 3.5315297]\n",
      "generator loss: -0.10296677 discriminator loss:  -0.3149811\n",
      "Time for epoch 20 is 1.0668270587921143 sec\n",
      "[1.1095539 1.6906143 2.4764638 3.546652 ]\n",
      "generator loss: -0.21992138 discriminator loss:  -0.18391763\n",
      "Time for epoch 21 is 1.1350901126861572 sec\n",
      "[1.1224388 1.7063694 2.4893804 3.5591395]\n",
      "generator loss: -0.20644858 discriminator loss:  -0.21025097\n",
      "Time for epoch 22 is 0.9999113082885742 sec\n",
      "[1.1360538 1.7224424 2.5028627 3.572439 ]\n",
      "generator loss: -0.2565731 discriminator loss:  -0.18381718\n",
      "Time for epoch 23 is 1.1085870265960693 sec\n",
      "[1.1510928 1.7397282 2.517916  3.5874834]\n",
      "generator loss: -0.16276303 discriminator loss:  -0.22913373\n",
      "Time for epoch 24 is 0.9396331310272217 sec\n",
      "[1.1651999 1.7568073 2.5322764 3.6018298]\n",
      "generator loss: -0.12536612 discriminator loss:  -0.28283203\n",
      "Time for epoch 25 is 0.8817100524902344 sec\n",
      "[1.1806129 1.7716124 2.547318  3.6167655]\n",
      "generator loss: -0.25854558 discriminator loss:  -0.12404321\n",
      "Time for epoch 26 is 0.8873999118804932 sec\n",
      "[1.1943355 1.7835127 2.5604858 3.6297264]\n",
      "generator loss: -0.18885693 discriminator loss:  -0.19635671\n",
      "Time for epoch 27 is 1.1025710105895996 sec\n",
      "[1.2088956 1.7973188 2.5744002 3.6437511]\n",
      "generator loss: -0.26397872 discriminator loss:  -0.13087612\n",
      "Time for epoch 28 is 1.1534819602966309 sec\n",
      "[1.2220106 1.8098826 2.5869555 3.6565607]\n",
      "generator loss: -0.20779979 discriminator loss:  -0.18089125\n",
      "Time for epoch 29 is 1.234618902206421 sec\n",
      "[1.2358832 1.8255662 2.5999973 3.6700501]\n",
      "generator loss: -0.22084004 discriminator loss:  -0.21358177\n",
      "Time for epoch 30 is 1.0341169834136963 sec\n",
      "[1.2520117 1.845136  2.6154084 3.6860287]\n",
      "generator loss: -0.3147568 discriminator loss:  -0.12834664\n",
      "Time for epoch 31 is 1.1814720630645752 sec\n",
      "[1.2677163 1.8617073 2.6307557 3.701707 ]\n",
      "generator loss: -0.27433455 discriminator loss:  -0.10282959\n",
      "Time for epoch 32 is 1.24576997756958 sec\n",
      "[1.2788898 1.8743403 2.6426628 3.7137516]\n",
      "generator loss: -0.22184335 discriminator loss:  -0.14615603\n",
      "Time for epoch 33 is 0.9488570690155029 sec\n",
      "[1.2903247 1.8891025 2.6551952 3.726483 ]\n",
      "generator loss: -0.18975414 discriminator loss:  -0.17508605\n",
      "Time for epoch 34 is 0.9220170974731445 sec\n",
      "[1.3038801 1.9061723 2.6694725 3.7410681]\n",
      "generator loss: -0.23440076 discriminator loss:  -0.16754168\n",
      "Time for epoch 35 is 0.9125139713287354 sec\n",
      "[1.3171997 1.9225521 2.6841362 3.7561724]\n",
      "generator loss: -0.29117793 discriminator loss:  -0.085435025\n",
      "Time for epoch 36 is 0.9021399021148682 sec\n",
      "[1.3298697 1.93869   2.6983116 3.7706485]\n",
      "generator loss: -0.3195561 discriminator loss:  -0.034235884\n",
      "Time for epoch 37 is 0.9343118667602539 sec\n",
      "[1.3394024 1.9499602 2.7094812 3.7817369]\n",
      "generator loss: -0.25353804 discriminator loss:  -0.085731104\n",
      "Time for epoch 38 is 0.9077918529510498 sec\n",
      "[1.3449696 1.9563446 2.715915  3.788142 ]\n",
      "generator loss: -0.24078792 discriminator loss:  -0.11530279\n",
      "Time for epoch 39 is 0.9043161869049072 sec\n",
      "[1.3588674 1.9727033 2.7301445 3.8029149]\n",
      "generator loss: -0.28201443 discriminator loss:  -0.10603866\n",
      "Time for epoch 40 is 0.8907546997070312 sec\n",
      "[1.3700542 1.984899  2.7418897 3.814797 ]\n",
      "generator loss: -0.26925805 discriminator loss:  -0.070758514\n",
      "Time for epoch 41 is 0.9102907180786133 sec\n",
      "[1.3764944 1.9918269 2.74879   3.8217213]\n",
      "generator loss: -0.2500314 discriminator loss:  -0.11516179\n",
      "Time for epoch 42 is 0.9374489784240723 sec\n",
      "[1.3886365 2.0062778 2.761232  3.8344975]\n",
      "generator loss: -0.26451153 discriminator loss:  -0.10676834\n",
      "Time for epoch 43 is 1.0180590152740479 sec\n",
      "[1.3970119 2.0160685 2.7701793 3.8435366]\n",
      "generator loss: -0.3053258 discriminator loss:  -0.072787486\n",
      "Time for epoch 44 is 0.9425859451293945 sec\n",
      "[1.4019868 2.0215054 2.7755883 3.8489418]\n",
      "generator loss: -0.29930001 discriminator loss:  -0.06522179\n",
      "Time for epoch 45 is 0.9181811809539795 sec\n",
      "[1.4073371 2.02732   2.780996  3.8543813]\n",
      "generator loss: -0.3197083 discriminator loss:  -0.06088598\n",
      "Time for epoch 46 is 0.901496171951294 sec\n",
      "[1.4199384 2.0428677 2.7924905 3.8665164]\n",
      "generator loss: -0.33208612 discriminator loss:  -0.077351354\n",
      "Time for epoch 47 is 0.9452841281890869 sec\n",
      "[1.4317511 2.056265  2.8034885 3.878034 ]\n",
      "generator loss: -0.30490345 discriminator loss:  -0.079053186\n",
      "Time for epoch 48 is 1.0776100158691406 sec\n",
      "[1.4369322 2.0612302 2.8086846 3.883205 ]\n",
      "generator loss: -0.27793008 discriminator loss:  -0.08417052\n",
      "Time for epoch 49 is 1.0958290100097656 sec\n",
      "[1.4447849 2.0689921 2.8162193 3.8909307]\n",
      "generator loss: -0.28713122 discriminator loss:  -0.08100538\n",
      "Time for epoch 50 is 1.3931479454040527 sec\n",
      "[1.4507514 2.0742528 2.8221405 3.8967638]\n",
      "generator loss: -0.2884305 discriminator loss:  -0.07076805\n"
     ]
    }
   ],
   "source": [
    "wgan.train(data_perturbed, epochs=epochs//2, batch_size=batch_size, step_size=step_size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22312006581491062\n",
      "0.2344593145903957\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(np.mean(data_perturbed, axis=0)-theta)**2)\n",
    "print(np.linalg.norm(wgan.generator.trainable_variables[0].numpy()-theta)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "p = 4\n",
    "sigma = 1\n",
    "beta = np.array([1,2,3,4], dtype=np.float32)\n",
    "\n",
    "data_X = np.random.normal(size=(N,p)).astype(np.float32)\n",
    "data_y = data_X @ beta + np.random.normal(scale=sigma, size=(N,)).astype(np.float32)\n",
    "data_y = data_y.reshape([-1,1])\n",
    "data_reg = np.concatenate([data_X, data_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least square estimate: \n",
      " [[0.918088 ]\n",
      " [1.9790355]\n",
      " [3.0042918]\n",
      " [3.978514 ]]\n"
     ]
    }
   ],
   "source": [
    "betahat = np.linalg.solve(data_X.T@data_X, (data_X.T@data_y))\n",
    "print(\"least square estimate: \\n\", betahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 9.458981037139893 sec\n",
      "[ 0.8137293   0.45727253 -1.116679   -0.67006314]\n",
      "generator loss: -0.05943303 discriminator loss:  -0.22450735\n",
      "Time for epoch 2 is 9.441058874130249 sec\n",
      "[ 1.0455842  0.7334564 -1.3095939 -0.5707018]\n",
      "generator loss: -0.011014687 discriminator loss:  -0.2832605\n",
      "Time for epoch 3 is 9.305871963500977 sec\n",
      "[ 1.2688947   0.9833873  -1.432649   -0.35507995]\n",
      "generator loss: 0.07638909 discriminator loss:  -0.2896044\n",
      "Time for epoch 4 is 9.490269899368286 sec\n",
      "[ 1.5105995   1.2216096  -1.4756104  -0.10068965]\n",
      "generator loss: 0.15273888 discriminator loss:  -0.38662213\n",
      "Time for epoch 5 is 9.741095304489136 sec\n",
      "[ 1.7713228   1.4890993  -1.4523885   0.11344511]\n",
      "generator loss: 0.18510675 discriminator loss:  -0.4062869\n",
      "Time for epoch 6 is 10.159914016723633 sec\n",
      "[ 2.0671592   1.7392192  -1.3528737   0.36751267]\n",
      "generator loss: 0.2995221 discriminator loss:  -0.43001193\n",
      "Time for epoch 7 is 9.508867979049683 sec\n",
      "[ 2.3325555  2.0300498 -1.1113856  0.6464563]\n",
      "generator loss: 0.336553 discriminator loss:  -0.40458256\n",
      "Time for epoch 8 is 9.365824937820435 sec\n",
      "[ 2.5980563  2.3097155 -0.8355042  0.8863811]\n",
      "generator loss: 0.3772732 discriminator loss:  -0.40459812\n",
      "Time for epoch 9 is 9.42086386680603 sec\n",
      "[ 2.8529198   2.5593927  -0.57522166  1.173721  ]\n",
      "generator loss: 0.39184013 discriminator loss:  -0.38007224\n",
      "Time for epoch 10 is 10.104347944259644 sec\n",
      "[ 3.0969856   2.7749066  -0.29494327  1.4661894 ]\n",
      "generator loss: 0.44572484 discriminator loss:  -0.40847996\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "step_size = 0.01\n",
    "\n",
    "wgan = WGAN(dim_x=p+1, target=\"regression\")\n",
    "wgan.train(data_reg, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(data, epochs=10, batch_size=32, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct test version of model with self defined layers\n",
    "# def build_model():\n",
    "#     a = tf.keras.Input(shape=(4,))\n",
    "#     out = LocationAdd(input_dim=4)(a+5)\n",
    "#     model = tf.keras.Model(inputs=a, outputs=out)\n",
    "#     return model\n",
    "# model = build_model()\n",
    "# model2 = build_model()\n",
    "# print(model.trainable_variables)\n",
    "# print(model2.trainable_variables)\n",
    "# model.compile(optimizer='rmsprop', loss=tf.keras.losses.MeanSquaredError())\n",
    "# model.fit(x=data,y=data, batch_size=1, epochs=100)\n",
    "# print(model.trainable_variables)\n",
    "# print(model2.trainable_variables)\n",
    "\n",
    "## tf.keras.layers.add can make variables not trainable, below is not correct\n",
    "# a = tf.keras.Input(shape=(4,))\n",
    "# b = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(4,)), trainable=True)\n",
    "# out = tf.keras.layers.add([a+5,b])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
