{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom-defined layers\n",
    "\n",
    "class LocationAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LocationAdd, self).__init__()\n",
    "        w_init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim,)), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.add(inputs, self.w)\n",
    "    \n",
    "class RegressionAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionAdd, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        w_init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim-1,)), trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_X, input_z = tf.split(inputs, [self.input_dim-1, 1], axis=1)\n",
    "        return tf.concat([input_X, tf.add(tf.reshape(tf.linalg.matvec(input_X, self.w),[-1,1]),input_z)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom-defined constraints\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "class Constraint(object):\n",
    "    def __call__(self, w):\n",
    "        return w\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "class Max1Norm(Constraint):\n",
    "    \"\"\"1-Norm weight constraint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_value=2, axis=0):\n",
    "        self.max_value = max_value\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, w):\n",
    "        norms = math_ops.reduce_sum(math_ops.abs(w), axis=self.axis, keepdims=True)\n",
    "        desired = K.clip(norms, 0, self.max_value)\n",
    "        return w * (desired / (K.epsilon() + norms))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'max_value': self.max_value, 'axis': self.axis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WganError(tf.keras.losses.Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        #y_pred = ops.convert_to_tensor(y_pred)\n",
    "        #y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "        return K.mean(y_pred - y_true, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN:\n",
    "    \n",
    "    ''' A static model, with fixed input size.\n",
    "        Model should not be defined in train(), so it should not depend on dataset dimension.\n",
    "        Model API has an advantage that it can save weights between different calls of train.\n",
    "        Instead of using tf.Session() as before, where only one training can happen, next will refresh,\n",
    "        using Model() API avoids this, it provides a model which saves weights outside tf.Session()!\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dim_x, target):\n",
    "        self.dim_x = dim_x\n",
    "        self.target = target\n",
    "        self.generator = self.generator_model(dim_x, target)\n",
    "        self.discriminator = self.discriminator_model(dim_x)\n",
    "\n",
    "    \n",
    "    def generator_model(self, dim, target):\n",
    "        if target == \"location\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = LocationAdd(dim)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "        elif target == \"cov-matrix\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = layers.Dense(units=dim, use_bias=False)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "        elif target == \"regression\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = RegressionAdd(dim)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "    \n",
    "    def discriminator_model(self, dim):        \n",
    "        inputs = tf.keras.Input(shape=(dim,))\n",
    "        dense1 = layers.Dense(units=dim//2, activation=tf.keras.activations.sigmoid, \n",
    "                              kernel_constraint=tf.keras.constraints.MaxNorm(max_value=10, axis=0))(inputs)\n",
    "        dense2 = layers.Dense(units=dim//4, activation=tf.keras.activations.relu, \n",
    "                              kernel_constraint=Max1Norm(max_value=1, axis=0))(dense1)\n",
    "        out = layers.Dense(units=1, activation=None, \n",
    "                           kernel_constraint=Max1Norm(max_value=1,axis=0))(dense2)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        #real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        #fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        #total_loss = real_loss + fake_loss\n",
    "        total_loss = WganError()(real_output, fake_output)\n",
    "        return total_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator_loss(fake_output):\n",
    "        # cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        # loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        loss = WganError()(fake_output, tf.zeros_like(fake_output))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def train(self, dataset, epochs, batch_size, step_size):\n",
    "        self.generator_optimizer = tf.keras.optimizers.RMSprop(step_size)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.RMSprop(step_size)\n",
    "        data = tf.data.Dataset.from_tensor_slices(dataset).repeat().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        for epoch in range(epochs):\n",
    "            noises = tf.data.Dataset.from_tensor_slices(tf.random.normal(dataset.shape)).batch(batch_size).take(dataset.shape[0]//batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "            for batch, noise in zip(data, noises):\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    generated = self.generator(noise, training=True)\n",
    "                    real_output = self.discriminator(batch, training=True)\n",
    "                    fake_output = self.discriminator(generated, training=True)\n",
    "\n",
    "                    gen_loss = WGAN.generator_loss(fake_output)\n",
    "                    disc_loss = WGAN.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "                    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                    self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "#             print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "#             A = self.generator.trainable_variables[0].numpy()\n",
    "#             if self.target == \"location\" or self.target == \"regression\":\n",
    "#                 print(A)\n",
    "#             elif self.target == \"cov-matrix\":\n",
    "#                 sigma_hat = np.matmul(A, A.T)\n",
    "#                 print(sigma_hat)\n",
    "#                 print(np.linalg.norm(sigma_hat-np.identity(self.dim_x), ord=2))\n",
    "            if epoch >= epochs - 10:\n",
    "                print(\"generator loss: {:.4f}, discriminator loss: {:.4f}\".format(gen_loss.numpy(),disc_loss.numpy()))\n",
    "#             print(np.linalg.norm(self.discriminator.trainable_variables[0].numpy(), ord=1, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance matrix estimation\n",
    "\n",
    "https://stackoverflow.com/questions/56201185/how-to-find-a-variable-by-name-in-tensorflow2-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_cov(N, p, model):        \n",
    "    if N <= 100:\n",
    "        batch_size = 32 \n",
    "    elif N <= 5000:\n",
    "        batch_size = 128\n",
    "    else:\n",
    "        batch_size = 256\n",
    "    epochs = 200\n",
    "    step_size = 0.005\n",
    "    \n",
    "    wgan = WGAN(dim_x=p, target=\"cov-matrix\")\n",
    "    wgan.train(data_perturbed, epochs=epochs, batch_size=batch_size, step_size=step_size)\n",
    "    \n",
    "    Ahat = wgan.generator.trainable_variables[0].numpy()\n",
    "    wgan_error = np.linalg.norm(Ahat.T@Ahat-cov, ord=2)\n",
    "    return wgan_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100, p=10, model=Cauchy in progress.\n",
      "sample cov error: 989.1726\n",
      "generator loss: 0.1043, discriminator loss: -0.2424\n",
      "generator loss: 0.0238, discriminator loss: -0.1643\n",
      "generator loss: 0.0445, discriminator loss: -0.1857\n",
      "generator loss: 0.0468, discriminator loss: -0.1893\n",
      "generator loss: 0.0074, discriminator loss: -0.1529\n",
      "generator loss: -0.0131, discriminator loss: -0.1336\n",
      "generator loss: 0.1717, discriminator loss: -0.3180\n",
      "generator loss: 0.0341, discriminator loss: -0.1805\n",
      "generator loss: 0.0409, discriminator loss: -0.1885\n",
      "generator loss: 0.0080, discriminator loss: -0.1595\n",
      "wgan error: 2.6623\n",
      "generator loss: -0.4117, discriminator loss: -0.2360\n",
      "generator loss: -0.6338, discriminator loss: -0.0143\n",
      "generator loss: -0.4676, discriminator loss: -0.1813\n",
      "generator loss: -0.5412, discriminator loss: -0.1085\n",
      "generator loss: -0.5042, discriminator loss: -0.1462\n",
      "generator loss: -0.5400, discriminator loss: -0.1103\n",
      "generator loss: -0.3422, discriminator loss: -0.3081\n",
      "generator loss: -0.4567, discriminator loss: -0.1950\n",
      "generator loss: -0.4581, discriminator loss: -0.1943\n",
      "generator loss: -0.5675, discriminator loss: -0.0858\n",
      "wgan error: 3.7695\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "wgan error: 2.8977\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "wgan error: 1.8114\n",
      "generator loss: 0.5503, discriminator loss: -0.2034\n",
      "generator loss: 0.4584, discriminator loss: -0.1068\n",
      "generator loss: 0.5394, discriminator loss: -0.1884\n",
      "generator loss: 0.4820, discriminator loss: -0.1313\n",
      "generator loss: 0.5967, discriminator loss: -0.2457\n",
      "generator loss: 0.5164, discriminator loss: -0.1694\n",
      "generator loss: 0.5895, discriminator loss: -0.2402\n",
      "generator loss: 0.5991, discriminator loss: -0.2512\n",
      "generator loss: 0.5288, discriminator loss: -0.1778\n",
      "generator loss: 0.4721, discriminator loss: -0.1166\n",
      "wgan error: 3.5582\n",
      "generator loss: 0.4030, discriminator loss: -0.1037\n",
      "generator loss: 0.4777, discriminator loss: -0.1754\n",
      "generator loss: 0.4299, discriminator loss: -0.1268\n",
      "generator loss: 0.4824, discriminator loss: -0.1781\n",
      "generator loss: 0.5278, discriminator loss: -0.2254\n",
      "generator loss: 0.3993, discriminator loss: -0.0985\n",
      "generator loss: 0.5221, discriminator loss: -0.2187\n",
      "generator loss: 0.4398, discriminator loss: -0.1344\n",
      "generator loss: 0.5302, discriminator loss: -0.2210\n",
      "generator loss: 0.5316, discriminator loss: -0.2228\n",
      "wgan error: 2.3409\n",
      "generator loss: -0.4555, discriminator loss: -0.2121\n",
      "generator loss: -0.4981, discriminator loss: -0.1706\n",
      "generator loss: -0.4400, discriminator loss: -0.2285\n",
      "generator loss: -0.5358, discriminator loss: -0.1333\n",
      "generator loss: -0.5592, discriminator loss: -0.1115\n",
      "generator loss: -0.4922, discriminator loss: -0.1780\n",
      "generator loss: -0.4163, discriminator loss: -0.2536\n",
      "generator loss: -0.4812, discriminator loss: -0.1887\n",
      "generator loss: -0.4605, discriminator loss: -0.2120\n",
      "generator loss: -0.5727, discriminator loss: -0.1001\n",
      "wgan error: 2.7802\n",
      "generator loss: 0.4208, discriminator loss: -0.0802\n",
      "generator loss: 0.5097, discriminator loss: -0.1689\n",
      "generator loss: 0.4619, discriminator loss: -0.1198\n",
      "generator loss: 0.4088, discriminator loss: -0.0667\n",
      "generator loss: 0.5067, discriminator loss: -0.1651\n",
      "generator loss: 0.4218, discriminator loss: -0.0792\n",
      "generator loss: 0.4580, discriminator loss: -0.1141\n",
      "generator loss: 0.4589, discriminator loss: -0.1143\n",
      "generator loss: 0.4233, discriminator loss: -0.0783\n",
      "generator loss: 0.5020, discriminator loss: -0.1561\n",
      "wgan error: 1.8932\n",
      "generator loss: 0.0028, discriminator loss: -0.1174\n",
      "generator loss: 0.0847, discriminator loss: -0.2013\n",
      "generator loss: 0.0661, discriminator loss: -0.1828\n",
      "generator loss: 0.1308, discriminator loss: -0.2463\n",
      "generator loss: -0.0535, discriminator loss: -0.0632\n",
      "generator loss: 0.0498, discriminator loss: -0.1671\n",
      "generator loss: -0.0092, discriminator loss: -0.1089\n",
      "generator loss: -0.0399, discriminator loss: -0.0786\n",
      "generator loss: -0.1103, discriminator loss: -0.0093\n",
      "generator loss: 0.1274, discriminator loss: -0.2480\n",
      "wgan error: 2.1369\n",
      "generator loss: 0.5105, discriminator loss: -0.1689\n",
      "generator loss: 0.4923, discriminator loss: -0.1498\n",
      "generator loss: 0.4973, discriminator loss: -0.1526\n",
      "generator loss: 0.5202, discriminator loss: -0.1745\n",
      "generator loss: 0.6050, discriminator loss: -0.2589\n",
      "generator loss: 0.6092, discriminator loss: -0.2618\n",
      "generator loss: 0.5023, discriminator loss: -0.1504\n",
      "generator loss: 0.5419, discriminator loss: -0.1863\n",
      "generator loss: 0.5373, discriminator loss: -0.1822\n",
      "generator loss: 0.4872, discriminator loss: -0.1317\n",
      "wgan error: 2.8556\n",
      "(100, 10, 'Cauchy') 989.1726\n",
      "(100, 10, 'Cauchy') 2.6706 0.6188\n",
      "N=100, p=10, model=Cauchy in done.(1.62 minutes)\n",
      "N=100, p=10, model=Normal in progress.\n",
      "sample cov error: 22.6888\n",
      "generator loss: -0.5024, discriminator loss: -0.1092\n",
      "generator loss: -0.4911, discriminator loss: -0.1201\n",
      "generator loss: -0.5368, discriminator loss: -0.0737\n",
      "generator loss: -0.6019, discriminator loss: -0.0094\n",
      "generator loss: -0.4309, discriminator loss: -0.1818\n",
      "generator loss: -0.5533, discriminator loss: -0.0573\n",
      "generator loss: -0.5637, discriminator loss: -0.0488\n",
      "generator loss: -0.5690, discriminator loss: -0.0429\n",
      "generator loss: -0.4864, discriminator loss: -0.1239\n",
      "generator loss: -0.3816, discriminator loss: -0.2281\n",
      "wgan error: 3.0429\n",
      "generator loss: 0.0300, discriminator loss: -0.1175\n",
      "generator loss: 0.0892, discriminator loss: -0.1777\n",
      "generator loss: -0.0362, discriminator loss: -0.0513\n",
      "generator loss: 0.0246, discriminator loss: -0.1131\n",
      "generator loss: -0.0661, discriminator loss: -0.0246\n",
      "generator loss: 0.0382, discriminator loss: -0.1303\n",
      "generator loss: 0.0430, discriminator loss: -0.1352\n",
      "generator loss: -0.0070, discriminator loss: -0.0862\n",
      "generator loss: -0.0129, discriminator loss: -0.0807\n",
      "generator loss: -0.0437, discriminator loss: -0.0505\n",
      "wgan error: 2.7604\n",
      "generator loss: 0.5455, discriminator loss: -0.1203\n",
      "generator loss: 0.5305, discriminator loss: -0.1041\n",
      "generator loss: 0.4992, discriminator loss: -0.0686\n",
      "generator loss: 0.4864, discriminator loss: -0.0549\n",
      "generator loss: 0.5044, discriminator loss: -0.0713\n",
      "generator loss: 0.5516, discriminator loss: -0.1151\n",
      "generator loss: 0.5108, discriminator loss: -0.0741\n",
      "generator loss: 0.4981, discriminator loss: -0.0588\n",
      "generator loss: 0.5651, discriminator loss: -0.1262\n",
      "generator loss: 0.5415, discriminator loss: -0.1012\n",
      "wgan error: 1.3785\n",
      "generator loss: -0.0200, discriminator loss: -0.1147\n",
      "generator loss: -0.0322, discriminator loss: -0.1031\n",
      "generator loss: -0.0146, discriminator loss: -0.1215\n",
      "generator loss: -0.0382, discriminator loss: -0.0940\n",
      "generator loss: 0.0070, discriminator loss: -0.1395\n",
      "generator loss: 0.0302, discriminator loss: -0.1618\n",
      "generator loss: -0.0144, discriminator loss: -0.1156\n",
      "generator loss: 0.0130, discriminator loss: -0.1445\n",
      "generator loss: -0.0528, discriminator loss: -0.0778\n",
      "generator loss: -0.0008, discriminator loss: -0.1291\n",
      "wgan error: 2.4078\n",
      "generator loss: -0.5749, discriminator loss: -0.0702\n",
      "generator loss: -0.6189, discriminator loss: -0.0243\n",
      "generator loss: -0.5488, discriminator loss: -0.0924\n",
      "generator loss: -0.5727, discriminator loss: -0.0670\n",
      "generator loss: -0.4340, discriminator loss: -0.2046\n",
      "generator loss: -0.4390, discriminator loss: -0.1990\n",
      "generator loss: -0.5524, discriminator loss: -0.0854\n",
      "generator loss: -0.5480, discriminator loss: -0.0895\n",
      "generator loss: -0.5255, discriminator loss: -0.1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: -0.5892, discriminator loss: -0.0465\n",
      "wgan error: 2.6485\n",
      "generator loss: -0.5887, discriminator loss: 0.0011\n",
      "generator loss: -0.4768, discriminator loss: -0.1116\n",
      "generator loss: -0.5526, discriminator loss: -0.0368\n",
      "generator loss: -0.5571, discriminator loss: -0.0334\n",
      "generator loss: -0.3998, discriminator loss: -0.1920\n",
      "generator loss: -0.5181, discriminator loss: -0.0841\n",
      "generator loss: -0.4483, discriminator loss: -0.1544\n",
      "generator loss: -0.5526, discriminator loss: -0.0512\n",
      "generator loss: -0.4346, discriminator loss: -0.1696\n",
      "generator loss: -0.4578, discriminator loss: -0.1468\n",
      "wgan error: 4.4542\n",
      "generator loss: 0.0371, discriminator loss: -0.1483\n",
      "generator loss: 0.0136, discriminator loss: -0.1225\n",
      "generator loss: 0.0019, discriminator loss: -0.1134\n",
      "generator loss: 0.0263, discriminator loss: -0.1370\n",
      "generator loss: 0.0508, discriminator loss: -0.1631\n",
      "generator loss: -0.0131, discriminator loss: -0.0964\n",
      "generator loss: -0.0282, discriminator loss: -0.0801\n",
      "generator loss: -0.0973, discriminator loss: -0.0098\n",
      "generator loss: -0.0014, discriminator loss: -0.1074\n",
      "generator loss: 0.0190, discriminator loss: -0.1257\n",
      "wgan error: 2.6737\n",
      "generator loss: 0.0059, discriminator loss: -0.1208\n",
      "generator loss: 0.0594, discriminator loss: -0.1768\n",
      "generator loss: -0.0331, discriminator loss: -0.0849\n",
      "generator loss: 0.0715, discriminator loss: -0.1893\n",
      "generator loss: 0.0232, discriminator loss: -0.1416\n",
      "generator loss: -0.0227, discriminator loss: -0.0969\n",
      "generator loss: -0.0587, discriminator loss: -0.0641\n",
      "generator loss: -0.0735, discriminator loss: -0.0519\n",
      "generator loss: 0.0155, discriminator loss: -0.1381\n",
      "generator loss: 0.0403, discriminator loss: -0.1648\n",
      "wgan error: 3.3099\n",
      "generator loss: 0.3905, discriminator loss: -0.0331\n",
      "generator loss: 0.4930, discriminator loss: -0.1364\n",
      "generator loss: 0.4073, discriminator loss: -0.0513\n",
      "generator loss: 0.4697, discriminator loss: -0.1141\n",
      "generator loss: 0.4360, discriminator loss: -0.0821\n",
      "generator loss: 0.4001, discriminator loss: -0.0447\n",
      "generator loss: 0.5034, discriminator loss: -0.1495\n",
      "generator loss: 0.4720, discriminator loss: -0.1167\n",
      "generator loss: 0.4435, discriminator loss: -0.0898\n",
      "generator loss: 0.3282, discriminator loss: 0.0257\n",
      "wgan error: 4.6752\n",
      "generator loss: -0.4698, discriminator loss: -0.1539\n",
      "generator loss: -0.5613, discriminator loss: -0.0636\n",
      "generator loss: -0.6355, discriminator loss: 0.0105\n",
      "generator loss: -0.4279, discriminator loss: -0.1982\n",
      "generator loss: -0.5350, discriminator loss: -0.0917\n",
      "generator loss: -0.4848, discriminator loss: -0.1416\n",
      "generator loss: -0.5596, discriminator loss: -0.0666\n",
      "generator loss: -0.5153, discriminator loss: -0.1100\n",
      "generator loss: -0.5013, discriminator loss: -0.1165\n",
      "generator loss: -0.5920, discriminator loss: -0.0341\n",
      "wgan error: 6.5794\n",
      "(100, 10, 'Normal') 22.6888\n",
      "(100, 10, 'Normal') 3.3931 1.3983\n",
      "N=100, p=10, model=Normal in done.(1.62 minutes)\n",
      "N=100, p=10, model=Gumbel in progress.\n",
      "sample cov error: 28.0165\n",
      "generator loss: -0.0667, discriminator loss: -0.0644\n",
      "generator loss: -0.0128, discriminator loss: -0.1187\n",
      "generator loss: -0.0320, discriminator loss: -0.1000\n",
      "generator loss: 0.0897, discriminator loss: -0.2210\n",
      "generator loss: 0.0193, discriminator loss: -0.1498\n",
      "generator loss: 0.0656, discriminator loss: -0.1957\n",
      "generator loss: -0.0199, discriminator loss: -0.1100\n",
      "generator loss: 0.0330, discriminator loss: -0.1619\n",
      "generator loss: 0.1185, discriminator loss: -0.2508\n",
      "generator loss: 0.0186, discriminator loss: -0.1508\n",
      "wgan error: 4.0014\n",
      "generator loss: -0.0620, discriminator loss: -0.1103\n",
      "generator loss: -0.0261, discriminator loss: -0.1461\n",
      "generator loss: -0.0317, discriminator loss: -0.1394\n",
      "generator loss: -0.0811, discriminator loss: -0.0914\n",
      "generator loss: -0.0265, discriminator loss: -0.1458\n",
      "generator loss: 0.0078, discriminator loss: -0.1799\n",
      "generator loss: 0.0536, discriminator loss: -0.2258\n",
      "generator loss: -0.0403, discriminator loss: -0.1325\n",
      "generator loss: 0.1371, discriminator loss: -0.3101\n",
      "generator loss: -0.0556, discriminator loss: -0.1184\n",
      "wgan error: 3.3051\n",
      "generator loss: -0.4255, discriminator loss: -0.2014\n",
      "generator loss: -0.5529, discriminator loss: -0.0739\n",
      "generator loss: -0.5031, discriminator loss: -0.1244\n",
      "generator loss: -0.4057, discriminator loss: -0.2227\n",
      "generator loss: -0.4416, discriminator loss: -0.1902\n",
      "generator loss: -0.4734, discriminator loss: -0.1595\n",
      "generator loss: -0.4471, discriminator loss: -0.1854\n",
      "generator loss: -0.5701, discriminator loss: -0.0625\n",
      "generator loss: -0.4376, discriminator loss: -0.1946\n",
      "generator loss: -0.3650, discriminator loss: -0.2674\n",
      "wgan error: 3.0723\n",
      "generator loss: -0.5276, discriminator loss: -0.0763\n",
      "generator loss: -0.4343, discriminator loss: -0.1685\n",
      "generator loss: -0.4564, discriminator loss: -0.1450\n",
      "generator loss: -0.4445, discriminator loss: -0.1578\n",
      "generator loss: -0.4591, discriminator loss: -0.1431\n",
      "generator loss: -0.4916, discriminator loss: -0.1105\n",
      "generator loss: -0.4683, discriminator loss: -0.1330\n",
      "generator loss: -0.4991, discriminator loss: -0.0996\n",
      "generator loss: -0.4110, discriminator loss: -0.1884\n",
      "generator loss: -0.4226, discriminator loss: -0.1761\n",
      "wgan error: 2.4595\n",
      "generator loss: -0.0146, discriminator loss: -0.1462\n",
      "generator loss: 0.0305, discriminator loss: -0.1893\n",
      "generator loss: -0.0176, discriminator loss: -0.1395\n",
      "generator loss: 0.1213, discriminator loss: -0.2794\n",
      "generator loss: -0.0766, discriminator loss: -0.0831\n",
      "generator loss: -0.1267, discriminator loss: -0.0333\n",
      "generator loss: 0.0468, discriminator loss: -0.2086\n",
      "generator loss: -0.1045, discriminator loss: -0.0576\n",
      "generator loss: -0.0070, discriminator loss: -0.1535\n",
      "generator loss: -0.1251, discriminator loss: -0.0343\n",
      "wgan error: 3.6067\n",
      "generator loss: -0.5882, discriminator loss: -0.0972\n",
      "generator loss: -0.5494, discriminator loss: -0.1355\n",
      "generator loss: -0.4674, discriminator loss: -0.2168\n",
      "generator loss: -0.5414, discriminator loss: -0.1419\n",
      "generator loss: -0.5455, discriminator loss: -0.1406\n",
      "generator loss: -0.4612, discriminator loss: -0.2253\n",
      "generator loss: -0.5202, discriminator loss: -0.1671\n",
      "generator loss: -0.4455, discriminator loss: -0.2405\n",
      "generator loss: -0.5687, discriminator loss: -0.1191\n",
      "generator loss: -0.5388, discriminator loss: -0.1498\n",
      "wgan error: 3.7612\n",
      "generator loss: 0.4719, discriminator loss: -0.0870\n",
      "generator loss: 0.6255, discriminator loss: -0.2365\n",
      "generator loss: 0.4280, discriminator loss: -0.0402\n",
      "generator loss: 0.5415, discriminator loss: -0.1545\n",
      "generator loss: 0.5326, discriminator loss: -0.1462\n",
      "generator loss: 0.5332, discriminator loss: -0.1450\n",
      "generator loss: 0.5702, discriminator loss: -0.1810\n",
      "generator loss: 0.5521, discriminator loss: -0.1601\n",
      "generator loss: 0.5021, discriminator loss: -0.1108\n",
      "generator loss: 0.4459, discriminator loss: -0.0544\n",
      "wgan error: 2.9793\n",
      "generator loss: -0.5260, discriminator loss: -0.1726\n",
      "generator loss: -0.4822, discriminator loss: -0.2184\n",
      "generator loss: -0.5869, discriminator loss: -0.1160\n",
      "generator loss: -0.4826, discriminator loss: -0.2224\n",
      "generator loss: -0.5869, discriminator loss: -0.1188\n",
      "generator loss: -0.5639, discriminator loss: -0.1430\n",
      "generator loss: -0.5864, discriminator loss: -0.1199\n",
      "generator loss: -0.5974, discriminator loss: -0.1091\n",
      "generator loss: -0.4943, discriminator loss: -0.2151\n",
      "generator loss: -0.5401, discriminator loss: -0.1740\n",
      "wgan error: 2.3897\n",
      "generator loss: 0.4486, discriminator loss: -0.1113\n",
      "generator loss: 0.4286, discriminator loss: -0.0889\n",
      "generator loss: 0.4067, discriminator loss: -0.0670\n",
      "generator loss: 0.4139, discriminator loss: -0.0765\n",
      "generator loss: 0.4518, discriminator loss: -0.1144\n",
      "generator loss: 0.4474, discriminator loss: -0.1082\n",
      "generator loss: 0.5152, discriminator loss: -0.1752\n",
      "generator loss: 0.4392, discriminator loss: -0.0998\n",
      "generator loss: 0.4173, discriminator loss: -0.0774\n",
      "generator loss: 0.4502, discriminator loss: -0.1096\n",
      "wgan error: 2.9093\n",
      "generator loss: -0.4854, discriminator loss: -0.1424\n",
      "generator loss: -0.5900, discriminator loss: -0.0382\n",
      "generator loss: -0.4835, discriminator loss: -0.1456\n",
      "generator loss: -0.3775, discriminator loss: -0.2496\n",
      "generator loss: -0.6138, discriminator loss: -0.0130\n",
      "generator loss: -0.5353, discriminator loss: -0.0907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: -0.5004, discriminator loss: -0.1254\n",
      "generator loss: -0.4883, discriminator loss: -0.1360\n",
      "generator loss: -0.4659, discriminator loss: -0.1606\n",
      "generator loss: -0.5537, discriminator loss: -0.0741\n",
      "wgan error: 2.0250\n",
      "(100, 10, 'Gumbel') 28.0165\n",
      "(100, 10, 'Gumbel') 3.0510 0.6039\n",
      "N=100, p=10, model=Gumbel in done.(1.87 minutes)\n",
      "N=100, p=20, model=Cauchy in progress.\n",
      "sample cov error: 341.9525\n",
      "generator loss: -0.4290, discriminator loss: -0.1291\n",
      "generator loss: -0.3253, discriminator loss: -0.2285\n",
      "generator loss: -0.4429, discriminator loss: -0.1000\n",
      "generator loss: -0.4089, discriminator loss: -0.1251\n",
      "generator loss: -0.3499, discriminator loss: -0.1792\n",
      "generator loss: -0.4245, discriminator loss: -0.1048\n",
      "generator loss: -0.3996, discriminator loss: -0.1260\n",
      "generator loss: -0.3190, discriminator loss: -0.2050\n",
      "generator loss: -0.3593, discriminator loss: -0.1679\n",
      "generator loss: -0.3864, discriminator loss: -0.1345\n",
      "wgan error: 4.2819\n",
      "generator loss: -0.1915, discriminator loss: -0.2670\n",
      "generator loss: -0.2991, discriminator loss: -0.1578\n",
      "generator loss: -0.2921, discriminator loss: -0.1690\n",
      "generator loss: -0.2766, discriminator loss: -0.1817\n",
      "generator loss: -0.2754, discriminator loss: -0.1881\n",
      "generator loss: -0.4177, discriminator loss: -0.0423\n",
      "generator loss: -0.3412, discriminator loss: -0.1154\n",
      "generator loss: -0.3234, discriminator loss: -0.1376\n",
      "generator loss: -0.3202, discriminator loss: -0.1351\n",
      "generator loss: -0.2530, discriminator loss: -0.1995\n",
      "wgan error: 3.6101\n",
      "generator loss: -0.1254, discriminator loss: -0.2104\n",
      "generator loss: -0.1790, discriminator loss: -0.1527\n",
      "generator loss: -0.1385, discriminator loss: -0.1925\n",
      "generator loss: -0.1828, discriminator loss: -0.1436\n",
      "generator loss: -0.2138, discriminator loss: -0.1110\n",
      "generator loss: -0.1528, discriminator loss: -0.1774\n",
      "generator loss: -0.0979, discriminator loss: -0.2311\n",
      "generator loss: -0.1215, discriminator loss: -0.2075\n",
      "generator loss: -0.2160, discriminator loss: -0.1133\n",
      "generator loss: -0.1923, discriminator loss: -0.1368\n",
      "wgan error: 3.7029\n",
      "generator loss: 0.4576, discriminator loss: -0.1887\n",
      "generator loss: 0.4142, discriminator loss: -0.1458\n",
      "generator loss: 0.4236, discriminator loss: -0.1529\n",
      "generator loss: 0.4274, discriminator loss: -0.1529\n",
      "generator loss: 0.4193, discriminator loss: -0.1416\n",
      "generator loss: 0.4658, discriminator loss: -0.1909\n",
      "generator loss: 0.5366, discriminator loss: -0.2702\n",
      "generator loss: 0.4105, discriminator loss: -0.1345\n",
      "generator loss: 0.3416, discriminator loss: -0.0833\n",
      "generator loss: 0.4314, discriminator loss: -0.1813\n",
      "wgan error: 3.7065\n",
      "generator loss: -0.0635, discriminator loss: -0.2517\n",
      "generator loss: -0.1211, discriminator loss: -0.2023\n",
      "generator loss: -0.1696, discriminator loss: -0.1596\n",
      "generator loss: -0.0837, discriminator loss: -0.2449\n",
      "generator loss: -0.1237, discriminator loss: -0.2011\n",
      "generator loss: -0.1506, discriminator loss: -0.1818\n",
      "generator loss: -0.1311, discriminator loss: -0.2040\n",
      "generator loss: -0.1210, discriminator loss: -0.2135\n",
      "generator loss: -0.1291, discriminator loss: -0.2100\n",
      "generator loss: -0.1089, discriminator loss: -0.2296\n",
      "wgan error: 3.0034\n",
      "generator loss: 0.3759, discriminator loss: -0.2803\n",
      "generator loss: 0.3334, discriminator loss: -0.2410\n",
      "generator loss: 0.2940, discriminator loss: -0.2030\n",
      "generator loss: 0.3665, discriminator loss: -0.2699\n",
      "generator loss: 0.3311, discriminator loss: -0.2406\n",
      "generator loss: 0.3870, discriminator loss: -0.3016\n",
      "generator loss: 0.2919, discriminator loss: -0.2084\n",
      "generator loss: 0.3536, discriminator loss: -0.2657\n",
      "generator loss: 0.2880, discriminator loss: -0.2041\n",
      "generator loss: 0.3083, discriminator loss: -0.2222\n",
      "wgan error: 5.2400\n",
      "generator loss: -0.0528, discriminator loss: -0.0219\n",
      "generator loss: 0.0820, discriminator loss: -0.1559\n",
      "generator loss: 0.0497, discriminator loss: -0.1202\n",
      "generator loss: 0.0217, discriminator loss: -0.0961\n",
      "generator loss: 0.1152, discriminator loss: -0.1874\n",
      "generator loss: 0.1126, discriminator loss: -0.1818\n",
      "generator loss: 0.0916, discriminator loss: -0.1633\n",
      "generator loss: 0.1084, discriminator loss: -0.1815\n",
      "generator loss: 0.1030, discriminator loss: -0.1722\n",
      "generator loss: 0.0233, discriminator loss: -0.0913\n",
      "wgan error: 3.7075\n",
      "generator loss: 0.2609, discriminator loss: -0.1006\n",
      "generator loss: 0.3388, discriminator loss: -0.1769\n",
      "generator loss: 0.3371, discriminator loss: -0.1718\n",
      "generator loss: 0.3587, discriminator loss: -0.1930\n",
      "generator loss: 0.4017, discriminator loss: -0.2369\n",
      "generator loss: 0.2845, discriminator loss: -0.1213\n",
      "generator loss: 0.4161, discriminator loss: -0.2498\n",
      "generator loss: 0.3393, discriminator loss: -0.1723\n",
      "generator loss: 0.2814, discriminator loss: -0.1180\n",
      "generator loss: 0.3150, discriminator loss: -0.1513\n",
      "wgan error: 4.4291\n",
      "generator loss: 0.0678, discriminator loss: -0.1473\n",
      "generator loss: -0.0094, discriminator loss: -0.0637\n",
      "generator loss: 0.0272, discriminator loss: -0.1052\n",
      "generator loss: 0.1298, discriminator loss: -0.2032\n",
      "generator loss: 0.1039, discriminator loss: -0.1734\n",
      "generator loss: 0.1486, discriminator loss: -0.2218\n",
      "generator loss: 0.1081, discriminator loss: -0.1834\n",
      "generator loss: 0.1362, discriminator loss: -0.2144\n",
      "generator loss: 0.1516, discriminator loss: -0.2287\n",
      "generator loss: 0.1428, discriminator loss: -0.2209\n",
      "wgan error: 3.6731\n",
      "generator loss: 0.2208, discriminator loss: -0.1992\n",
      "generator loss: 0.2250, discriminator loss: -0.2037\n",
      "generator loss: 0.2340, discriminator loss: -0.2108\n",
      "generator loss: 0.2378, discriminator loss: -0.2171\n",
      "generator loss: 0.2954, discriminator loss: -0.2755\n",
      "generator loss: 0.2344, discriminator loss: -0.2140\n",
      "generator loss: 0.2172, discriminator loss: -0.1924\n",
      "generator loss: 0.1771, discriminator loss: -0.1563\n",
      "generator loss: 0.1603, discriminator loss: -0.1379\n",
      "generator loss: 0.2097, discriminator loss: -0.1916\n",
      "wgan error: 4.3782\n",
      "(100, 20, 'Cauchy') 341.9525\n",
      "(100, 20, 'Cauchy') 3.9733 0.5873\n",
      "N=100, p=20, model=Cauchy in done.(3.54 minutes)\n",
      "N=100, p=20, model=Normal in progress.\n",
      "sample cov error: 22.9557\n",
      "generator loss: 0.0973, discriminator loss: -0.3031\n",
      "generator loss: 0.1212, discriminator loss: -0.3274\n",
      "generator loss: -0.0375, discriminator loss: -0.1617\n",
      "generator loss: 0.1475, discriminator loss: -0.3502\n",
      "generator loss: -0.0296, discriminator loss: -0.1737\n",
      "generator loss: 0.0590, discriminator loss: -0.2636\n",
      "generator loss: 0.0161, discriminator loss: -0.2226\n",
      "generator loss: 0.0180, discriminator loss: -0.2253\n",
      "generator loss: 0.0709, discriminator loss: -0.2781\n",
      "generator loss: -0.0536, discriminator loss: -0.1530\n",
      "wgan error: 2.4603\n",
      "generator loss: 0.1852, discriminator loss: -0.1858\n",
      "generator loss: 0.3005, discriminator loss: -0.3014\n",
      "generator loss: 0.3667, discriminator loss: -0.3683\n",
      "generator loss: 0.2669, discriminator loss: -0.2682\n",
      "generator loss: 0.1295, discriminator loss: -0.1324\n",
      "generator loss: 0.2473, discriminator loss: -0.2513\n",
      "generator loss: 0.2619, discriminator loss: -0.2665\n",
      "generator loss: 0.1173, discriminator loss: -0.1218\n",
      "generator loss: 0.2432, discriminator loss: -0.2493\n",
      "generator loss: 0.3158, discriminator loss: -0.3211\n",
      "wgan error: 2.4203\n",
      "generator loss: -0.2033, discriminator loss: -0.1642\n",
      "generator loss: -0.1510, discriminator loss: -0.2176\n",
      "generator loss: -0.1061, discriminator loss: -0.2628\n",
      "generator loss: -0.1339, discriminator loss: -0.2357\n",
      "generator loss: -0.1221, discriminator loss: -0.2462\n",
      "generator loss: -0.2343, discriminator loss: -0.1357\n",
      "generator loss: -0.1587, discriminator loss: -0.2091\n",
      "generator loss: -0.1352, discriminator loss: -0.2348\n",
      "generator loss: -0.1482, discriminator loss: -0.2217\n",
      "generator loss: -0.2663, discriminator loss: -0.1030\n",
      "wgan error: 3.0823\n",
      "generator loss: -0.1699, discriminator loss: -0.2002\n",
      "generator loss: -0.1098, discriminator loss: -0.2581\n",
      "generator loss: -0.0765, discriminator loss: -0.2914\n",
      "generator loss: -0.1389, discriminator loss: -0.2266\n",
      "generator loss: -0.0652, discriminator loss: -0.3020\n",
      "generator loss: -0.1835, discriminator loss: -0.1834\n",
      "generator loss: -0.0409, discriminator loss: -0.3290\n",
      "generator loss: -0.1852, discriminator loss: -0.1842\n",
      "generator loss: -0.1051, discriminator loss: -0.2622\n",
      "generator loss: -0.1393, discriminator loss: -0.2295\n",
      "wgan error: 4.0905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: -0.3134, discriminator loss: -0.2674\n",
      "generator loss: -0.3177, discriminator loss: -0.2625\n",
      "generator loss: -0.3058, discriminator loss: -0.2721\n",
      "generator loss: -0.4186, discriminator loss: -0.1608\n",
      "generator loss: -0.3327, discriminator loss: -0.2458\n",
      "generator loss: -0.3945, discriminator loss: -0.1821\n",
      "generator loss: -0.3483, discriminator loss: -0.2300\n",
      "generator loss: -0.2419, discriminator loss: -0.3350\n",
      "generator loss: -0.3226, discriminator loss: -0.2530\n",
      "generator loss: -0.2960, discriminator loss: -0.2803\n",
      "wgan error: 3.6862\n",
      "generator loss: -0.3700, discriminator loss: -0.2172\n",
      "generator loss: -0.4600, discriminator loss: -0.1270\n",
      "generator loss: -0.3685, discriminator loss: -0.2165\n",
      "generator loss: -0.3414, discriminator loss: -0.2449\n",
      "generator loss: -0.5236, discriminator loss: -0.0624\n",
      "generator loss: -0.4549, discriminator loss: -0.1335\n",
      "generator loss: -0.3328, discriminator loss: -0.2548\n",
      "generator loss: -0.3239, discriminator loss: -0.2620\n",
      "generator loss: -0.3561, discriminator loss: -0.2291\n",
      "generator loss: -0.2762, discriminator loss: -0.3082\n",
      "wgan error: 2.7644\n",
      "generator loss: -0.2146, discriminator loss: -0.2135\n",
      "generator loss: -0.2761, discriminator loss: -0.1552\n",
      "generator loss: -0.2183, discriminator loss: -0.2102\n",
      "generator loss: -0.2704, discriminator loss: -0.1564\n",
      "generator loss: -0.1978, discriminator loss: -0.2284\n",
      "generator loss: -0.2328, discriminator loss: -0.1906\n",
      "generator loss: -0.1694, discriminator loss: -0.2561\n",
      "generator loss: -0.2009, discriminator loss: -0.2243\n",
      "generator loss: -0.1807, discriminator loss: -0.2411\n",
      "generator loss: -0.2573, discriminator loss: -0.1613\n",
      "wgan error: 2.5772\n",
      "generator loss: 0.2685, discriminator loss: -0.2104\n",
      "generator loss: 0.3871, discriminator loss: -0.3280\n",
      "generator loss: 0.1730, discriminator loss: -0.1170\n",
      "generator loss: 0.3522, discriminator loss: -0.2965\n",
      "generator loss: 0.2141, discriminator loss: -0.1558\n",
      "generator loss: 0.3298, discriminator loss: -0.2742\n",
      "generator loss: 0.2802, discriminator loss: -0.2260\n",
      "generator loss: 0.3067, discriminator loss: -0.2485\n",
      "generator loss: 0.3869, discriminator loss: -0.3301\n",
      "generator loss: 0.2909, discriminator loss: -0.2356\n",
      "wgan error: 2.8629\n",
      "generator loss: -0.1927, discriminator loss: -0.3278\n",
      "generator loss: -0.3019, discriminator loss: -0.2193\n",
      "generator loss: -0.2431, discriminator loss: -0.2782\n",
      "generator loss: -0.3485, discriminator loss: -0.1740\n",
      "generator loss: -0.3739, discriminator loss: -0.1461\n",
      "generator loss: -0.2786, discriminator loss: -0.2431\n",
      "generator loss: -0.4154, discriminator loss: -0.1076\n",
      "generator loss: -0.2542, discriminator loss: -0.2678\n",
      "generator loss: -0.2260, discriminator loss: -0.2956\n",
      "generator loss: -0.3358, discriminator loss: -0.1852\n",
      "wgan error: 3.0068\n",
      "generator loss: -0.2280, discriminator loss: -0.2031\n",
      "generator loss: -0.1027, discriminator loss: -0.3292\n",
      "generator loss: -0.2955, discriminator loss: -0.1406\n",
      "generator loss: -0.1409, discriminator loss: -0.2971\n",
      "generator loss: -0.1535, discriminator loss: -0.2876\n",
      "generator loss: -0.2134, discriminator loss: -0.2294\n",
      "generator loss: -0.2012, discriminator loss: -0.2427\n",
      "generator loss: -0.2390, discriminator loss: -0.2045\n",
      "generator loss: -0.1735, discriminator loss: -0.2707\n",
      "generator loss: -0.2153, discriminator loss: -0.2314\n",
      "wgan error: 3.7741\n",
      "(100, 20, 'Normal') 22.9557\n",
      "(100, 20, 'Normal') 3.0725 0.5562\n",
      "N=100, p=20, model=Normal in done.(3.58 minutes)\n",
      "N=100, p=20, model=Gumbel in progress.\n",
      "sample cov error: 43.0277\n",
      "generator loss: -0.1661, discriminator loss: -0.2093\n",
      "generator loss: 0.0248, discriminator loss: -0.3997\n",
      "generator loss: -0.2079, discriminator loss: -0.1674\n",
      "generator loss: -0.0274, discriminator loss: -0.3478\n",
      "generator loss: -0.1467, discriminator loss: -0.2295\n",
      "generator loss: -0.1046, discriminator loss: -0.2703\n",
      "generator loss: -0.1695, discriminator loss: -0.2037\n",
      "generator loss: -0.1151, discriminator loss: -0.2581\n",
      "generator loss: -0.1440, discriminator loss: -0.2304\n",
      "generator loss: -0.2114, discriminator loss: -0.1611\n",
      "wgan error: 3.2551\n",
      "generator loss: -0.2817, discriminator loss: -0.2543\n",
      "generator loss: -0.1694, discriminator loss: -0.3655\n",
      "generator loss: -0.1706, discriminator loss: -0.3615\n",
      "generator loss: -0.3585, discriminator loss: -0.1724\n",
      "generator loss: -0.3107, discriminator loss: -0.2219\n",
      "generator loss: -0.3450, discriminator loss: -0.1905\n",
      "generator loss: -0.2353, discriminator loss: -0.3006\n",
      "generator loss: -0.1790, discriminator loss: -0.3580\n",
      "generator loss: -0.3087, discriminator loss: -0.2278\n",
      "generator loss: -0.3232, discriminator loss: -0.2155\n",
      "wgan error: 4.5101\n",
      "generator loss: -0.2484, discriminator loss: -0.3165\n",
      "generator loss: -0.4628, discriminator loss: -0.1028\n",
      "generator loss: -0.3262, discriminator loss: -0.2392\n",
      "generator loss: -0.1963, discriminator loss: -0.3700\n",
      "generator loss: -0.2716, discriminator loss: -0.2943\n",
      "generator loss: -0.1398, discriminator loss: -0.4268\n",
      "generator loss: -0.3888, discriminator loss: -0.1755\n",
      "generator loss: -0.3472, discriminator loss: -0.2176\n",
      "generator loss: -0.3623, discriminator loss: -0.2027\n",
      "generator loss: -0.2478, discriminator loss: -0.3193\n",
      "wgan error: 4.2597\n",
      "generator loss: 0.1211, discriminator loss: -0.2718\n",
      "generator loss: 0.1068, discriminator loss: -0.2570\n",
      "generator loss: 0.0798, discriminator loss: -0.2303\n",
      "generator loss: 0.0373, discriminator loss: -0.1893\n",
      "generator loss: 0.1280, discriminator loss: -0.2814\n",
      "generator loss: 0.1271, discriminator loss: -0.2792\n",
      "generator loss: 0.0662, discriminator loss: -0.2177\n",
      "generator loss: 0.1558, discriminator loss: -0.3063\n",
      "generator loss: 0.1214, discriminator loss: -0.2690\n",
      "generator loss: 0.1566, discriminator loss: -0.3068\n",
      "wgan error: 3.3031\n",
      "generator loss: -0.3395, discriminator loss: -0.1884\n",
      "generator loss: -0.2862, discriminator loss: -0.2426\n",
      "generator loss: -0.2364, discriminator loss: -0.2925\n",
      "generator loss: -0.3558, discriminator loss: -0.1749\n",
      "generator loss: -0.3299, discriminator loss: -0.2013\n",
      "generator loss: -0.2496, discriminator loss: -0.2813\n",
      "generator loss: -0.2733, discriminator loss: -0.2581\n",
      "generator loss: -0.3096, discriminator loss: -0.2223\n",
      "generator loss: -0.3763, discriminator loss: -0.1564\n",
      "generator loss: -0.1719, discriminator loss: -0.3592\n",
      "wgan error: 4.7057\n",
      "generator loss: -0.5198, discriminator loss: -0.2440\n",
      "generator loss: -0.4398, discriminator loss: -0.3240\n",
      "generator loss: -0.3883, discriminator loss: -0.3761\n",
      "generator loss: -0.5666, discriminator loss: -0.1978\n",
      "generator loss: -0.4865, discriminator loss: -0.2785\n",
      "generator loss: -0.4868, discriminator loss: -0.2777\n",
      "generator loss: -0.4386, discriminator loss: -0.3267\n",
      "generator loss: -0.3868, discriminator loss: -0.3805\n",
      "generator loss: -0.5704, discriminator loss: -0.1968\n",
      "generator loss: -0.4174, discriminator loss: -0.3515\n",
      "wgan error: 5.4399\n",
      "generator loss: 0.0913, discriminator loss: -0.2318\n",
      "generator loss: 0.1673, discriminator loss: -0.3088\n",
      "generator loss: 0.0959, discriminator loss: -0.2399\n",
      "generator loss: 0.0554, discriminator loss: -0.2003\n",
      "generator loss: 0.0321, discriminator loss: -0.1790\n",
      "generator loss: 0.1151, discriminator loss: -0.2615\n",
      "generator loss: 0.1235, discriminator loss: -0.2701\n",
      "generator loss: -0.0144, discriminator loss: -0.1326\n",
      "generator loss: 0.0029, discriminator loss: -0.1510\n",
      "generator loss: 0.1171, discriminator loss: -0.2644\n",
      "wgan error: 5.0747\n",
      "generator loss: 0.0423, discriminator loss: -0.3160\n",
      "generator loss: 0.0944, discriminator loss: -0.3693\n",
      "generator loss: -0.0906, discriminator loss: -0.1836\n",
      "generator loss: 0.0128, discriminator loss: -0.2861\n",
      "generator loss: -0.0860, discriminator loss: -0.1879\n",
      "generator loss: 0.0328, discriminator loss: -0.3056\n",
      "generator loss: 0.0233, discriminator loss: -0.2965\n",
      "generator loss: -0.0225, discriminator loss: -0.2493\n",
      "generator loss: 0.0060, discriminator loss: -0.2758\n",
      "generator loss: -0.0245, discriminator loss: -0.2476\n",
      "wgan error: 4.7015\n",
      "generator loss: -0.0553, discriminator loss: -0.2303\n",
      "generator loss: -0.0563, discriminator loss: -0.2278\n",
      "generator loss: -0.1146, discriminator loss: -0.1649\n",
      "generator loss: -0.1889, discriminator loss: -0.0932\n",
      "generator loss: -0.0452, discriminator loss: -0.2296\n",
      "generator loss: -0.0400, discriminator loss: -0.2330\n",
      "generator loss: -0.0709, discriminator loss: -0.2018\n",
      "generator loss: -0.0137, discriminator loss: -0.2612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: -0.1030, discriminator loss: -0.1713\n",
      "generator loss: 0.1027, discriminator loss: -0.3746\n",
      "wgan error: 4.2796\n",
      "generator loss: 0.0316, discriminator loss: -0.2881\n",
      "generator loss: 0.0906, discriminator loss: -0.3470\n",
      "generator loss: 0.0578, discriminator loss: -0.3138\n",
      "generator loss: 0.0476, discriminator loss: -0.3021\n",
      "generator loss: -0.0994, discriminator loss: -0.1586\n",
      "generator loss: -0.0090, discriminator loss: -0.2522\n",
      "generator loss: -0.1147, discriminator loss: -0.1447\n",
      "generator loss: -0.0194, discriminator loss: -0.2366\n",
      "generator loss: 0.0437, discriminator loss: -0.2989\n",
      "generator loss: 0.0642, discriminator loss: -0.3191\n",
      "wgan error: 4.6759\n",
      "(100, 20, 'Gumbel') 43.0277\n",
      "(100, 20, 'Gumbel') 4.4205 0.6598\n",
      "N=100, p=20, model=Gumbel in done.(3.58 minutes)\n",
      "N=100, p=40, model=Cauchy in progress.\n",
      "sample cov error: 1992.2081\n",
      "generator loss: -0.3383, discriminator loss: -0.3270\n",
      "generator loss: -0.3670, discriminator loss: -0.2989\n",
      "generator loss: -0.4054, discriminator loss: -0.2618\n",
      "generator loss: -0.4061, discriminator loss: -0.2617\n",
      "generator loss: -0.3405, discriminator loss: -0.3283\n",
      "generator loss: -0.3499, discriminator loss: -0.3185\n",
      "generator loss: -0.3434, discriminator loss: -0.3245\n",
      "generator loss: -0.3620, discriminator loss: -0.3067\n",
      "generator loss: -0.3377, discriminator loss: -0.3322\n",
      "generator loss: -0.4924, discriminator loss: -0.1769\n",
      "wgan error: 6.3063\n",
      "generator loss: -0.2441, discriminator loss: -0.2219\n",
      "generator loss: -0.1904, discriminator loss: -0.2761\n",
      "generator loss: -0.1345, discriminator loss: -0.3390\n",
      "generator loss: -0.2219, discriminator loss: -0.2520\n",
      "generator loss: -0.1196, discriminator loss: -0.3540\n",
      "generator loss: -0.1206, discriminator loss: -0.3489\n",
      "generator loss: -0.2285, discriminator loss: -0.2422\n",
      "generator loss: -0.0891, discriminator loss: -0.3770\n",
      "generator loss: -0.2852, discriminator loss: -0.1807\n",
      "generator loss: -0.0680, discriminator loss: -0.3983\n",
      "wgan error: 7.2623\n",
      "generator loss: -0.2151, discriminator loss: -0.2878\n",
      "generator loss: -0.2260, discriminator loss: -0.2750\n",
      "generator loss: -0.2263, discriminator loss: -0.2805\n",
      "generator loss: -0.1510, discriminator loss: -0.3564\n",
      "generator loss: -0.1837, discriminator loss: -0.3175\n",
      "generator loss: -0.3197, discriminator loss: -0.1841\n",
      "generator loss: -0.1392, discriminator loss: -0.3639\n",
      "generator loss: -0.2595, discriminator loss: -0.2448\n",
      "generator loss: -0.2003, discriminator loss: -0.3049\n",
      "generator loss: -0.1397, discriminator loss: -0.3676\n",
      "wgan error: 6.5293\n",
      "generator loss: -0.2545, discriminator loss: -0.2316\n",
      "generator loss: -0.1666, discriminator loss: -0.3202\n",
      "generator loss: -0.2734, discriminator loss: -0.2147\n",
      "generator loss: -0.2530, discriminator loss: -0.2352\n",
      "generator loss: -0.2425, discriminator loss: -0.2455\n",
      "generator loss: -0.1393, discriminator loss: -0.3483\n",
      "generator loss: -0.2140, discriminator loss: -0.2727\n",
      "generator loss: -0.2060, discriminator loss: -0.2819\n",
      "generator loss: -0.1102, discriminator loss: -0.3785\n",
      "generator loss: -0.1455, discriminator loss: -0.3423\n",
      "wgan error: 5.0154\n",
      "generator loss: -0.2548, discriminator loss: -0.1974\n",
      "generator loss: -0.2200, discriminator loss: -0.2328\n",
      "generator loss: -0.2186, discriminator loss: -0.2384\n",
      "generator loss: -0.0248, discriminator loss: -0.4336\n",
      "generator loss: -0.1538, discriminator loss: -0.3040\n",
      "generator loss: -0.2174, discriminator loss: -0.2465\n",
      "generator loss: -0.0435, discriminator loss: -0.4177\n",
      "generator loss: -0.1821, discriminator loss: -0.2816\n",
      "generator loss: -0.1219, discriminator loss: -0.3347\n",
      "generator loss: -0.2305, discriminator loss: -0.2284\n",
      "wgan error: 6.0365\n",
      "generator loss: -0.1406, discriminator loss: -0.2508\n",
      "generator loss: -0.0389, discriminator loss: -0.3532\n",
      "generator loss: -0.2222, discriminator loss: -0.1714\n",
      "generator loss: -0.0452, discriminator loss: -0.3477\n",
      "generator loss: -0.1744, discriminator loss: -0.2229\n",
      "generator loss: -0.0748, discriminator loss: -0.3218\n",
      "generator loss: -0.0115, discriminator loss: -0.3834\n",
      "generator loss: -0.0040, discriminator loss: -0.3913\n",
      "generator loss: -0.0100, discriminator loss: -0.3872\n",
      "generator loss: -0.2419, discriminator loss: -0.1514\n",
      "wgan error: 5.1121\n",
      "generator loss: -0.2496, discriminator loss: -0.3238\n",
      "generator loss: -0.3196, discriminator loss: -0.2566\n",
      "generator loss: -0.2896, discriminator loss: -0.2881\n",
      "generator loss: -0.2957, discriminator loss: -0.2712\n",
      "generator loss: -0.2504, discriminator loss: -0.3177\n",
      "generator loss: -0.3687, discriminator loss: -0.2016\n",
      "generator loss: -0.2221, discriminator loss: -0.3499\n",
      "generator loss: -0.3373, discriminator loss: -0.2364\n",
      "generator loss: -0.4427, discriminator loss: -0.1275\n",
      "generator loss: -0.2760, discriminator loss: -0.2919\n",
      "wgan error: 6.6793\n",
      "generator loss: -0.0633, discriminator loss: -0.2603\n",
      "generator loss: 0.0526, discriminator loss: -0.3790\n",
      "generator loss: -0.0241, discriminator loss: -0.2971\n",
      "generator loss: 0.0184, discriminator loss: -0.3410\n",
      "generator loss: -0.0065, discriminator loss: -0.3124\n",
      "generator loss: -0.0315, discriminator loss: -0.2861\n",
      "generator loss: 0.0074, discriminator loss: -0.3197\n",
      "generator loss: 0.0743, discriminator loss: -0.3874\n",
      "generator loss: -0.1434, discriminator loss: -0.1755\n",
      "generator loss: -0.0991, discriminator loss: -0.2225\n",
      "wgan error: 6.2029\n",
      "generator loss: -0.3676, discriminator loss: -0.1487\n",
      "generator loss: -0.2635, discriminator loss: -0.2546\n",
      "generator loss: -0.3563, discriminator loss: -0.1658\n",
      "generator loss: -0.0351, discriminator loss: -0.4800\n",
      "generator loss: -0.1370, discriminator loss: -0.3772\n",
      "generator loss: -0.2046, discriminator loss: -0.3145\n",
      "generator loss: -0.1728, discriminator loss: -0.3447\n",
      "generator loss: -0.0748, discriminator loss: -0.4454\n",
      "generator loss: -0.2115, discriminator loss: -0.3084\n",
      "generator loss: -0.3286, discriminator loss: -0.1948\n",
      "wgan error: 5.0925\n",
      "generator loss: -0.0406, discriminator loss: -0.3486\n",
      "generator loss: -0.0277, discriminator loss: -0.3618\n",
      "generator loss: -0.0558, discriminator loss: -0.3328\n",
      "generator loss: -0.1369, discriminator loss: -0.2527\n",
      "generator loss: -0.0632, discriminator loss: -0.3283\n",
      "generator loss: -0.0025, discriminator loss: -0.3880\n",
      "generator loss: -0.1900, discriminator loss: -0.2003\n",
      "generator loss: -0.1195, discriminator loss: -0.2686\n",
      "generator loss: -0.1662, discriminator loss: -0.2234\n",
      "generator loss: -0.1520, discriminator loss: -0.2379\n",
      "wgan error: 6.0623\n",
      "(100, 40, 'Cauchy') 1992.2081\n",
      "(100, 40, 'Cauchy') 6.0299 0.7105\n",
      "N=100, p=40, model=Cauchy in done.(3.58 minutes)\n",
      "N=100, p=40, model=Normal in progress.\n",
      "sample cov error: 82.7338\n",
      "generator loss: -0.4606, discriminator loss: -0.2325\n",
      "generator loss: -0.4382, discriminator loss: -0.2565\n",
      "generator loss: -0.3579, discriminator loss: -0.3387\n",
      "generator loss: -0.4802, discriminator loss: -0.2171\n",
      "generator loss: -0.4480, discriminator loss: -0.2511\n",
      "generator loss: -0.3911, discriminator loss: -0.3084\n",
      "generator loss: -0.5645, discriminator loss: -0.1345\n",
      "generator loss: -0.2973, discriminator loss: -0.4007\n",
      "generator loss: -0.2994, discriminator loss: -0.3988\n",
      "generator loss: -0.3570, discriminator loss: -0.3416\n",
      "wgan error: 6.3781\n",
      "generator loss: -0.0313, discriminator loss: -0.3665\n",
      "generator loss: -0.0962, discriminator loss: -0.3013\n",
      "generator loss: -0.0160, discriminator loss: -0.3824\n",
      "generator loss: -0.1581, discriminator loss: -0.2422\n",
      "generator loss: -0.0948, discriminator loss: -0.3056\n",
      "generator loss: -0.1240, discriminator loss: -0.2765\n",
      "generator loss: -0.0101, discriminator loss: -0.3898\n",
      "generator loss: -0.0876, discriminator loss: -0.3114\n",
      "generator loss: -0.0926, discriminator loss: -0.3066\n",
      "generator loss: -0.0670, discriminator loss: -0.3337\n",
      "wgan error: 5.0064\n",
      "generator loss: 0.0291, discriminator loss: -0.2246\n",
      "generator loss: 0.1758, discriminator loss: -0.3723\n",
      "generator loss: -0.0039, discriminator loss: -0.1946\n",
      "generator loss: 0.1162, discriminator loss: -0.3154\n",
      "generator loss: 0.0924, discriminator loss: -0.2918\n",
      "generator loss: 0.1927, discriminator loss: -0.3905\n",
      "generator loss: 0.0872, discriminator loss: -0.2852\n",
      "generator loss: 0.0997, discriminator loss: -0.2978\n",
      "generator loss: -0.0781, discriminator loss: -0.1207\n",
      "generator loss: 0.0885, discriminator loss: -0.2875\n",
      "wgan error: 5.3826\n",
      "generator loss: -0.2527, discriminator loss: -0.2533\n",
      "generator loss: -0.1920, discriminator loss: -0.3145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: -0.3007, discriminator loss: -0.2051\n",
      "generator loss: -0.2225, discriminator loss: -0.2848\n",
      "generator loss: -0.1202, discriminator loss: -0.3884\n",
      "generator loss: -0.1474, discriminator loss: -0.3604\n",
      "generator loss: -0.1563, discriminator loss: -0.3508\n",
      "generator loss: -0.1875, discriminator loss: -0.3209\n",
      "generator loss: -0.2645, discriminator loss: -0.2461\n",
      "generator loss: -0.1391, discriminator loss: -0.3723\n",
      "wgan error: 6.8349\n",
      "generator loss: 0.4968, discriminator loss: -0.3007\n",
      "generator loss: 0.5292, discriminator loss: -0.3325\n",
      "generator loss: 0.5146, discriminator loss: -0.3186\n",
      "generator loss: 0.4119, discriminator loss: -0.2142\n",
      "generator loss: 0.5706, discriminator loss: -0.3729\n",
      "generator loss: 0.5258, discriminator loss: -0.3274\n",
      "generator loss: 0.5068, discriminator loss: -0.3075\n",
      "generator loss: 0.6295, discriminator loss: -0.4327\n",
      "generator loss: 0.6602, discriminator loss: -0.4651\n",
      "generator loss: 0.4985, discriminator loss: -0.3060\n",
      "wgan error: 4.5639\n",
      "generator loss: 0.0589, discriminator loss: -0.2064\n",
      "generator loss: 0.1447, discriminator loss: -0.2930\n",
      "generator loss: 0.0783, discriminator loss: -0.2303\n",
      "generator loss: 0.0662, discriminator loss: -0.2198\n",
      "generator loss: 0.2167, discriminator loss: -0.3682\n",
      "generator loss: -0.0080, discriminator loss: -0.1407\n",
      "generator loss: 0.0556, discriminator loss: -0.2053\n",
      "generator loss: 0.2150, discriminator loss: -0.3656\n",
      "generator loss: 0.2060, discriminator loss: -0.3572\n",
      "generator loss: 0.1781, discriminator loss: -0.3299\n",
      "wgan error: 5.0668\n",
      "generator loss: -0.2547, discriminator loss: -0.2835\n",
      "generator loss: -0.3382, discriminator loss: -0.2014\n",
      "generator loss: -0.2339, discriminator loss: -0.3053\n",
      "generator loss: -0.3266, discriminator loss: -0.2101\n",
      "generator loss: -0.2271, discriminator loss: -0.3106\n",
      "generator loss: -0.1745, discriminator loss: -0.3671\n",
      "generator loss: -0.2634, discriminator loss: -0.2763\n",
      "generator loss: -0.3317, discriminator loss: -0.2096\n",
      "generator loss: -0.2080, discriminator loss: -0.3376\n",
      "generator loss: -0.2780, discriminator loss: -0.2697\n",
      "wgan error: 6.6826\n",
      "generator loss: 0.1582, discriminator loss: -0.2887\n",
      "generator loss: 0.3322, discriminator loss: -0.4611\n",
      "generator loss: 0.1916, discriminator loss: -0.3203\n",
      "generator loss: 0.2234, discriminator loss: -0.3510\n",
      "generator loss: 0.1526, discriminator loss: -0.2820\n",
      "generator loss: 0.2237, discriminator loss: -0.3537\n",
      "generator loss: 0.2457, discriminator loss: -0.3786\n",
      "generator loss: 0.1703, discriminator loss: -0.3032\n",
      "generator loss: 0.0686, discriminator loss: -0.2008\n",
      "generator loss: 0.1102, discriminator loss: -0.2402\n",
      "wgan error: 5.3075\n",
      "generator loss: 0.0528, discriminator loss: -0.3270\n",
      "generator loss: -0.0326, discriminator loss: -0.2423\n",
      "generator loss: 0.0169, discriminator loss: -0.2880\n",
      "generator loss: -0.0812, discriminator loss: -0.1894\n",
      "generator loss: 0.1029, discriminator loss: -0.3754\n",
      "generator loss: 0.1282, discriminator loss: -0.4005\n",
      "generator loss: 0.0406, discriminator loss: -0.3138\n",
      "generator loss: -0.0684, discriminator loss: -0.2040\n",
      "generator loss: 0.0656, discriminator loss: -0.3395\n",
      "generator loss: 0.0613, discriminator loss: -0.3362\n",
      "wgan error: 5.7215\n",
      "generator loss: -0.0369, discriminator loss: -0.2984\n",
      "generator loss: -0.0367, discriminator loss: -0.2958\n",
      "generator loss: 0.0743, discriminator loss: -0.4060\n",
      "generator loss: -0.1158, discriminator loss: -0.2184\n",
      "generator loss: -0.0887, discriminator loss: -0.2468\n",
      "generator loss: -0.0130, discriminator loss: -0.3228\n",
      "generator loss: -0.0056, discriminator loss: -0.3286\n",
      "generator loss: -0.0247, discriminator loss: -0.3101\n",
      "generator loss: -0.0356, discriminator loss: -0.3011\n",
      "generator loss: -0.0691, discriminator loss: -0.2678\n",
      "wgan error: 4.4994\n",
      "(100, 40, 'Normal') 82.7338\n",
      "(100, 40, 'Normal') 5.5444 0.7963\n",
      "N=100, p=40, model=Normal in done.(3.54 minutes)\n",
      "N=100, p=40, model=Gumbel in progress.\n",
      "sample cov error: 62.7293\n",
      "generator loss: 0.3455, discriminator loss: -0.3715\n",
      "generator loss: 0.2313, discriminator loss: -0.2585\n",
      "generator loss: 0.2003, discriminator loss: -0.2267\n",
      "generator loss: 0.3250, discriminator loss: -0.3539\n",
      "generator loss: 0.1932, discriminator loss: -0.2237\n",
      "generator loss: 0.4243, discriminator loss: -0.4547\n",
      "generator loss: 0.2689, discriminator loss: -0.2990\n",
      "generator loss: 0.2478, discriminator loss: -0.2799\n",
      "generator loss: 0.2378, discriminator loss: -0.2695\n",
      "generator loss: 0.2326, discriminator loss: -0.2661\n",
      "wgan error: 5.1915\n",
      "generator loss: -0.0708, discriminator loss: -0.2429\n",
      "generator loss: 0.1261, discriminator loss: -0.4417\n",
      "generator loss: 0.0617, discriminator loss: -0.3794\n",
      "generator loss: -0.0178, discriminator loss: -0.2977\n",
      "generator loss: 0.0043, discriminator loss: -0.3241\n",
      "generator loss: -0.0723, discriminator loss: -0.2499\n",
      "generator loss: -0.0818, discriminator loss: -0.2363\n",
      "generator loss: -0.1252, discriminator loss: -0.1897\n",
      "generator loss: 0.0634, discriminator loss: -0.3779\n",
      "generator loss: -0.2004, discriminator loss: -0.1175\n",
      "wgan error: 5.8466\n",
      "generator loss: 0.1144, discriminator loss: -0.1717\n",
      "generator loss: 0.3417, discriminator loss: -0.3988\n",
      "generator loss: 0.2532, discriminator loss: -0.3109\n",
      "generator loss: 0.2883, discriminator loss: -0.3464\n",
      "generator loss: 0.3476, discriminator loss: -0.4065\n",
      "generator loss: 0.1805, discriminator loss: -0.2398\n",
      "generator loss: 0.3830, discriminator loss: -0.4423\n",
      "generator loss: 0.2675, discriminator loss: -0.3278\n",
      "generator loss: 0.2679, discriminator loss: -0.3293\n",
      "generator loss: 0.2438, discriminator loss: -0.3053\n",
      "wgan error: 6.5993\n",
      "generator loss: -0.3823, discriminator loss: -0.3029\n",
      "generator loss: -0.3364, discriminator loss: -0.3475\n",
      "generator loss: -0.3827, discriminator loss: -0.3031\n",
      "generator loss: -0.3373, discriminator loss: -0.3491\n",
      "generator loss: -0.3098, discriminator loss: -0.3707\n",
      "generator loss: -0.2459, discriminator loss: -0.4292\n",
      "generator loss: -0.3631, discriminator loss: -0.3116\n",
      "generator loss: -0.4124, discriminator loss: -0.2636\n",
      "generator loss: -0.3400, discriminator loss: -0.3359\n",
      "generator loss: -0.4950, discriminator loss: -0.1827\n",
      "wgan error: 4.2015\n",
      "generator loss: -0.2049, discriminator loss: -0.2835\n",
      "generator loss: -0.2099, discriminator loss: -0.2792\n",
      "generator loss: -0.3270, discriminator loss: -0.1620\n",
      "generator loss: -0.1264, discriminator loss: -0.3623\n",
      "generator loss: -0.1914, discriminator loss: -0.2956\n",
      "generator loss: -0.1419, discriminator loss: -0.3464\n",
      "generator loss: -0.3124, discriminator loss: -0.1762\n",
      "generator loss: -0.2565, discriminator loss: -0.2327\n",
      "generator loss: -0.2341, discriminator loss: -0.2571\n",
      "generator loss: -0.3301, discriminator loss: -0.1631\n",
      "wgan error: 4.9172\n",
      "generator loss: -0.0735, discriminator loss: -0.1696\n",
      "generator loss: -0.0037, discriminator loss: -0.2379\n",
      "generator loss: 0.0135, discriminator loss: -0.2569\n",
      "generator loss: -0.0397, discriminator loss: -0.2019\n",
      "generator loss: 0.1416, discriminator loss: -0.3841\n",
      "generator loss: 0.1591, discriminator loss: -0.4001\n",
      "generator loss: -0.0390, discriminator loss: -0.2019\n",
      "generator loss: 0.0701, discriminator loss: -0.3114\n",
      "generator loss: 0.0392, discriminator loss: -0.2831\n",
      "generator loss: 0.0299, discriminator loss: -0.2762\n",
      "wgan error: 5.1507\n",
      "generator loss: -0.0498, discriminator loss: -0.2659\n",
      "generator loss: -0.0006, discriminator loss: -0.3166\n",
      "generator loss: -0.0537, discriminator loss: -0.2646\n",
      "generator loss: -0.0518, discriminator loss: -0.2682\n",
      "generator loss: 0.0409, discriminator loss: -0.3600\n",
      "generator loss: -0.0608, discriminator loss: -0.2590\n",
      "generator loss: -0.0145, discriminator loss: -0.3045\n",
      "generator loss: -0.0418, discriminator loss: -0.2775\n",
      "generator loss: -0.0156, discriminator loss: -0.3046\n",
      "generator loss: -0.1639, discriminator loss: -0.1582\n",
      "wgan error: 6.6232\n",
      "generator loss: -0.0575, discriminator loss: -0.3584\n",
      "generator loss: -0.1048, discriminator loss: -0.3108\n",
      "generator loss: -0.1965, discriminator loss: -0.2209\n",
      "generator loss: -0.2449, discriminator loss: -0.1710\n",
      "generator loss: -0.1271, discriminator loss: -0.2884\n",
      "generator loss: -0.0972, discriminator loss: -0.3209\n",
      "generator loss: -0.1287, discriminator loss: -0.2892\n",
      "generator loss: -0.0463, discriminator loss: -0.3718\n",
      "generator loss: -0.0857, discriminator loss: -0.3348\n",
      "generator loss: -0.2236, discriminator loss: -0.1971\n",
      "wgan error: 4.4809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: 0.0347, discriminator loss: -0.2160\n",
      "generator loss: -0.0084, discriminator loss: -0.1735\n",
      "generator loss: 0.2470, discriminator loss: -0.4299\n",
      "generator loss: 0.0573, discriminator loss: -0.2434\n",
      "generator loss: 0.0892, discriminator loss: -0.2749\n",
      "generator loss: -0.0885, discriminator loss: -0.0981\n",
      "generator loss: 0.0642, discriminator loss: -0.2522\n",
      "generator loss: 0.1772, discriminator loss: -0.3655\n",
      "generator loss: 0.1010, discriminator loss: -0.2894\n",
      "generator loss: 0.0721, discriminator loss: -0.2608\n",
      "wgan error: 6.5970\n",
      "generator loss: -0.0071, discriminator loss: -0.3116\n",
      "generator loss: 0.0855, discriminator loss: -0.4036\n",
      "generator loss: -0.0510, discriminator loss: -0.2661\n",
      "generator loss: -0.0185, discriminator loss: -0.2981\n",
      "generator loss: 0.0854, discriminator loss: -0.4036\n",
      "generator loss: 0.0182, discriminator loss: -0.3403\n",
      "generator loss: -0.0524, discriminator loss: -0.2700\n",
      "generator loss: -0.1510, discriminator loss: -0.1732\n",
      "generator loss: 0.0364, discriminator loss: -0.3617\n",
      "generator loss: 0.0597, discriminator loss: -0.3826\n",
      "wgan error: 4.9748\n",
      "(100, 40, 'Gumbel') 62.7293\n",
      "(100, 40, 'Gumbel') 5.4583 0.8564\n",
      "N=100, p=40, model=Gumbel in done.(3.57 minutes)\n"
     ]
    }
   ],
   "source": [
    "Ns = [100]\n",
    "ps = [10, 20, 40]\n",
    "models = [\"Cauchy\", \"Normal\", \"Gumbel\"]\n",
    "res_sample_cov = dict()\n",
    "res_wgan_cov = defaultdict(list)\n",
    "# outfile = open(\"cov_est.txt\", 'w')\n",
    "\n",
    "for N, p, model in itertools.product(Ns, ps, models):\n",
    "    # A = np.random.uniform(size=(p,p))\n",
    "    A = np.eye(p)\n",
    "    cov = A.T @ A\n",
    "    data = np.random.normal(size=(N, p)) @ A\n",
    "    z = np.random.binomial(n=1,p=0.1,size=(N,1))\n",
    "    if model == \"Cauchy\":\n",
    "        noise = np.random.standard_cauchy(size=(N,p))\n",
    "    elif model == \"Normal\":\n",
    "        noise = np.random.normal(5,size=(N,p))\n",
    "    elif model == \"Gumbel\":\n",
    "        noise = np.random.gumbel(size=(N,p)) * 5\n",
    "    data_perturbed = data * (1-z) + noise * z\n",
    "    data_perturbed = data_perturbed.astype(np.float32)\n",
    "    \n",
    "    t = time.time()\n",
    "    print(\"N={}, p={}, model={} in progress.\".format(N, p, model))\n",
    "\n",
    "    sample_2norm_error = np.linalg.norm(np.cov(data_perturbed.T)-cov, ord=2)\n",
    "    res_sample_cov[(N,p,model)] = sample_2norm_error\n",
    "    print(\"sample cov error: {:.4f}\".format(sample_2norm_error))\n",
    "    \n",
    "    for i in range(10):\n",
    "        wgan_error = simulate_cov(N, p, model)\n",
    "        res_wgan_cov[(N,p,model)].append(wgan_error)\n",
    "        print(\"wgan error: {:.4f}\".format(wgan_error))\n",
    "        \n",
    "    key = (N, p, model)\n",
    "    print(key, \"{:.4f}\".format(res_sample_cov[key]))\n",
    "    print(key, \"{:.4f}\".format(np.mean(res_wgan_cov[key])), \"{:.4f}\".format(np.std(res_wgan_cov[key])))\n",
    "    print(\"N={}, p={}, model={} in done.({:.2f} minutes)\".format(N, p, model, (time.time()-t)/60))\n",
    "#     outfile.write(\"N={}, p={}, model={} samp: {}\\n\".format(N, p, model, res_sample_cov[(N,p,model)]))\n",
    "#     outfile.write(\"N={}, p={}, model={} wgan: {}\\n\".format(N, p, model, res_wgan_cov[(N,p,model)]))\n",
    "#     outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_sample_cov = defaultdict(list)\n",
    "# res_wgan_cov = defaultdict(list)\n",
    "# simulate_cov(100, 10, \"Cauchy\")\n",
    "# print(res_sample_cov)\n",
    "# print(res_wgan_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# p = 4\n",
    "\n",
    "# A = np.random.uniform(size=(p,p))\n",
    "# cov = A.T @ A\n",
    "\n",
    "# data = np.random.normal(size=(N,p)) @ A\n",
    "# noise = np.random.standard_cauchy(size=(N,p))\n",
    "# #noise = np.random.gumbel(size=(N,p)) * 5\n",
    "# z = np.random.binomial(n=1,p=0.1,size=(N,1))\n",
    "# data_perturbed = data * (1-z) + noise * z\n",
    "# data_perturbed = data_perturbed.astype(np.float32)\n",
    "# print(\"sample covariance: \\n\", np.cov(data_perturbed.T))\n",
    "# print(\"true covariance: \\n\", cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "# batch_size = 32\n",
    "# step_size = 0.01\n",
    "\n",
    "# wgan = WGAN(dim_x=p, target=\"cov-matrix\")\n",
    "# wgan.train(data_perturbed, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"2-norm loss, samp: \", np.linalg.norm(np.cov(data_perturbed.T)-cov, ord=2))\n",
    "# Ahat = wgan.generator.trainable_variables[0].numpy()\n",
    "# print(\"2-norm loss, wgan: \", np.linalg.norm(Ahat.T@Ahat - cov, ord=2))\n",
    "# print(\"cov hat: \\n\", A.T @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_loc(data_perturbed, N, p, model):    \n",
    "    if N <= 100:\n",
    "        batch_size = 32 \n",
    "    elif N <= 5000:\n",
    "        batch_size = 128\n",
    "    else:\n",
    "        batch_size = 256\n",
    "    epochs = 200\n",
    "    step_size = 0.005\n",
    "    \n",
    "    wgan = WGAN(dim_x=p, target=\"location\")\n",
    "    wgan.train(data_perturbed, epochs=epochs, batch_size=batch_size, step_size=step_size)\n",
    "    \n",
    "    wgan_error = np.linalg.norm(wgan.generator.trainable_variables[0].numpy()-theta)**2\n",
    "    return wgan_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ns = [1024]\n",
    "models = [\"Normal\",\"Gumbel\"]\n",
    "ps = [10, 20, 40, 80]\n",
    "res_sample_mean = dict()\n",
    "res_wgan_mean = defaultdict(list)\n",
    "# outfile = open(\"location_est_new.txt\", 'w')\n",
    "\n",
    "for N, model, p in itertools.product(Ns, models, ps):\n",
    "    np.random.seed(5)\n",
    "    # theta = np.repeat(np.array([1,2,3,4,5]), p//5)\n",
    "    theta = np.zeros(shape=(p,))\n",
    "    data = np.random.normal(size=(N, p)) + theta\n",
    "    # print(\"sample mean: \\n\", np.mean(data, axis=0))\n",
    "    z = np.random.binomial(n=1,p=0.1,size=(N,1))\n",
    "    if model == \"Cauchy\":\n",
    "        noise = np.random.standard_cauchy(size=(N,p))\n",
    "    elif model == \"Normal\":\n",
    "        noise = np.random.normal(2,size=(N,p))\n",
    "    elif model == \"Gumbel\":\n",
    "        noise = np.random.gumbel(size=(N,p))\n",
    "    data_perturbed = data * (1-z) + noise * z\n",
    "    data_perturbed = data_perturbed.astype(np.float32)\n",
    "    # print(\"noisy sample mean: \\n\", np.mean(data_perturbed, axis=0))\n",
    "    \n",
    "    t = time.time()\n",
    "    print(\"N={}, p={}, model={} in progress.\".format(N, p, model))\n",
    "    \n",
    "    sample_mean_error = np.round(np.linalg.norm(np.mean(data_perturbed, axis=0)-theta)**2, 4)\n",
    "    res_sample_mean[(N,p,model)] = sample_mean_error\n",
    "    print(\"sample mean error: {:.4f}\".format(sample_mean_error))\n",
    "    \n",
    "    for i in range(10):\n",
    "        wgan_error = simulate_loc(data_perturbed, N, p, model)\n",
    "        res_wgan_mean[(N,p,model)].append(wgan_error)\n",
    "        print(\"wgan error: {:.4f}\".format(wgan_error))\n",
    "    \n",
    "    key = (N, p, model)\n",
    "    print(key, res_sample_mean[key])\n",
    "    print(key, np.mean(res_wgan_mean[key]), np.std(res_wgan_mean[key]))\n",
    "    print(\"N={}, p={}, model={} in done.({:.2f} minutes)\".format(N, p, model, (time.time()-t)/60))\n",
    "#     outfile.write(\"N={}, p={}, model={} samp: {}\\n\".format(N, p, model, res_sample_mean[(N,p,model)]))\n",
    "#     outfile.write(\"N={}, p={}, model={} wgan: {}\\n\".format(N, p, model, res_wgan_mean[(N,p,model)]))\n",
    "#     outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_sample_mean = defaultdict(list)\n",
    "# res_wgan_mean = defaultdict(list)\n",
    "# simulate_loc(100, 80, \"Gumbel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_reg(data_reg, N, p, model):    \n",
    "    if N <= 100:\n",
    "        batch_size = 32 \n",
    "    elif N <= 5000:\n",
    "        batch_size = 128\n",
    "    else:\n",
    "        batch_size = 512\n",
    "    epochs = 200\n",
    "    step_size = 0.005\n",
    "\n",
    "    wgan = WGAN(dim_x=p+1, target=\"regression\")\n",
    "    wgan.train(data_reg, epochs=epochs, batch_size=batch_size, step_size=step_size)\n",
    "    \n",
    "    betahat_wgan = wgan.generator.trainable_variables[0].numpy()\n",
    "    wgan_error = np.linalg.norm(betahat_wgan - beta)\n",
    "    return wgan_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=4096, p=10, model=Cauchy in progress.\n",
      "ols_error: 0.1404\n",
      "repeat:  1\n",
      "generator loss: 0.4922, discriminator loss: -0.0593\n",
      "generator loss: 0.5399, discriminator loss: -0.0919\n",
      "generator loss: 0.4916, discriminator loss: -0.0478\n",
      "generator loss: 0.5103, discriminator loss: -0.0650\n",
      "generator loss: 0.5716, discriminator loss: -0.1209\n",
      "generator loss: 0.4737, discriminator loss: -0.0269\n",
      "generator loss: 0.4914, discriminator loss: -0.0398\n",
      "generator loss: 0.5367, discriminator loss: -0.0826\n",
      "generator loss: 0.4319, discriminator loss: 0.0114\n",
      "generator loss: 0.4955, discriminator loss: -0.0461\n",
      "wgan error: 0.4268\n",
      "repeat:  2\n",
      "generator loss: 0.5349, discriminator loss: -0.0719\n",
      "generator loss: 0.5290, discriminator loss: -0.0748\n",
      "generator loss: 0.5797, discriminator loss: -0.1104\n",
      "generator loss: 0.5383, discriminator loss: -0.0722\n",
      "generator loss: 0.5552, discriminator loss: -0.0812\n",
      "generator loss: 0.5615, discriminator loss: -0.0929\n",
      "generator loss: 0.5494, discriminator loss: -0.0787\n",
      "generator loss: 0.5158, discriminator loss: -0.0425\n",
      "generator loss: 0.5335, discriminator loss: -0.0617\n",
      "generator loss: 0.5483, discriminator loss: -0.0740\n",
      "wgan error: 0.3914\n",
      "repeat:  3\n",
      "generator loss: -0.6030, discriminator loss: 0.0205\n",
      "generator loss: -0.5550, discriminator loss: -0.0413\n",
      "generator loss: -0.5724, discriminator loss: -0.0245\n",
      "generator loss: -0.5591, discriminator loss: -0.0245\n",
      "generator loss: -0.5556, discriminator loss: -0.0284\n",
      "generator loss: -0.5547, discriminator loss: -0.0232\n",
      "generator loss: -0.5183, discriminator loss: -0.0725\n",
      "generator loss: -0.5384, discriminator loss: -0.0322\n",
      "generator loss: -0.5829, discriminator loss: -0.0102\n",
      "generator loss: -0.5612, discriminator loss: -0.0315\n",
      "wgan error: 0.2319\n",
      "repeat:  4\n",
      "generator loss: 0.0804, discriminator loss: -0.0756\n",
      "generator loss: 0.0363, discriminator loss: -0.0323\n",
      "generator loss: 0.0438, discriminator loss: -0.0437\n",
      "generator loss: 0.0864, discriminator loss: -0.0914\n",
      "generator loss: 0.0840, discriminator loss: -0.0822\n",
      "generator loss: 0.0838, discriminator loss: -0.0759\n",
      "generator loss: 0.0591, discriminator loss: -0.0688\n",
      "generator loss: 0.0264, discriminator loss: -0.0473\n",
      "generator loss: 0.0706, discriminator loss: -0.0946\n",
      "generator loss: 0.0347, discriminator loss: -0.0550\n",
      "wgan error: 0.3275\n",
      "repeat:  5\n",
      "generator loss: 0.0036, discriminator loss: -0.0848\n",
      "generator loss: -0.0835, discriminator loss: 0.0047\n",
      "generator loss: -0.0312, discriminator loss: -0.0507\n",
      "generator loss: -0.0035, discriminator loss: -0.0732\n",
      "generator loss: -0.0217, discriminator loss: -0.0596\n",
      "generator loss: -0.0367, discriminator loss: -0.0441\n",
      "generator loss: -0.0267, discriminator loss: -0.0533\n",
      "generator loss: 0.0111, discriminator loss: -0.0959\n",
      "generator loss: -0.0674, discriminator loss: -0.0136\n",
      "generator loss: 0.0224, discriminator loss: -0.0961\n",
      "wgan error: 0.5936\n",
      "repeat:  6\n",
      "generator loss: 0.0151, discriminator loss: -0.0367\n",
      "generator loss: 0.0555, discriminator loss: -0.0737\n",
      "generator loss: -0.0143, discriminator loss: -0.0003\n",
      "generator loss: 0.0451, discriminator loss: -0.0552\n",
      "generator loss: 0.0077, discriminator loss: -0.0166\n",
      "generator loss: 0.0636, discriminator loss: -0.0727\n",
      "generator loss: -0.0473, discriminator loss: 0.0344\n",
      "generator loss: -0.0055, discriminator loss: -0.0062\n",
      "generator loss: -0.0097, discriminator loss: -0.0030\n",
      "generator loss: -0.0442, discriminator loss: 0.0218\n",
      "wgan error: 0.6138\n",
      "repeat:  7\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "generator loss: 0.0000, discriminator loss: 0.0000\n",
      "wgan error: 0.2902\n",
      "repeat:  8\n",
      "generator loss: 0.4656, discriminator loss: -0.0369\n",
      "generator loss: 0.4768, discriminator loss: -0.0414\n",
      "generator loss: 0.5358, discriminator loss: -0.1116\n",
      "generator loss: 0.4695, discriminator loss: -0.0369\n",
      "generator loss: 0.5013, discriminator loss: -0.0906\n",
      "generator loss: 0.5616, discriminator loss: -0.1324\n",
      "generator loss: 0.4828, discriminator loss: -0.0528\n",
      "generator loss: 0.4941, discriminator loss: -0.0652\n",
      "generator loss: 0.4530, discriminator loss: -0.0464\n",
      "generator loss: 0.5021, discriminator loss: -0.0783\n",
      "wgan error: 0.6017\n",
      "repeat:  9\n",
      "generator loss: -0.5332, discriminator loss: -0.0558\n",
      "generator loss: -0.4294, discriminator loss: -0.1397\n",
      "generator loss: -0.4953, discriminator loss: -0.0941\n",
      "generator loss: -0.5789, discriminator loss: 0.0087\n",
      "generator loss: -0.4938, discriminator loss: -0.0807\n",
      "generator loss: -0.4774, discriminator loss: -0.1107\n",
      "generator loss: -0.4951, discriminator loss: -0.0936\n",
      "generator loss: -0.5226, discriminator loss: -0.0643\n",
      "generator loss: -0.4512, discriminator loss: -0.1353\n",
      "generator loss: -0.4549, discriminator loss: -0.1253\n",
      "wgan error: 0.4652\n",
      "repeat:  10\n",
      "generator loss: -0.0521, discriminator loss: -0.0355\n",
      "generator loss: -0.0441, discriminator loss: -0.0485\n",
      "generator loss: 0.0133, discriminator loss: -0.1060\n",
      "generator loss: -0.0399, discriminator loss: -0.0462\n",
      "generator loss: -0.0925, discriminator loss: 0.0048\n",
      "generator loss: 0.0224, discriminator loss: -0.1078\n",
      "generator loss: 0.0088, discriminator loss: -0.1012\n",
      "generator loss: -0.0147, discriminator loss: -0.0726\n",
      "generator loss: 0.0275, discriminator loss: -0.1163\n",
      "generator loss: 0.0086, discriminator loss: -0.1023\n",
      "wgan error: 0.6369\n",
      "(4096, 10, 'Cauchy') 0.1404\n",
      "(4096, 10, 'Cauchy') 0.4579 0.1404\n",
      "(4096, 10, 'Cauchy') [0.4267916598540776, 0.39141557708456043, 0.23191875110270785, 0.3275347056181308, 0.5935744313927757, 0.6137640200088206, 0.29019434525711973, 0.6017474570475032, 0.46523374909239085, 0.6368722185121992]\n",
      "N=4096, p=10, model=Cauchy in done.(15.75 minutes)\n"
     ]
    }
   ],
   "source": [
    "Ns = [4096]\n",
    "ps = [10]\n",
    "models = [\"Cauchy\"]\n",
    "epsilons = [0.05]\n",
    "res_ols_reg = dict()\n",
    "res_wgan_reg = defaultdict(list)\n",
    "# outfile = open(\"regression_est.txt\", 'w')\n",
    "\n",
    "p = 10\n",
    "N = 4096\n",
    "np.random.seed(4)\n",
    "beta = np.repeat(np.array([-1,-1,0,1,1]), p//5) * 0.05\n",
    "data_X = np.random.normal(size=(N,p))\n",
    "for p, N, model, epsilon in itertools.product(ps, Ns, models, epsilons):\n",
    "    \n",
    "    z = np.random.binomial(n=1,p=epsilon,size=(N,))\n",
    "    if model == \"Cauchy\":\n",
    "        noise = (1-z)*np.random.normal(scale=1, size=(N,)) + z*(np.abs(np.random.standard_cauchy(size=(N,))))\n",
    "    elif model == \"Normal\":\n",
    "        noise = (1-z)*np.random.normal(scale=1, size=(N,)) + z*(np.abs(np.random.normal(loc=2, scale=5, size=(N,))))\n",
    "    elif model == \"Gumbel\":\n",
    "        noise = (1-z)*np.random.normal(scale=1, size=(N,)) + z*(np.abs(np.random.gumbel(size=(N,))*10))\n",
    "    data_y = data_X @ beta + noise\n",
    "    data_y = data_y.reshape([-1,1])\n",
    "    data_reg = np.concatenate([data_X, data_y], axis=1)\n",
    "    data_reg = data_reg.astype(np.float32)\n",
    "\n",
    "    t = time.time()\n",
    "    print(\"N={}, p={}, model={} in progress.\".format(N, p, model))\n",
    "\n",
    "    betahat = np.linalg.solve(data_X.T@data_X, (data_X.T@data_y)).reshape(-1)\n",
    "    ols_error = np.linalg.norm(betahat - beta)\n",
    "    res_ols_reg[(N,p,model)] = ols_error\n",
    "    print(\"ols_error: {:.4f}\".format(ols_error))\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"repeat: \", i+1)\n",
    "        wgan_error = simulate_reg(data_reg, N, p, model)\n",
    "        res_wgan_reg[(N,p,model)].append(wgan_error)\n",
    "        print(\"wgan error: {:.4f}\".format(wgan_error))\n",
    "    \n",
    "    key = (N,p,model)\n",
    "    print(key, \"{:.4f}\".format(res_ols_reg[key]))\n",
    "    print(key, \"{:.4f}\".format(np.mean(res_wgan_reg[key])), \"{:.4f}\".format(np.std(res_wgan_reg[key])))\n",
    "    print(key, res_wgan_reg[key])\n",
    "    print(\"N={}, p={}, model={} in done.({:.2f} minutes)\".format(N, p, model, (time.time()-t)/60))\n",
    "    # outfile.write(\"N={}, p={}, model={} samp: {}\\n\".format(N, p, model, res_ols_reg[(N,p,model)]))\n",
    "    # outfile.write(\"N={}, p={}, model={} wgan: {}\\n\".format(N, p, model, res_wgan_reg[(N,p,model)]))\n",
    "    # outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=4096, p=40, model=Cauchy in progress.\n",
      "ols_error: 0.4137\n",
      "repeat:  1\n",
      "generator loss: -0.1441, discriminator loss: -0.0956\n",
      "generator loss: -0.2061, discriminator loss: -0.0314\n",
      "generator loss: -0.1837, discriminator loss: -0.0526\n",
      "generator loss: -0.1466, discriminator loss: -0.0928\n",
      "generator loss: -0.2158, discriminator loss: -0.0269\n",
      "generator loss: -0.1940, discriminator loss: -0.0432\n",
      "generator loss: -0.1091, discriminator loss: -0.1268\n",
      "generator loss: -0.1941, discriminator loss: -0.0394\n",
      "generator loss: -0.1470, discriminator loss: -0.0854\n",
      "generator loss: -0.2514, discriminator loss: 0.0157\n",
      "wgan error: 0.6472\n",
      "repeat:  2\n",
      "generator loss: -0.2018, discriminator loss: -0.0755\n",
      "generator loss: -0.2733, discriminator loss: -0.0042\n",
      "generator loss: -0.2171, discriminator loss: -0.0630\n",
      "generator loss: -0.2109, discriminator loss: -0.0674\n",
      "generator loss: -0.2226, discriminator loss: -0.0519\n",
      "generator loss: -0.2059, discriminator loss: -0.0725\n",
      "generator loss: -0.2240, discriminator loss: -0.0527\n",
      "generator loss: -0.2283, discriminator loss: -0.0557\n",
      "generator loss: -0.2542, discriminator loss: -0.0295\n",
      "generator loss: -0.2088, discriminator loss: -0.0656\n",
      "wgan error: 0.5986\n",
      "repeat:  3\n",
      "generator loss: -0.0442, discriminator loss: -0.0888\n",
      "generator loss: -0.0338, discriminator loss: -0.0902\n",
      "generator loss: -0.0592, discriminator loss: -0.0673\n",
      "generator loss: -0.0586, discriminator loss: -0.0794\n",
      "generator loss: -0.0614, discriminator loss: -0.0644\n",
      "generator loss: -0.0514, discriminator loss: -0.0651\n",
      "generator loss: -0.0574, discriminator loss: -0.0686\n",
      "generator loss: -0.0632, discriminator loss: -0.0618\n",
      "generator loss: -0.0960, discriminator loss: -0.0405\n",
      "generator loss: -0.0133, discriminator loss: -0.1332\n",
      "wgan error: 0.6525\n",
      "repeat:  4\n",
      "generator loss: 0.3774, discriminator loss: -0.0023\n",
      "generator loss: 0.3996, discriminator loss: -0.0294\n",
      "generator loss: 0.4207, discriminator loss: -0.0597\n",
      "generator loss: 0.4135, discriminator loss: -0.0417\n",
      "generator loss: 0.5169, discriminator loss: -0.1358\n",
      "generator loss: 0.3840, discriminator loss: -0.0164\n",
      "generator loss: 0.4135, discriminator loss: -0.0491\n",
      "generator loss: 0.3654, discriminator loss: 0.0056\n",
      "generator loss: 0.4472, discriminator loss: -0.0789\n",
      "generator loss: 0.3800, discriminator loss: -0.0120\n",
      "wgan error: 0.6029\n",
      "repeat:  5\n",
      "generator loss: 0.3438, discriminator loss: -0.0614\n",
      "generator loss: 0.3003, discriminator loss: -0.0190\n",
      "generator loss: 0.3847, discriminator loss: -0.1133\n",
      "generator loss: 0.3537, discriminator loss: -0.0745\n",
      "generator loss: 0.2846, discriminator loss: 0.0014\n",
      "generator loss: 0.3183, discriminator loss: -0.0384\n",
      "generator loss: 0.3815, discriminator loss: -0.0923\n",
      "generator loss: 0.3159, discriminator loss: -0.0390\n",
      "generator loss: 0.3599, discriminator loss: -0.0715\n",
      "generator loss: 0.3374, discriminator loss: -0.0490\n",
      "wgan error: 0.6886\n",
      "repeat:  6\n",
      "generator loss: 0.1324, discriminator loss: -0.1053\n",
      "generator loss: 0.0716, discriminator loss: -0.0448\n",
      "generator loss: 0.0698, discriminator loss: -0.0456\n",
      "generator loss: 0.0663, discriminator loss: -0.0522\n",
      "generator loss: 0.0409, discriminator loss: -0.0101\n",
      "generator loss: 0.0774, discriminator loss: -0.0497\n",
      "generator loss: 0.1506, discriminator loss: -0.1393\n",
      "generator loss: 0.0147, discriminator loss: 0.0015\n",
      "generator loss: 0.1168, discriminator loss: -0.1027\n",
      "generator loss: 0.0615, discriminator loss: -0.0988\n",
      "wgan error: 0.6078\n",
      "repeat:  7\n",
      "generator loss: -0.0223, discriminator loss: -0.0393\n",
      "generator loss: -0.0234, discriminator loss: -0.0409\n",
      "generator loss: 0.0305, discriminator loss: -0.0909\n",
      "generator loss: 0.0357, discriminator loss: -0.0931\n",
      "generator loss: -0.0147, discriminator loss: -0.0429\n",
      "generator loss: -0.0203, discriminator loss: -0.0476\n",
      "generator loss: -0.0027, discriminator loss: -0.0511\n",
      "generator loss: -0.0222, discriminator loss: -0.0408\n",
      "generator loss: 0.0289, discriminator loss: -0.0967\n",
      "generator loss: -0.0217, discriminator loss: -0.0387\n",
      "wgan error: 0.5659\n",
      "repeat:  8\n",
      "generator loss: -0.3594, discriminator loss: -0.1024\n",
      "generator loss: -0.3444, discriminator loss: -0.1251\n",
      "generator loss: -0.3919, discriminator loss: -0.0661\n",
      "generator loss: -0.3381, discriminator loss: -0.1263\n",
      "generator loss: -0.4430, discriminator loss: -0.0263\n",
      "generator loss: -0.3929, discriminator loss: -0.0747\n",
      "generator loss: -0.4337, discriminator loss: -0.0311\n",
      "generator loss: -0.3569, discriminator loss: -0.1147\n",
      "generator loss: -0.3781, discriminator loss: -0.0791\n",
      "generator loss: -0.4068, discriminator loss: -0.0644\n",
      "wgan error: 0.7225\n",
      "repeat:  9\n",
      "generator loss: 0.2727, discriminator loss: -0.0593\n",
      "generator loss: 0.2689, discriminator loss: -0.0523\n",
      "generator loss: 0.2967, discriminator loss: -0.0795\n",
      "generator loss: 0.2842, discriminator loss: -0.0673\n",
      "generator loss: 0.2983, discriminator loss: -0.0826\n",
      "generator loss: 0.2573, discriminator loss: -0.0533\n",
      "generator loss: 0.3412, discriminator loss: -0.1349\n",
      "generator loss: 0.3027, discriminator loss: -0.0796\n",
      "generator loss: 0.3015, discriminator loss: -0.0940\n",
      "generator loss: 0.2567, discriminator loss: -0.0496\n",
      "wgan error: 0.5783\n",
      "repeat:  10\n",
      "generator loss: 0.2098, discriminator loss: -0.0573\n",
      "generator loss: 0.2347, discriminator loss: -0.0842\n",
      "generator loss: 0.1928, discriminator loss: -0.0494\n",
      "generator loss: 0.2544, discriminator loss: -0.1029\n",
      "generator loss: 0.2018, discriminator loss: -0.0531\n",
      "generator loss: 0.2281, discriminator loss: -0.0829\n",
      "generator loss: 0.2021, discriminator loss: -0.0441\n",
      "generator loss: 0.2386, discriminator loss: -0.0915\n",
      "generator loss: 0.2467, discriminator loss: -0.0871\n",
      "generator loss: 0.2235, discriminator loss: -0.0761\n",
      "wgan error: 0.7091\n",
      "(4096, 40, 'Cauchy') 0.4137\n",
      "(4096, 40, 'Cauchy') 0.6373 0.0524\n",
      "(4096, 40, 'Cauchy') [0.647158916956551, 0.5986061274619897, 0.6525096849419766, 0.6028648123171252, 0.6885773219180449, 0.6078414925531145, 0.5658858832439794, 0.7225277469598864, 0.5783399394710708, 0.7090755409447349]\n",
      "N=4096, p=40, model=Cauchy in done.(15.79 minutes)\n",
      "N=4096, p=40, model=Cauchy in progress.\n",
      "ols_error: 1.1675\n",
      "repeat:  1\n",
      "generator loss: -0.0599, discriminator loss: -0.1558\n",
      "generator loss: -0.0530, discriminator loss: -0.1594\n",
      "generator loss: -0.0603, discriminator loss: -0.1548\n",
      "generator loss: -0.0503, discriminator loss: -0.1678\n",
      "generator loss: -0.0491, discriminator loss: -0.1687\n",
      "generator loss: -0.0577, discriminator loss: -0.1629\n",
      "generator loss: -0.0817, discriminator loss: -0.1332\n",
      "generator loss: -0.0206, discriminator loss: -0.2005\n",
      "generator loss: -0.0629, discriminator loss: -0.1515\n",
      "generator loss: 0.0100, discriminator loss: -0.2327\n",
      "wgan error: 0.8329\n",
      "repeat:  2\n",
      "generator loss: 0.2449, discriminator loss: -0.1482\n",
      "generator loss: 0.1647, discriminator loss: -0.0732\n",
      "generator loss: 0.2311, discriminator loss: -0.1399\n",
      "generator loss: 0.2293, discriminator loss: -0.1406\n",
      "generator loss: 0.2846, discriminator loss: -0.1937\n",
      "generator loss: 0.2594, discriminator loss: -0.1701\n",
      "generator loss: 0.3118, discriminator loss: -0.2227\n",
      "generator loss: 0.2585, discriminator loss: -0.1683\n",
      "generator loss: 0.2600, discriminator loss: -0.1685\n",
      "generator loss: 0.2167, discriminator loss: -0.1245\n",
      "wgan error: 0.7184\n",
      "repeat:  3\n",
      "generator loss: 0.1360, discriminator loss: -0.1973\n",
      "generator loss: 0.1659, discriminator loss: -0.2307\n",
      "generator loss: 0.0628, discriminator loss: -0.1221\n",
      "generator loss: 0.1458, discriminator loss: -0.2041\n",
      "generator loss: 0.0605, discriminator loss: -0.1215\n",
      "generator loss: 0.0791, discriminator loss: -0.1411\n",
      "generator loss: 0.0965, discriminator loss: -0.1563\n",
      "generator loss: 0.0706, discriminator loss: -0.1230\n",
      "generator loss: 0.0824, discriminator loss: -0.1395\n",
      "generator loss: 0.1063, discriminator loss: -0.1632\n",
      "wgan error: 0.7076\n",
      "repeat:  4\n",
      "generator loss: 0.1492, discriminator loss: -0.1413\n",
      "generator loss: 0.1893, discriminator loss: -0.1859\n",
      "generator loss: 0.1827, discriminator loss: -0.1692\n",
      "generator loss: 0.1283, discriminator loss: -0.1213\n",
      "generator loss: 0.1756, discriminator loss: -0.1681\n",
      "generator loss: 0.0908, discriminator loss: -0.0799\n",
      "generator loss: 0.1613, discriminator loss: -0.1500\n",
      "generator loss: 0.1019, discriminator loss: -0.0957\n",
      "generator loss: 0.1461, discriminator loss: -0.1398\n",
      "generator loss: 0.1720, discriminator loss: -0.1641\n",
      "wgan error: 0.9131\n",
      "repeat:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: 0.0503, discriminator loss: -0.0453\n",
      "generator loss: 0.0782, discriminator loss: -0.0694\n",
      "generator loss: 0.2106, discriminator loss: -0.2046\n",
      "generator loss: 0.1138, discriminator loss: -0.1114\n",
      "generator loss: 0.1504, discriminator loss: -0.1444\n",
      "generator loss: 0.1476, discriminator loss: -0.1428\n",
      "generator loss: 0.1489, discriminator loss: -0.1448\n",
      "generator loss: 0.0994, discriminator loss: -0.0943\n",
      "generator loss: 0.1697, discriminator loss: -0.1642\n",
      "generator loss: 0.2127, discriminator loss: -0.2021\n",
      "wgan error: 0.7671\n",
      "repeat:  6\n",
      "generator loss: 0.2269, discriminator loss: -0.1376\n",
      "generator loss: 0.2892, discriminator loss: -0.1929\n",
      "generator loss: 0.2129, discriminator loss: -0.1106\n",
      "generator loss: 0.2978, discriminator loss: -0.1979\n",
      "generator loss: 0.2746, discriminator loss: -0.1753\n",
      "generator loss: 0.2639, discriminator loss: -0.1622\n",
      "generator loss: 0.1884, discriminator loss: -0.0875\n",
      "generator loss: 0.2345, discriminator loss: -0.1370\n",
      "generator loss: 0.2241, discriminator loss: -0.1185\n",
      "generator loss: 0.2680, discriminator loss: -0.1574\n",
      "wgan error: 0.5791\n",
      "repeat:  7\n",
      "generator loss: -0.0136, discriminator loss: -0.1607\n",
      "generator loss: -0.0370, discriminator loss: -0.1383\n",
      "generator loss: -0.0359, discriminator loss: -0.1423\n",
      "generator loss: -0.0024, discriminator loss: -0.1684\n",
      "generator loss: -0.0204, discriminator loss: -0.1560\n",
      "generator loss: -0.0123, discriminator loss: -0.1612\n",
      "generator loss: -0.0243, discriminator loss: -0.1439\n",
      "generator loss: -0.0260, discriminator loss: -0.1310\n",
      "generator loss: -0.0071, discriminator loss: -0.1589\n",
      "generator loss: 0.0311, discriminator loss: -0.1996\n",
      "wgan error: 0.7414\n",
      "repeat:  8\n",
      "generator loss: 0.0920, discriminator loss: -0.1205\n",
      "generator loss: 0.1562, discriminator loss: -0.1762\n",
      "generator loss: 0.1183, discriminator loss: -0.1442\n",
      "generator loss: 0.0684, discriminator loss: -0.0956\n",
      "generator loss: 0.0692, discriminator loss: -0.0962\n",
      "generator loss: 0.1659, discriminator loss: -0.1867\n",
      "generator loss: 0.1069, discriminator loss: -0.1339\n",
      "generator loss: 0.1372, discriminator loss: -0.1638\n",
      "generator loss: 0.1899, discriminator loss: -0.2127\n",
      "generator loss: 0.0778, discriminator loss: -0.1120\n",
      "wgan error: 0.7851\n",
      "repeat:  9\n",
      "generator loss: -0.0855, discriminator loss: -0.1949\n",
      "generator loss: -0.1142, discriminator loss: -0.1697\n",
      "generator loss: -0.2013, discriminator loss: -0.0780\n",
      "generator loss: -0.1077, discriminator loss: -0.1741\n",
      "generator loss: -0.0666, discriminator loss: -0.2216\n",
      "generator loss: -0.1163, discriminator loss: -0.1712\n",
      "generator loss: -0.1580, discriminator loss: -0.1305\n",
      "generator loss: -0.1140, discriminator loss: -0.1733\n",
      "generator loss: -0.0857, discriminator loss: -0.1990\n",
      "generator loss: -0.1401, discriminator loss: -0.1432\n",
      "wgan error: 0.6491\n",
      "repeat:  10\n",
      "generator loss: -0.2274, discriminator loss: -0.1133\n",
      "generator loss: -0.1873, discriminator loss: -0.1533\n",
      "generator loss: -0.2217, discriminator loss: -0.1197\n",
      "generator loss: -0.1343, discriminator loss: -0.2090\n",
      "generator loss: -0.0919, discriminator loss: -0.2501\n",
      "generator loss: -0.2283, discriminator loss: -0.1151\n",
      "generator loss: -0.2227, discriminator loss: -0.1149\n",
      "generator loss: -0.1341, discriminator loss: -0.2043\n",
      "generator loss: -0.1910, discriminator loss: -0.1522\n",
      "generator loss: -0.2320, discriminator loss: -0.1102\n",
      "wgan error: 0.8460\n",
      "(4096, 40, 'Cauchy') 1.1675\n",
      "(4096, 40, 'Cauchy') 0.6957 0.0954\n",
      "(4096, 40, 'Cauchy') [0.647158916956551, 0.5986061274619897, 0.6525096849419766, 0.6028648123171252, 0.6885773219180449, 0.6078414925531145, 0.5658858832439794, 0.7225277469598864, 0.5783399394710708, 0.7090755409447349, 0.8329469382854542, 0.7183599763694057, 0.7075758370918269, 0.9130626754881189, 0.767132747093127, 0.5790783767398914, 0.7414158763615996, 0.7850872108958092, 0.6491444648425616, 0.8460072176300603]\n",
      "N=4096, p=40, model=Cauchy in done.(15.80 minutes)\n",
      "N=4096, p=40, model=Cauchy in progress.\n",
      "ols_error: 2.1114\n",
      "repeat:  1\n",
      "generator loss: -0.1497, discriminator loss: -0.1709\n",
      "generator loss: -0.0819, discriminator loss: -0.2398\n",
      "generator loss: -0.0955, discriminator loss: -0.2256\n",
      "generator loss: -0.0955, discriminator loss: -0.2251\n",
      "generator loss: -0.1148, discriminator loss: -0.2074\n",
      "generator loss: -0.1713, discriminator loss: -0.1501\n",
      "generator loss: -0.1121, discriminator loss: -0.2082\n",
      "generator loss: -0.1018, discriminator loss: -0.2194\n",
      "generator loss: -0.0884, discriminator loss: -0.2318\n",
      "generator loss: -0.1435, discriminator loss: -0.1766\n",
      "wgan error: 0.7187\n",
      "repeat:  2\n",
      "generator loss: -0.1385, discriminator loss: -0.2764\n",
      "generator loss: -0.1868, discriminator loss: -0.2287\n",
      "generator loss: -0.1971, discriminator loss: -0.2183\n",
      "generator loss: -0.2450, discriminator loss: -0.1695\n",
      "generator loss: -0.1024, discriminator loss: -0.3122\n",
      "generator loss: -0.2615, discriminator loss: -0.1525\n",
      "generator loss: -0.1470, discriminator loss: -0.2670\n",
      "generator loss: -0.1858, discriminator loss: -0.2279\n",
      "generator loss: -0.1905, discriminator loss: -0.2254\n",
      "generator loss: -0.0911, discriminator loss: -0.3259\n",
      "wgan error: 0.8060\n",
      "repeat:  3\n",
      "generator loss: -0.2128, discriminator loss: -0.2490\n",
      "generator loss: -0.2377, discriminator loss: -0.2266\n",
      "generator loss: -0.2006, discriminator loss: -0.2632\n",
      "generator loss: -0.2065, discriminator loss: -0.2570\n",
      "generator loss: -0.2220, discriminator loss: -0.2423\n",
      "generator loss: -0.2855, discriminator loss: -0.1784\n",
      "generator loss: -0.1836, discriminator loss: -0.2801\n",
      "generator loss: -0.2646, discriminator loss: -0.1988\n",
      "generator loss: -0.2017, discriminator loss: -0.2622\n",
      "generator loss: -0.2229, discriminator loss: -0.2408\n",
      "wgan error: 0.6960\n",
      "repeat:  4\n",
      "generator loss: -0.2928, discriminator loss: -0.1239\n",
      "generator loss: -0.1779, discriminator loss: -0.2394\n",
      "generator loss: -0.1388, discriminator loss: -0.2779\n",
      "generator loss: -0.2034, discriminator loss: -0.2147\n",
      "generator loss: -0.2543, discriminator loss: -0.1643\n",
      "generator loss: -0.2611, discriminator loss: -0.1563\n",
      "generator loss: -0.1969, discriminator loss: -0.2216\n",
      "generator loss: -0.2419, discriminator loss: -0.1780\n",
      "generator loss: -0.2611, discriminator loss: -0.1593\n",
      "generator loss: -0.1430, discriminator loss: -0.2778\n",
      "wgan error: 0.8125\n",
      "repeat:  5\n",
      "generator loss: 0.0302, discriminator loss: -0.2766\n",
      "generator loss: -0.0357, discriminator loss: -0.2086\n",
      "generator loss: 0.0168, discriminator loss: -0.2615\n",
      "generator loss: -0.0256, discriminator loss: -0.2195\n",
      "generator loss: 0.0467, discriminator loss: -0.2897\n",
      "generator loss: -0.0631, discriminator loss: -0.1794\n",
      "generator loss: 0.0173, discriminator loss: -0.2589\n",
      "generator loss: -0.0714, discriminator loss: -0.1688\n",
      "generator loss: -0.0150, discriminator loss: -0.2239\n",
      "generator loss: 0.0058, discriminator loss: -0.2454\n",
      "wgan error: 0.6597\n",
      "repeat:  6\n",
      "generator loss: -0.0712, discriminator loss: -0.1758\n",
      "generator loss: 0.0144, discriminator loss: -0.2605\n",
      "generator loss: -0.0456, discriminator loss: -0.2010\n",
      "generator loss: 0.0329, discriminator loss: -0.2788\n",
      "generator loss: 0.0143, discriminator loss: -0.2597\n",
      "generator loss: -0.1147, discriminator loss: -0.1297\n",
      "generator loss: 0.0081, discriminator loss: -0.2504\n",
      "generator loss: 0.0714, discriminator loss: -0.3140\n",
      "generator loss: -0.0036, discriminator loss: -0.2391\n",
      "generator loss: 0.0137, discriminator loss: -0.2553\n",
      "wgan error: 0.5923\n",
      "repeat:  7\n",
      "generator loss: -0.2642, discriminator loss: -0.2913\n",
      "generator loss: -0.3728, discriminator loss: -0.1834\n",
      "generator loss: -0.3079, discriminator loss: -0.2483\n",
      "generator loss: -0.3316, discriminator loss: -0.2253\n",
      "generator loss: -0.3366, discriminator loss: -0.2190\n",
      "generator loss: -0.3212, discriminator loss: -0.2342\n",
      "generator loss: -0.3524, discriminator loss: -0.2025\n",
      "generator loss: -0.3378, discriminator loss: -0.2170\n",
      "generator loss: -0.2782, discriminator loss: -0.2771\n",
      "generator loss: -0.2305, discriminator loss: -0.3233\n",
      "wgan error: 0.6830\n",
      "repeat:  8\n",
      "generator loss: 0.0543, discriminator loss: -0.2979\n",
      "generator loss: 0.0277, discriminator loss: -0.2704\n",
      "generator loss: -0.0720, discriminator loss: -0.1709\n",
      "generator loss: 0.0221, discriminator loss: -0.2656\n",
      "generator loss: -0.0905, discriminator loss: -0.1534\n",
      "generator loss: 0.0313, discriminator loss: -0.2761\n",
      "generator loss: 0.0146, discriminator loss: -0.2597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loss: 0.0439, discriminator loss: -0.2875\n",
      "generator loss: -0.0751, discriminator loss: -0.1686\n",
      "generator loss: -0.0388, discriminator loss: -0.2057\n",
      "wgan error: 0.7644\n",
      "repeat:  9\n",
      "generator loss: 0.0847, discriminator loss: -0.2275\n",
      "generator loss: 0.0494, discriminator loss: -0.1918\n",
      "generator loss: 0.0828, discriminator loss: -0.2253\n",
      "generator loss: 0.0405, discriminator loss: -0.1825\n",
      "generator loss: 0.1692, discriminator loss: -0.3101\n",
      "generator loss: 0.0962, discriminator loss: -0.2375\n",
      "generator loss: 0.1176, discriminator loss: -0.2598\n",
      "generator loss: 0.1079, discriminator loss: -0.2506\n",
      "generator loss: 0.0528, discriminator loss: -0.1949\n",
      "generator loss: 0.0226, discriminator loss: -0.1629\n",
      "wgan error: 0.7064\n",
      "repeat:  10\n",
      "generator loss: -0.1882, discriminator loss: -0.2809\n",
      "generator loss: -0.1918, discriminator loss: -0.2783\n",
      "generator loss: -0.3056, discriminator loss: -0.1652\n",
      "generator loss: -0.2197, discriminator loss: -0.2506\n",
      "generator loss: -0.2627, discriminator loss: -0.2083\n",
      "generator loss: -0.2258, discriminator loss: -0.2461\n",
      "generator loss: -0.2236, discriminator loss: -0.2499\n",
      "generator loss: -0.1885, discriminator loss: -0.2864\n",
      "generator loss: -0.3062, discriminator loss: -0.1692\n",
      "generator loss: -0.2161, discriminator loss: -0.2587\n",
      "wgan error: 0.7474\n",
      "(4096, 40, 'Cauchy') 2.1114\n",
      "(4096, 40, 'Cauchy') 0.7033 0.0868\n",
      "(4096, 40, 'Cauchy') [0.647158916956551, 0.5986061274619897, 0.6525096849419766, 0.6028648123171252, 0.6885773219180449, 0.6078414925531145, 0.5658858832439794, 0.7225277469598864, 0.5783399394710708, 0.7090755409447349, 0.8329469382854542, 0.7183599763694057, 0.7075758370918269, 0.9130626754881189, 0.767132747093127, 0.5790783767398914, 0.7414158763615996, 0.7850872108958092, 0.6491444648425616, 0.8460072176300603, 0.7187239664924389, 0.8060459210007686, 0.6959760432439765, 0.8125383455136614, 0.6596550255459176, 0.5922830155407545, 0.6830423470404351, 0.7643645854410084, 0.7063960135798336, 0.7473942153838679]\n",
      "N=4096, p=40, model=Cauchy in done.(15.79 minutes)\n"
     ]
    }
   ],
   "source": [
    "Ns = [4096]\n",
    "ps = [40]\n",
    "models = [\"Cauchy\"]\n",
    "epsilons = [0.10, 0.20, 0.50]\n",
    "res_ols_reg = dict()\n",
    "res_wgan_reg = defaultdict(list)\n",
    "# outfile = open(\"regression_est.txt\", 'w')\n",
    "\n",
    "p = 40\n",
    "N = 4096\n",
    "np.random.seed(5)\n",
    "beta = np.repeat(np.array([-1,-1,0,1,1]), p//5) * 0.05\n",
    "data_X = np.random.normal(size=(N,p))\n",
    "for p, N, model, epsilon in itertools.product(ps, Ns, models, epsilons):\n",
    "    \n",
    "    z = np.random.binomial(n=1,p=epsilon,size=(N,))\n",
    "    if model == \"Cauchy\":\n",
    "        noise = (1-z)*np.random.normal(scale=1, size=(N,)) + z*(np.abs(np.random.standard_cauchy(size=(N,))))\n",
    "    elif model == \"Normal\":\n",
    "        noise = (1-z)*np.random.normal(scale=1, size=(N,)) + z*(np.abs(np.random.normal(loc=2, scale=5, size=(N,))))\n",
    "    elif model == \"Gumbel\":\n",
    "        noise = (1-z)*np.random.normal(scale=1, size=(N,)) + z*(np.abs(np.random.gumbel(size=(N,))*10))\n",
    "    data_y = data_X @ beta + noise\n",
    "    data_y = data_y.reshape([-1,1])\n",
    "    data_reg = np.concatenate([data_X, data_y], axis=1)\n",
    "    data_reg = data_reg.astype(np.float32)\n",
    "\n",
    "    t = time.time()\n",
    "    print(\"N={}, p={}, model={} in progress.\".format(N, p, model))\n",
    "\n",
    "    betahat = np.linalg.solve(data_X.T@data_X, (data_X.T@data_y)).reshape(-1)\n",
    "    ols_error = np.linalg.norm(betahat - beta)\n",
    "    res_ols_reg[(N,p,model)] = ols_error\n",
    "    print(\"ols_error: {:.4f}\".format(ols_error))\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"repeat: \", i+1)\n",
    "        wgan_error = simulate_reg(data_reg, N, p, model)\n",
    "        res_wgan_reg[(N,p,model)].append(wgan_error)\n",
    "        print(\"wgan error: {:.4f}\".format(wgan_error))\n",
    "    \n",
    "    key = (N,p,model)\n",
    "    print(key, \"{:.4f}\".format(res_ols_reg[key]))\n",
    "    print(key, \"{:.4f}\".format(np.mean(res_wgan_reg[key])), \"{:.4f}\".format(np.std(res_wgan_reg[key])))\n",
    "    print(key, res_wgan_reg[key])\n",
    "    print(\"N={}, p={}, model={} in done.({:.2f} minutes)\".format(N, p, model, (time.time()-t)/60))\n",
    "    # outfile.write(\"N={}, p={}, model={} samp: {}\\n\".format(N, p, model, res_ols_reg[(N,p,model)]))\n",
    "    # outfile.write(\"N={}, p={}, model={} wgan: {}\\n\".format(N, p, model, res_wgan_reg[(N,p,model)]))\n",
    "    # outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# betahat = np.linalg.solve(data_X.T@data_X, (data_X.T@data_y)).reshape(-1)\n",
    "# print(\"least square estimate: \\n\", betahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 200\n",
    "# batch_size = 64\n",
    "# step_size = 0.005\n",
    "\n",
    "# wgan = WGAN(dim_x=p+1, target=\"regression\")\n",
    "# wgan.train(data_reg, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"OLS error: \", np.round(np.linalg.norm(betahat - beta), 4))\n",
    "# betahat_wgan = wgan.generator.trainable_variables[0].numpy()\n",
    "# print(\"wgan error: \", np.round(np.linalg.norm(betahat_wgan - beta), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct test version of model with self defined layers\n",
    "# def build_model():\n",
    "#     a = tf.keras.Input(shape=(4,))\n",
    "#     out = LocationAdd(input_dim=4)(a+5)\n",
    "#     model = tf.keras.Model(inputs=a, outputs=out)\n",
    "#     return model\n",
    "# model = build_model()\n",
    "# model2 = build_model()\n",
    "# print(model.trainable_variables)\n",
    "# print(model2.trainable_variables)\n",
    "# model.compile(optimizer='rmsprop', loss=tf.keras.losses.MeanSquaredError())\n",
    "# model.fit(x=data,y=data, batch_size=1, epochs=100)\n",
    "# print(model.trainable_variables)\n",
    "# print(model2.trainable_variables)\n",
    "\n",
    "## tf.keras.layers.add can make variables not trainable, below is not correct\n",
    "# a = tf.keras.Input(shape=(4,))\n",
    "# b = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(4,)), trainable=True)\n",
    "# out = tf.keras.layers.add([a+5,b])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
