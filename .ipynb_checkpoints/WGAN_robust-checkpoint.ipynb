{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom-defined layers\n",
    "\n",
    "class LocationAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LocationAdd, self).__init__()\n",
    "        w_init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim,)), trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.add(inputs, self.w)\n",
    "    \n",
    "class RegressionAdd(layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionAdd, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        w_init = tf.keras.initializers.GlorotNormal()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim-1,)), trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_X, input_z = tf.split(inputs, [self.input_dim-1, 1], axis=1)\n",
    "        return tf.concat([input_X, tf.add(tf.reshape(tf.linalg.matvec(input_X, self.w),[-1,1]),input_z)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom-defined constraints\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "class Constraint(object):\n",
    "    def __call__(self, w):\n",
    "        return w\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "class Max1Norm(Constraint):\n",
    "    \"\"\"1-Norm weight constraint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_value=2, axis=0):\n",
    "        self.max_value = max_value\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, w):\n",
    "        norms = math_ops.reduce_sum(math_ops.abs(w), axis=self.axis, keepdims=True)\n",
    "        desired = K.clip(norms, 0, self.max_value)\n",
    "        return w * (desired / (K.epsilon() + norms))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'max_value': self.max_value, 'axis': self.axis}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WganError(tf.keras.losses.Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        #y_pred = ops.convert_to_tensor(y_pred)\n",
    "        #y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "        return K.mean(y_pred - y_true, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN:\n",
    "    \n",
    "    ''' A static model, with fixed input size.\n",
    "        Model should not be defined in train(), so it should not depend on dataset dimension.\n",
    "        Model API has an advantage that it can save weights between different calls of train.\n",
    "        Instead of using tf.Session() as before, where only one training can happen, next will refresh,\n",
    "        using Model() API avoids this, it provides a model which saves weights outside tf.Session()!\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, dim_x, target):\n",
    "        self.dim_x = dim_x\n",
    "        self.generator = self.generator_model(dim_x, target)\n",
    "        self.discriminator = self.discriminator_model(dim_x)\n",
    "\n",
    "    \n",
    "    def generator_model(self, dim, target):\n",
    "        if target == \"location\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = LocationAdd(dim)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "        elif target == \"cov-matrix\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = layers.Dense(units=dim, use_bias=False)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "        elif target == \"regression\":\n",
    "            inputs = tf.keras.Input(shape=(dim,))\n",
    "            out = RegressionAdd(dim)(inputs)\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "            return model\n",
    "    \n",
    "    def discriminator_model(self, dim):        \n",
    "        inputs = tf.keras.Input(shape=(dim,))\n",
    "        dense1 = layers.Dense(units=2*dim, activation=tf.keras.activations.sigmoid, \n",
    "                              kernel_constraint=tf.keras.constraints.MaxNorm(max_value=1, axis=0))(inputs)\n",
    "        dense2 = layers.Dense(units=4*dim, activation=tf.keras.activations.relu, \n",
    "                              kernel_constraint=tf.keras.constraints.MaxNorm(max_value=1, axis=0))(dense1)\n",
    "        out = layers.Dense(units=1, activation=None, \n",
    "                           kernel_constraint=Max1Norm(max_value=1,axis=0))(dense2)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def discriminator_loss(real_output, fake_output):\n",
    "        #cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        #real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        #fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        #total_loss = real_loss + fake_loss\n",
    "        total_loss = WganError()(real_output, fake_output)\n",
    "        return total_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def generator_loss(fake_output):\n",
    "        # cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        # loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        loss = WganError()(fake_output, tf.zeros_like(fake_output))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def train(self, dataset, epochs, batch_size, step_size):\n",
    "        self.generator_optimizer = tf.keras.optimizers.RMSprop(step_size)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.RMSprop(step_size)\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            for i in range(dataset.shape[0]//batch_size):\n",
    "                noise = tf.random.normal([batch_size, self.dim_x])\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    generated = self.generator(noise, training=True)\n",
    "                    real_output = self.discriminator(dataset[i*batch_size:(i+1)*batch_size], training=True)\n",
    "                    fake_output = self.discriminator(generated, training=True)\n",
    "\n",
    "                    gen_loss = WGAN.generator_loss(fake_output)\n",
    "                    disc_loss = WGAN.discriminator_loss(real_output, fake_output)\n",
    "\n",
    "                    gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                    gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                    self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                    self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "    \n",
    "            print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "            A = self.generator.trainable_variables[0].numpy()\n",
    "            # print(np.linalg.norm(self.discriminator.trainable_variables[0].numpy(), ord=1, axis=0))\n",
    "            # print(np.matmul(A, A.T))   ## for cov-matrix\n",
    "            print(A)  ## for location estimation and regression\n",
    "            print(\"generator loss:\", gen_loss.numpy(), \"discriminator loss: \", disc_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance matrix estimation\n",
    "\n",
    "https://stackoverflow.com/questions/56201185/how-to-find-a-variable-by-name-in-tensorflow2-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample covariance: \n",
      " [[ 1.06207285  0.03006412  0.00372015 -0.04736984]\n",
      " [ 0.03006412  1.01144075 -0.06582223  0.00390109]\n",
      " [ 0.00372015 -0.06582223  1.00023798 -0.01642981]\n",
      " [-0.04736984  0.00390109 -0.01642981  0.96230879]]\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "p = 4\n",
    "\n",
    "data = np.random.normal(size=(N,p)).astype(np.float32) ## change to float32 for tensorflow\n",
    "print(\"sample covariance: \\n\", np.cov(data.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 8.711712121963501 sec\n",
      "[[ 0.9999624  -0.01137087  0.29432845  0.07042147]\n",
      " [-0.01137087  0.4587177   0.24475011  0.3217195 ]\n",
      " [ 0.29432845  0.24475011  1.0532123  -0.68895334]\n",
      " [ 0.07042147  0.3217195  -0.68895334  1.2594512 ]]\n",
      "generator loss: 0.006464634 discriminator loss:  -0.015455792\n",
      "Time for epoch 2 is 8.898500204086304 sec\n",
      "[[ 1.1726494  -0.06395453  0.2813566  -0.0968382 ]\n",
      " [-0.06395453  0.8004384   0.53677464  0.5472659 ]\n",
      " [ 0.2813566   0.53677464  1.0877877  -0.04575237]\n",
      " [-0.0968382   0.5472659  -0.04575237  1.1446836 ]]\n",
      "generator loss: -0.06882776 discriminator loss:  -0.077590466\n",
      "Time for epoch 3 is 9.164647102355957 sec\n",
      "[[ 1.23648     0.29594547  0.08317912 -0.28725505]\n",
      " [ 0.29594547  1.2908907  -0.09132874 -0.06942075]\n",
      " [ 0.08317912 -0.09132874  1.3612378   0.3130958 ]\n",
      " [-0.28725505 -0.06942075  0.3130958   1.5620112 ]]\n",
      "generator loss: 0.011176802 discriminator loss:  -0.016457537\n",
      "Time for epoch 4 is 10.340165138244629 sec\n",
      "[[ 1.1685554   0.21455106  0.1958428   0.03975868]\n",
      " [ 0.21455106  1.0198553  -0.02665538  0.23114237]\n",
      " [ 0.1958428  -0.02665538  0.80914515 -0.21160087]\n",
      " [ 0.03975868  0.23114237 -0.21160087  0.90279585]]\n",
      "generator loss: 0.11129363 discriminator loss:  -0.0022987835\n",
      "Time for epoch 5 is 9.047795057296753 sec\n",
      "[[ 1.2003007   0.21888278  0.01343249  0.04698551]\n",
      " [ 0.21888278  1.077269   -0.27898756  0.16479963]\n",
      " [ 0.01343249 -0.27898756  1.1021527  -0.13078989]\n",
      " [ 0.04698551  0.16479963 -0.13078989  1.0272775 ]]\n",
      "generator loss: 0.20171589 discriminator loss:  0.015499555\n",
      "Time for epoch 6 is 9.344044208526611 sec\n",
      "[[ 1.0262153   0.02127214  0.16894183  0.14428876]\n",
      " [ 0.02127214  0.9341062  -0.31165558  0.15003093]\n",
      " [ 0.16894183 -0.31165558  1.1635007  -0.2554771 ]\n",
      " [ 0.14428876  0.15003093 -0.2554771   0.97098386]]\n",
      "generator loss: 0.18861046 discriminator loss:  -0.010423346\n",
      "Time for epoch 7 is 8.947640895843506 sec\n",
      "[[ 9.6773821e-01  6.8286397e-02  1.6219319e-01  4.7912166e-02]\n",
      " [ 6.8286397e-02  9.8052132e-01 -2.9762477e-01 -9.1083325e-04]\n",
      " [ 1.6219319e-01 -2.9762477e-01  1.1749209e+00 -7.5363830e-02]\n",
      " [ 4.7912166e-02 -9.1083325e-04 -7.5363830e-02  1.2425677e+00]]\n",
      "generator loss: 0.10137416 discriminator loss:  -0.02143432\n",
      "Time for epoch 8 is 9.228492021560669 sec\n",
      "[[ 0.9297994   0.06009535  0.21735734 -0.00254293]\n",
      " [ 0.06009535  0.9334419  -0.24679296 -0.00128545]\n",
      " [ 0.21735734 -0.24679296  1.060394   -0.07008092]\n",
      " [-0.00254293 -0.00128545 -0.07008092  1.2685741 ]]\n",
      "generator loss: 0.19899711 discriminator loss:  -0.022334628\n",
      "Time for epoch 9 is 8.952221155166626 sec\n",
      "[[ 0.95226943  0.04592977  0.22749056  0.01293643]\n",
      " [ 0.04592977  0.81843823 -0.06281433  0.14146814]\n",
      " [ 0.22749056 -0.06281433  0.88188887 -0.17157869]\n",
      " [ 0.01293643  0.14146814 -0.17157869  1.1480584 ]]\n",
      "generator loss: 0.17830941 discriminator loss:  -0.002988657\n",
      "Time for epoch 10 is 8.674150943756104 sec\n",
      "[[ 1.0695192   0.1884877   0.06621901 -0.19905594]\n",
      " [ 0.1884877   0.90807176 -0.26475635  0.03207929]\n",
      " [ 0.06621901 -0.26475635  1.0236096   0.05752861]\n",
      " [-0.19905594  0.03207929  0.05752861  1.3412088 ]]\n",
      "generator loss: 0.09615801 discriminator loss:  0.10636322\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "step_size = 0.01\n",
    "\n",
    "wgan = WGAN(dim_x=p, target=\"cov-matrix\")\n",
    "wgan.train(data, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(data, epochs=10, batch_size=32, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean: \n",
      " [1.085083  1.848611  2.9304116 3.8409376]\n",
      "noisy sample mean: \n",
      " [0.97268575 1.6706607  2.568898   3.3398514 ]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "p = 4\n",
    "theta = np.array([1,2,3,4])\n",
    "\n",
    "data = np.random.normal(size=(N, p)) + theta\n",
    "data = data.astype(np.float32)\n",
    "print(\"sample mean: \\n\", np.mean(data, axis=0))\n",
    "\n",
    "z = np.random.binomial(n=1,p=0.2,size=(N,1))\n",
    "# noise = np.random.standard_cauchy(size=(N,p))\n",
    "# noise = np.random.normal(2,size=(N,p))\n",
    "# noise = np.random.normal(0.5, size=(N,p))\n",
    "# A = np.random.uniform(size=(p,p))\n",
    "# noise = np.random.normal(size=(N,p)) @ A\n",
    "noise = np.random.gumbel(size=(N,p))\n",
    "data_perturbed = data * (1-z) + noise * z\n",
    "data_perturbed = data_perturbed.astype(np.float32)\n",
    "print(\"noisy sample mean: \\n\", np.mean(data_perturbed, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 28.74838399887085 sec\n",
      "[0.21047485 0.67292506 1.3881041  1.0307283 ]\n",
      "generator loss: 0.24857643 discriminator loss:  -0.6197872\n",
      "Time for epoch 2 is 30.155303239822388 sec\n",
      "[0.73737204 0.96448165 1.4212497  1.8233352 ]\n",
      "generator loss: 0.19159165 discriminator loss:  -0.45163202\n",
      "Time for epoch 3 is 24.991045713424683 sec\n",
      "[0.7815021 1.4306906 2.2227762 2.5838559]\n",
      "generator loss: 0.13382448 discriminator loss:  -0.22719237\n",
      "Time for epoch 4 is 24.098383903503418 sec\n",
      "[0.9397373 1.7474004 2.8358245 3.354781 ]\n",
      "generator loss: 0.12292438 discriminator loss:  -0.103685796\n",
      "Time for epoch 5 is 23.920121669769287 sec\n",
      "[0.55565476 1.6406938  2.337537   3.4468472 ]\n",
      "generator loss: -0.34470317 discriminator loss:  -0.18769215\n",
      "Time for epoch 6 is 23.45095705986023 sec\n",
      "[0.7737611 1.5590043 2.340589  3.583774 ]\n",
      "generator loss: -0.16158211 discriminator loss:  -0.23214094\n",
      "Time for epoch 7 is 24.289983987808228 sec\n",
      "[0.86226773 1.5869552  2.3822947  3.654326  ]\n",
      "generator loss: -0.12482942 discriminator loss:  -0.23997809\n",
      "Time for epoch 8 is 23.797631978988647 sec\n",
      "[0.86782914 1.5663573  2.360814   3.6095715 ]\n",
      "generator loss: -0.13630405 discriminator loss:  -0.22827503\n",
      "Time for epoch 9 is 23.452435970306396 sec\n",
      "[0.8649972 1.5802404 2.4126608 3.5858648]\n",
      "generator loss: -0.11577783 discriminator loss:  -0.24277025\n",
      "Time for epoch 10 is 23.36538529396057 sec\n",
      "[0.8817321 1.5784011 2.4458    3.5315652]\n",
      "generator loss: -0.10756348 discriminator loss:  -0.26197398\n",
      "Time for epoch 11 is 23.840718746185303 sec\n",
      "[0.79415745 1.5809246  2.454658   3.4524643 ]\n",
      "generator loss: -0.10663399 discriminator loss:  -0.25440097\n",
      "Time for epoch 12 is 25.003794193267822 sec\n",
      "[0.8355877 1.6218011 2.4993443 3.4086232]\n",
      "generator loss: -0.10240506 discriminator loss:  -0.2630721\n",
      "Time for epoch 13 is 23.640526056289673 sec\n",
      "[0.88303643 1.6024634  2.510953   3.3782032 ]\n",
      "generator loss: -0.14846028 discriminator loss:  -0.21866094\n",
      "Time for epoch 14 is 23.367594003677368 sec\n",
      "[0.91203237 1.6106527  2.5408866  3.4107594 ]\n",
      "generator loss: -0.100897215 discriminator loss:  -0.24760675\n",
      "Time for epoch 15 is 22.974321126937866 sec\n",
      "[0.83043236 1.6249764  2.4962761  3.4040666 ]\n",
      "generator loss: -0.109613836 discriminator loss:  -0.23950814\n",
      "Time for epoch 16 is 22.588043928146362 sec\n",
      "[0.83626276 1.6517532  2.5088997  3.4105263 ]\n",
      "generator loss: -0.12499272 discriminator loss:  -0.2268087\n",
      "Time for epoch 17 is 23.52182126045227 sec\n",
      "[0.85249543 1.6635875  2.550377   3.4491053 ]\n",
      "generator loss: -0.12437155 discriminator loss:  -0.2354886\n",
      "Time for epoch 18 is 22.64361333847046 sec\n",
      "[0.90749294 1.6912012  2.5310576  3.4760678 ]\n",
      "generator loss: -0.10943319 discriminator loss:  -0.25413418\n",
      "Time for epoch 19 is 22.48934006690979 sec\n",
      "[0.8716619 1.6891125 2.5493553 3.4733005]\n",
      "generator loss: -0.12904799 discriminator loss:  -0.23623395\n",
      "Time for epoch 20 is 22.51092004776001 sec\n",
      "[0.8959881 1.6358812 2.580894  3.4359646]\n",
      "generator loss: -0.10551956 discriminator loss:  -0.25496805\n",
      "Time for epoch 21 is 22.570010900497437 sec\n",
      "[0.91135406 1.7066551  2.6185086  3.478908  ]\n",
      "generator loss: -0.089957476 discriminator loss:  -0.25730437\n",
      "Time for epoch 22 is 22.967835903167725 sec\n",
      "[0.8346164 1.7336836 2.5761173 3.4783585]\n",
      "generator loss: -0.09103252 discriminator loss:  -0.2732297\n",
      "Time for epoch 23 is 23.233075380325317 sec\n",
      "[0.9031865 1.6729131 2.5195572 3.4358413]\n",
      "generator loss: -0.109480605 discriminator loss:  -0.2531187\n",
      "Time for epoch 24 is 23.099834203720093 sec\n",
      "[0.87447375 1.7192513  2.5849204  3.487598  ]\n",
      "generator loss: -0.109951645 discriminator loss:  -0.23328385\n",
      "Time for epoch 25 is 21.92293381690979 sec\n",
      "[0.8832708 1.6904284 2.6102974 3.448841 ]\n",
      "generator loss: -0.087990925 discriminator loss:  -0.26538193\n",
      "Time for epoch 26 is 27.333654165267944 sec\n",
      "[0.83637404 1.6912903  2.6124463  3.434252  ]\n",
      "generator loss: -0.10354129 discriminator loss:  -0.24232145\n",
      "Time for epoch 27 is 23.24678325653076 sec\n",
      "[0.8659592 1.7579942 2.5945435 3.4606786]\n",
      "generator loss: -0.104420714 discriminator loss:  -0.24744\n",
      "Time for epoch 28 is 22.58438992500305 sec\n",
      "[0.89575577 1.7191824  2.6193628  3.5005202 ]\n",
      "generator loss: -0.08904968 discriminator loss:  -0.25937855\n",
      "Time for epoch 29 is 21.91042995452881 sec\n",
      "[0.8853758 1.7130232 2.6498964 3.5628748]\n",
      "generator loss: -0.10801162 discriminator loss:  -0.230901\n",
      "Time for epoch 30 is 21.54380702972412 sec\n",
      "[0.9569704 1.7353289 2.5672114 3.503261 ]\n",
      "generator loss: -0.102968626 discriminator loss:  -0.24537711\n",
      "Time for epoch 31 is 21.871958017349243 sec\n",
      "[0.8254263 1.7502817 2.5770473 3.4949207]\n",
      "generator loss: -0.10229869 discriminator loss:  -0.2504159\n",
      "Time for epoch 32 is 21.786919116973877 sec\n",
      "[0.97841823 1.7161657  2.649858   3.5386245 ]\n",
      "generator loss: -0.11799911 discriminator loss:  -0.23188296\n",
      "Time for epoch 33 is 22.26356816291809 sec\n",
      "[0.92635536 1.6888163  2.617026   3.4690878 ]\n",
      "generator loss: -0.09478854 discriminator loss:  -0.24709135\n",
      "Time for epoch 34 is 22.007106065750122 sec\n",
      "[0.93408966 1.7460688  2.6188266  3.5267513 ]\n",
      "generator loss: -0.09324773 discriminator loss:  -0.24339844\n",
      "Time for epoch 35 is 21.918891191482544 sec\n",
      "[0.859815 1.75554  2.606239 3.520974]\n",
      "generator loss: -0.07263026 discriminator loss:  -0.27709204\n",
      "Time for epoch 36 is 24.373663902282715 sec\n",
      "[0.9755073 1.8072563 2.646879  3.502233 ]\n",
      "generator loss: -0.11945042 discriminator loss:  -0.23480998\n",
      "Time for epoch 37 is 24.678306818008423 sec\n",
      "[0.9478036 1.7746544 2.6457791 3.510216 ]\n",
      "generator loss: -0.0801069 discriminator loss:  -0.2699495\n",
      "Time for epoch 38 is 23.313475131988525 sec\n",
      "[0.91604346 1.718218   2.6591444  3.5441546 ]\n",
      "generator loss: -0.06950161 discriminator loss:  -0.26443702\n",
      "Time for epoch 39 is 23.27341318130493 sec\n",
      "[0.89347357 1.6495144  2.5882792  3.4625936 ]\n",
      "generator loss: -0.098886415 discriminator loss:  -0.25223848\n",
      "Time for epoch 40 is 22.463830947875977 sec\n",
      "[0.90298986 1.7662297  2.6368666  3.4796665 ]\n",
      "generator loss: -0.0855986 discriminator loss:  -0.2579152\n",
      "Time for epoch 41 is 22.775173902511597 sec\n",
      "[0.9592188 1.753095  2.6488862 3.47421  ]\n",
      "generator loss: -0.10334772 discriminator loss:  -0.24347371\n",
      "Time for epoch 42 is 22.526413202285767 sec\n",
      "[0.9412377 1.7679263 2.6454072 3.5053148]\n",
      "generator loss: -0.090633586 discriminator loss:  -0.25986642\n",
      "Time for epoch 43 is 22.463737964630127 sec\n",
      "[0.91760576 1.7269256  2.6434288  3.5157552 ]\n",
      "generator loss: -0.10855193 discriminator loss:  -0.24297008\n",
      "Time for epoch 44 is 23.121209144592285 sec\n",
      "[0.8721981 1.7703993 2.6383014 3.5434246]\n",
      "generator loss: -0.07004863 discriminator loss:  -0.27040958\n",
      "Time for epoch 45 is 23.2810640335083 sec\n",
      "[0.95950925 1.7038081  2.6351795  3.5325308 ]\n",
      "generator loss: -0.11001535 discriminator loss:  -0.23663862\n",
      "Time for epoch 46 is 23.248292922973633 sec\n",
      "[0.89145505 1.7093209  2.586013   3.4411068 ]\n",
      "generator loss: -0.084195316 discriminator loss:  -0.26128924\n",
      "Time for epoch 47 is 22.36334800720215 sec\n",
      "[0.8407898 1.7971026 2.6562982 3.471218 ]\n",
      "generator loss: -0.09155568 discriminator loss:  -0.26735294\n",
      "Time for epoch 48 is 22.87760829925537 sec\n",
      "[0.93847907 1.6960541  2.629641   3.4729235 ]\n",
      "generator loss: -0.094320565 discriminator loss:  -0.2574696\n",
      "Time for epoch 49 is 23.768980979919434 sec\n",
      "[0.88646126 1.7238232  2.5791051  3.5097327 ]\n",
      "generator loss: -0.072555475 discriminator loss:  -0.27131048\n",
      "Time for epoch 50 is 26.116683959960938 sec\n",
      "[0.91199344 1.7281302  2.5693398  3.501783  ]\n",
      "generator loss: -0.088651165 discriminator loss:  -0.25843066\n",
      "Time for epoch 51 is 22.709176778793335 sec\n",
      "[0.9472164 1.7484612 2.659067  3.5006452]\n",
      "generator loss: -0.123237334 discriminator loss:  -0.2237415\n",
      "Time for epoch 52 is 22.481264114379883 sec\n",
      "[0.94057107 1.7199994  2.6487544  3.452913  ]\n",
      "generator loss: -0.086284414 discriminator loss:  -0.2575138\n",
      "Time for epoch 53 is 22.79970669746399 sec\n",
      "[0.89796495 1.7245325  2.6206043  3.4704976 ]\n",
      "generator loss: -0.08934904 discriminator loss:  -0.26284432\n",
      "Time for epoch 54 is 23.364656686782837 sec\n",
      "[0.9685213 1.7523121 2.6542013 3.5305917]\n",
      "generator loss: -0.08242832 discriminator loss:  -0.2613762\n",
      "Time for epoch 55 is 22.70860004425049 sec\n",
      "[0.839577  1.7379563 2.6382127 3.488273 ]\n",
      "generator loss: -0.07983913 discriminator loss:  -0.2583643\n",
      "Time for epoch 56 is 22.80387282371521 sec\n",
      "[0.9349827 1.7444296 2.6358285 3.4626722]\n",
      "generator loss: -0.10163658 discriminator loss:  -0.24638543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 57 is 22.517171144485474 sec\n",
      "[0.91895235 1.7662553  2.6716306  3.5053577 ]\n",
      "generator loss: -0.12530866 discriminator loss:  -0.22363658\n",
      "Time for epoch 58 is 22.352845191955566 sec\n",
      "[0.88844323 1.7615476  2.6376572  3.5127077 ]\n",
      "generator loss: -0.070527546 discriminator loss:  -0.28027764\n",
      "Time for epoch 59 is 22.756879091262817 sec\n",
      "[0.9861868 1.7215385 2.6505997 3.4953706]\n",
      "generator loss: -0.087481424 discriminator loss:  -0.25353926\n",
      "Time for epoch 60 is 22.8980610370636 sec\n",
      "[0.9345974 1.7293556 2.6621509 3.5124695]\n",
      "generator loss: -0.08346833 discriminator loss:  -0.24766788\n",
      "Time for epoch 61 is 22.59460973739624 sec\n",
      "[0.95406777 1.7405769  2.648832   3.5138578 ]\n",
      "generator loss: -0.10062018 discriminator loss:  -0.2518391\n",
      "Time for epoch 62 is 22.700992107391357 sec\n",
      "[0.9647227 1.7309546 2.6607928 3.4729002]\n",
      "generator loss: -0.11362153 discriminator loss:  -0.2361522\n",
      "Time for epoch 63 is 21.88555908203125 sec\n",
      "[0.85777   1.7608651 2.6544778 3.455934 ]\n",
      "generator loss: -0.08724575 discriminator loss:  -0.2567245\n",
      "Time for epoch 64 is 22.299854040145874 sec\n",
      "[0.95379514 1.7713464  2.631365   3.4700491 ]\n",
      "generator loss: -0.105110034 discriminator loss:  -0.23884374\n",
      "Time for epoch 65 is 21.723335027694702 sec\n",
      "[0.9250915 1.799312  2.6402047 3.5333147]\n",
      "generator loss: -0.085814 discriminator loss:  -0.2565693\n",
      "Time for epoch 66 is 22.629456996917725 sec\n",
      "[0.75399977 1.664231   2.5899527  3.491802  ]\n",
      "generator loss: -0.09273304 discriminator loss:  -0.25651354\n",
      "Time for epoch 67 is 22.16574215888977 sec\n",
      "[0.9156318 1.7452077 2.6435075 3.5209885]\n",
      "generator loss: -0.08826451 discriminator loss:  -0.25848097\n",
      "Time for epoch 68 is 21.869582176208496 sec\n",
      "[0.9503498 1.728257  2.637884  3.4889777]\n",
      "generator loss: -0.088480234 discriminator loss:  -0.26089326\n",
      "Time for epoch 69 is 21.685873985290527 sec\n",
      "[0.8960009 1.7637815 2.692354  3.5165925]\n",
      "generator loss: -0.08670382 discriminator loss:  -0.26162452\n",
      "Time for epoch 70 is 21.703195810317993 sec\n",
      "[0.94626164 1.7789968  2.6624656  3.5137105 ]\n",
      "generator loss: -0.08785111 discriminator loss:  -0.2642571\n",
      "Time for epoch 71 is 21.715049982070923 sec\n",
      "[0.8818165 1.7091999 2.5919845 3.465271 ]\n",
      "generator loss: -0.113691024 discriminator loss:  -0.2393102\n",
      "Time for epoch 72 is 22.219867944717407 sec\n",
      "[0.8678862 1.7505955 2.6289194 3.4727805]\n",
      "generator loss: -0.083645426 discriminator loss:  -0.2563535\n",
      "Time for epoch 73 is 24.664556980133057 sec\n",
      "[0.8915849 1.7053972 2.6380794 3.4819343]\n",
      "generator loss: -0.07779633 discriminator loss:  -0.26985943\n",
      "Time for epoch 74 is 23.84018898010254 sec\n",
      "[0.9173384 1.7483444 2.623009  3.4417918]\n",
      "generator loss: -0.09554202 discriminator loss:  -0.25269514\n",
      "Time for epoch 75 is 27.12360906600952 sec\n",
      "[0.88610035 1.8092288  2.6471078  3.4559104 ]\n",
      "generator loss: -0.091072366 discriminator loss:  -0.26018673\n",
      "Time for epoch 76 is 23.959010124206543 sec\n",
      "[0.8901617 1.7323056 2.6363285 3.506978 ]\n",
      "generator loss: -0.100933924 discriminator loss:  -0.24677275\n",
      "Time for epoch 77 is 25.89317560195923 sec\n",
      "[0.89733976 1.7124858  2.6001983  3.5128865 ]\n",
      "generator loss: -0.08306009 discriminator loss:  -0.25491315\n",
      "Time for epoch 78 is 25.918636083602905 sec\n",
      "[0.9692094 1.7464601 2.5935473 3.4457707]\n",
      "generator loss: -0.10394786 discriminator loss:  -0.25288156\n",
      "Time for epoch 79 is 22.35394811630249 sec\n",
      "[0.9529589 1.7269781 2.649733  3.4722152]\n",
      "generator loss: -0.09316829 discriminator loss:  -0.26062936\n",
      "Time for epoch 80 is 22.53679895401001 sec\n",
      "[0.87867755 1.7177948  2.6554759  3.494647  ]\n",
      "generator loss: -0.08719029 discriminator loss:  -0.263934\n",
      "Time for epoch 81 is 26.281222105026245 sec\n",
      "[0.9469738 1.7529831 2.6233287 3.5290658]\n",
      "generator loss: -0.09917836 discriminator loss:  -0.25025028\n",
      "Time for epoch 82 is 26.96147894859314 sec\n",
      "[0.9653189 1.7220064 2.6059334 3.5013714]\n",
      "generator loss: -0.0983664 discriminator loss:  -0.25113642\n",
      "Time for epoch 83 is 25.916280031204224 sec\n",
      "[0.89589334 1.7502918  2.6366706  3.5046654 ]\n",
      "generator loss: -0.06777641 discriminator loss:  -0.2783948\n",
      "Time for epoch 84 is 23.34429693222046 sec\n",
      "[0.8415168 1.7571781 2.5962253 3.456891 ]\n",
      "generator loss: -0.09044382 discriminator loss:  -0.2590893\n",
      "Time for epoch 85 is 24.179094791412354 sec\n",
      "[0.91693723 1.6948669  2.6057806  3.4340339 ]\n",
      "generator loss: -0.10039331 discriminator loss:  -0.25257066\n",
      "Time for epoch 86 is 25.62119722366333 sec\n",
      "[0.9421726 1.6977756 2.64576   3.4801884]\n",
      "generator loss: -0.08583888 discriminator loss:  -0.2579039\n",
      "Time for epoch 87 is 26.69055700302124 sec\n",
      "[0.87854064 1.772996   2.6829228  3.5347311 ]\n",
      "generator loss: -0.067092925 discriminator loss:  -0.2762436\n",
      "Time for epoch 88 is 26.7718288898468 sec\n",
      "[0.9362737 1.7475051 2.6463864 3.5038815]\n",
      "generator loss: -0.0959274 discriminator loss:  -0.24746248\n",
      "Time for epoch 89 is 22.677109003067017 sec\n",
      "[0.9168621 1.7497339 2.6256022 3.4881124]\n",
      "generator loss: -0.10765535 discriminator loss:  -0.23549214\n",
      "Time for epoch 90 is 24.307544231414795 sec\n",
      "[0.83871675 1.7504888  2.6064079  3.501946  ]\n",
      "generator loss: -0.094867855 discriminator loss:  -0.25255045\n",
      "Time for epoch 91 is 23.679139137268066 sec\n",
      "[0.90534306 1.7218649  2.6231432  3.49604   ]\n",
      "generator loss: -0.08659282 discriminator loss:  -0.2618882\n",
      "Time for epoch 92 is 24.301483154296875 sec\n",
      "[0.9514531 1.7564583 2.6554253 3.4845634]\n",
      "generator loss: -0.095102824 discriminator loss:  -0.25068718\n",
      "Time for epoch 93 is 25.37542223930359 sec\n",
      "[0.941233  1.7150359 2.6579573 3.4773073]\n",
      "generator loss: -0.0861859 discriminator loss:  -0.26959375\n",
      "Time for epoch 94 is 26.470279932022095 sec\n",
      "[0.85241014 1.7347393  2.625      3.4860914 ]\n",
      "generator loss: -0.08427266 discriminator loss:  -0.27030656\n",
      "Time for epoch 95 is 26.34541893005371 sec\n",
      "[0.91548055 1.7519251  2.643312   3.4864798 ]\n",
      "generator loss: -0.08556354 discriminator loss:  -0.2689436\n",
      "Time for epoch 96 is 28.629969120025635 sec\n",
      "[0.8783692 1.7151854 2.623188  3.4578757]\n",
      "generator loss: -0.09573655 discriminator loss:  -0.25322416\n",
      "Time for epoch 97 is 26.464208126068115 sec\n",
      "[0.8737116 1.7066245 2.5787563 3.4537122]\n",
      "generator loss: -0.11426674 discriminator loss:  -0.23397073\n",
      "Time for epoch 98 is 26.514472246170044 sec\n",
      "[0.84593105 1.7692329  2.6520977  3.4805036 ]\n",
      "generator loss: -0.08418682 discriminator loss:  -0.25729135\n",
      "Time for epoch 99 is 24.927114725112915 sec\n",
      "[0.9361808 1.727578  2.6542592 3.4684162]\n",
      "generator loss: -0.09768012 discriminator loss:  -0.24814482\n",
      "Time for epoch 100 is 26.695619106292725 sec\n",
      "[0.8794747 1.6843294 2.6203804 3.4765062]\n",
      "generator loss: -0.08751076 discriminator loss:  -0.26310614\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "step_size = 0.01\n",
    "\n",
    "wgan = WGAN(dim_x=p, target=\"location\")\n",
    "wgan.train(data_perturbed, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 0.9796490669250488 sec\n",
      "[0.77604896 1.5157262  2.1762435  3.2488031 ]\n",
      "generator loss: -0.3662386 discriminator loss:  -0.2911882\n",
      "Time for epoch 2 is 0.9468278884887695 sec\n",
      "[0.8036269 1.5173982 2.201513  3.273699 ]\n",
      "generator loss: -0.21841952 discriminator loss:  -0.3735035\n",
      "Time for epoch 3 is 0.9065437316894531 sec\n",
      "[0.825439  1.4986236 2.2198682 3.2916005]\n",
      "generator loss: -0.19563393 discriminator loss:  -0.39427704\n",
      "Time for epoch 4 is 0.9309597015380859 sec\n",
      "[0.84795   1.4758803 2.2386518 3.3100014]\n",
      "generator loss: -0.29642737 discriminator loss:  -0.2552811\n",
      "Time for epoch 5 is 0.9330430030822754 sec\n",
      "[0.8671304 1.4601793 2.2544427 3.3258483]\n",
      "generator loss: -0.17755479 discriminator loss:  -0.37688398\n",
      "Time for epoch 6 is 0.8796870708465576 sec\n",
      "[0.8862762 1.4557648 2.270294  3.3419034]\n",
      "generator loss: -0.2164856 discriminator loss:  -0.34871703\n",
      "Time for epoch 7 is 0.894524097442627 sec\n",
      "[0.9046401 1.4650825 2.285781  3.357752 ]\n",
      "generator loss: -0.2714462 discriminator loss:  -0.3023104\n",
      "Time for epoch 8 is 0.9022531509399414 sec\n",
      "[0.92131793 1.4816691  2.300552   3.3725486 ]\n",
      "generator loss: -0.2625289 discriminator loss:  -0.2860611\n",
      "Time for epoch 9 is 0.8610928058624268 sec\n",
      "[0.93773985 1.500995   2.3158567  3.387938  ]\n",
      "generator loss: -0.25008547 discriminator loss:  -0.27145407\n",
      "Time for epoch 10 is 0.8590097427368164 sec\n",
      "[0.9546168 1.518558  2.3319242 3.4038715]\n",
      "generator loss: -0.25444013 discriminator loss:  -0.204725\n",
      "Time for epoch 11 is 0.8606181144714355 sec\n",
      "[0.9687359 1.5343403 2.3449695 3.4165506]\n",
      "generator loss: -0.11357269 discriminator loss:  -0.34990835\n",
      "Time for epoch 12 is 0.8821439743041992 sec\n",
      "[0.98361903 1.5540165  2.358475   3.4300842 ]\n",
      "generator loss: -0.211102 discriminator loss:  -0.29114228\n",
      "Time for epoch 13 is 1.1058409214019775 sec\n",
      "[0.99946237 1.5774734  2.372639   3.444412  ]\n",
      "generator loss: -0.11881017 discriminator loss:  -0.39850733\n",
      "Time for epoch 14 is 0.9514980316162109 sec\n",
      "[1.0167214 1.6006069 2.3882382 3.4600024]\n",
      "generator loss: -0.17505771 discriminator loss:  -0.3333536\n",
      "Time for epoch 15 is 0.998568058013916 sec\n",
      "[1.0328703 1.6178344 2.4028535 3.4743161]\n",
      "generator loss: -0.089035705 discriminator loss:  -0.39699897\n",
      "Time for epoch 16 is 1.047922134399414 sec\n",
      "[1.0504744 1.6358075 2.4187171 3.4899254]\n",
      "generator loss: -0.253559 discriminator loss:  -0.22154531\n",
      "Time for epoch 17 is 1.1054909229278564 sec\n",
      "[1.0668596 1.6464397 2.4341185 3.5048923]\n",
      "generator loss: -0.12447185 discriminator loss:  -0.28496072\n",
      "Time for epoch 18 is 1.0637609958648682 sec\n",
      "[1.0805423 1.6586312 2.447497  3.518128 ]\n",
      "generator loss: -0.12665208 discriminator loss:  -0.30732614\n",
      "Time for epoch 19 is 1.0550918579101562 sec\n",
      "[1.0941014 1.6722311 2.4610913 3.5315297]\n",
      "generator loss: -0.10296677 discriminator loss:  -0.3149811\n",
      "Time for epoch 20 is 1.0668270587921143 sec\n",
      "[1.1095539 1.6906143 2.4764638 3.546652 ]\n",
      "generator loss: -0.21992138 discriminator loss:  -0.18391763\n",
      "Time for epoch 21 is 1.1350901126861572 sec\n",
      "[1.1224388 1.7063694 2.4893804 3.5591395]\n",
      "generator loss: -0.20644858 discriminator loss:  -0.21025097\n",
      "Time for epoch 22 is 0.9999113082885742 sec\n",
      "[1.1360538 1.7224424 2.5028627 3.572439 ]\n",
      "generator loss: -0.2565731 discriminator loss:  -0.18381718\n",
      "Time for epoch 23 is 1.1085870265960693 sec\n",
      "[1.1510928 1.7397282 2.517916  3.5874834]\n",
      "generator loss: -0.16276303 discriminator loss:  -0.22913373\n",
      "Time for epoch 24 is 0.9396331310272217 sec\n",
      "[1.1651999 1.7568073 2.5322764 3.6018298]\n",
      "generator loss: -0.12536612 discriminator loss:  -0.28283203\n",
      "Time for epoch 25 is 0.8817100524902344 sec\n",
      "[1.1806129 1.7716124 2.547318  3.6167655]\n",
      "generator loss: -0.25854558 discriminator loss:  -0.12404321\n",
      "Time for epoch 26 is 0.8873999118804932 sec\n",
      "[1.1943355 1.7835127 2.5604858 3.6297264]\n",
      "generator loss: -0.18885693 discriminator loss:  -0.19635671\n",
      "Time for epoch 27 is 1.1025710105895996 sec\n",
      "[1.2088956 1.7973188 2.5744002 3.6437511]\n",
      "generator loss: -0.26397872 discriminator loss:  -0.13087612\n",
      "Time for epoch 28 is 1.1534819602966309 sec\n",
      "[1.2220106 1.8098826 2.5869555 3.6565607]\n",
      "generator loss: -0.20779979 discriminator loss:  -0.18089125\n",
      "Time for epoch 29 is 1.234618902206421 sec\n",
      "[1.2358832 1.8255662 2.5999973 3.6700501]\n",
      "generator loss: -0.22084004 discriminator loss:  -0.21358177\n",
      "Time for epoch 30 is 1.0341169834136963 sec\n",
      "[1.2520117 1.845136  2.6154084 3.6860287]\n",
      "generator loss: -0.3147568 discriminator loss:  -0.12834664\n",
      "Time for epoch 31 is 1.1814720630645752 sec\n",
      "[1.2677163 1.8617073 2.6307557 3.701707 ]\n",
      "generator loss: -0.27433455 discriminator loss:  -0.10282959\n",
      "Time for epoch 32 is 1.24576997756958 sec\n",
      "[1.2788898 1.8743403 2.6426628 3.7137516]\n",
      "generator loss: -0.22184335 discriminator loss:  -0.14615603\n",
      "Time for epoch 33 is 0.9488570690155029 sec\n",
      "[1.2903247 1.8891025 2.6551952 3.726483 ]\n",
      "generator loss: -0.18975414 discriminator loss:  -0.17508605\n",
      "Time for epoch 34 is 0.9220170974731445 sec\n",
      "[1.3038801 1.9061723 2.6694725 3.7410681]\n",
      "generator loss: -0.23440076 discriminator loss:  -0.16754168\n",
      "Time for epoch 35 is 0.9125139713287354 sec\n",
      "[1.3171997 1.9225521 2.6841362 3.7561724]\n",
      "generator loss: -0.29117793 discriminator loss:  -0.085435025\n",
      "Time for epoch 36 is 0.9021399021148682 sec\n",
      "[1.3298697 1.93869   2.6983116 3.7706485]\n",
      "generator loss: -0.3195561 discriminator loss:  -0.034235884\n",
      "Time for epoch 37 is 0.9343118667602539 sec\n",
      "[1.3394024 1.9499602 2.7094812 3.7817369]\n",
      "generator loss: -0.25353804 discriminator loss:  -0.085731104\n",
      "Time for epoch 38 is 0.9077918529510498 sec\n",
      "[1.3449696 1.9563446 2.715915  3.788142 ]\n",
      "generator loss: -0.24078792 discriminator loss:  -0.11530279\n",
      "Time for epoch 39 is 0.9043161869049072 sec\n",
      "[1.3588674 1.9727033 2.7301445 3.8029149]\n",
      "generator loss: -0.28201443 discriminator loss:  -0.10603866\n",
      "Time for epoch 40 is 0.8907546997070312 sec\n",
      "[1.3700542 1.984899  2.7418897 3.814797 ]\n",
      "generator loss: -0.26925805 discriminator loss:  -0.070758514\n",
      "Time for epoch 41 is 0.9102907180786133 sec\n",
      "[1.3764944 1.9918269 2.74879   3.8217213]\n",
      "generator loss: -0.2500314 discriminator loss:  -0.11516179\n",
      "Time for epoch 42 is 0.9374489784240723 sec\n",
      "[1.3886365 2.0062778 2.761232  3.8344975]\n",
      "generator loss: -0.26451153 discriminator loss:  -0.10676834\n",
      "Time for epoch 43 is 1.0180590152740479 sec\n",
      "[1.3970119 2.0160685 2.7701793 3.8435366]\n",
      "generator loss: -0.3053258 discriminator loss:  -0.072787486\n",
      "Time for epoch 44 is 0.9425859451293945 sec\n",
      "[1.4019868 2.0215054 2.7755883 3.8489418]\n",
      "generator loss: -0.29930001 discriminator loss:  -0.06522179\n",
      "Time for epoch 45 is 0.9181811809539795 sec\n",
      "[1.4073371 2.02732   2.780996  3.8543813]\n",
      "generator loss: -0.3197083 discriminator loss:  -0.06088598\n",
      "Time for epoch 46 is 0.901496171951294 sec\n",
      "[1.4199384 2.0428677 2.7924905 3.8665164]\n",
      "generator loss: -0.33208612 discriminator loss:  -0.077351354\n",
      "Time for epoch 47 is 0.9452841281890869 sec\n",
      "[1.4317511 2.056265  2.8034885 3.878034 ]\n",
      "generator loss: -0.30490345 discriminator loss:  -0.079053186\n",
      "Time for epoch 48 is 1.0776100158691406 sec\n",
      "[1.4369322 2.0612302 2.8086846 3.883205 ]\n",
      "generator loss: -0.27793008 discriminator loss:  -0.08417052\n",
      "Time for epoch 49 is 1.0958290100097656 sec\n",
      "[1.4447849 2.0689921 2.8162193 3.8909307]\n",
      "generator loss: -0.28713122 discriminator loss:  -0.08100538\n",
      "Time for epoch 50 is 1.3931479454040527 sec\n",
      "[1.4507514 2.0742528 2.8221405 3.8967638]\n",
      "generator loss: -0.2884305 discriminator loss:  -0.07076805\n"
     ]
    }
   ],
   "source": [
    "wgan.train(data_perturbed, epochs=epochs//2, batch_size=batch_size, step_size=step_size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.02552350725706\n",
      "0.5323310450902631\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(np.mean(data_perturbed, axis=0)-theta)**2)\n",
    "print(np.linalg.norm(wgan.generator.trainable_variables[0].numpy()-theta)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "p = 4\n",
    "sigma = 1\n",
    "beta = np.array([1,2,3,4], dtype=np.float32)\n",
    "\n",
    "data_X = np.random.normal(size=(N,p)).astype(np.float32)\n",
    "data_y = data_X @ beta + np.random.normal(scale=sigma, size=(N,)).astype(np.float32)\n",
    "data_y = data_y.reshape([-1,1])\n",
    "data_reg = np.concatenate([data_X, data_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least square estimate: \n",
      " [[0.918088 ]\n",
      " [1.9790355]\n",
      " [3.0042918]\n",
      " [3.978514 ]]\n"
     ]
    }
   ],
   "source": [
    "betahat = np.linalg.solve(data_X.T@data_X, (data_X.T@data_y))\n",
    "print(\"least square estimate: \\n\", betahat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 1 is 9.458981037139893 sec\n",
      "[ 0.8137293   0.45727253 -1.116679   -0.67006314]\n",
      "generator loss: -0.05943303 discriminator loss:  -0.22450735\n",
      "Time for epoch 2 is 9.441058874130249 sec\n",
      "[ 1.0455842  0.7334564 -1.3095939 -0.5707018]\n",
      "generator loss: -0.011014687 discriminator loss:  -0.2832605\n",
      "Time for epoch 3 is 9.305871963500977 sec\n",
      "[ 1.2688947   0.9833873  -1.432649   -0.35507995]\n",
      "generator loss: 0.07638909 discriminator loss:  -0.2896044\n",
      "Time for epoch 4 is 9.490269899368286 sec\n",
      "[ 1.5105995   1.2216096  -1.4756104  -0.10068965]\n",
      "generator loss: 0.15273888 discriminator loss:  -0.38662213\n",
      "Time for epoch 5 is 9.741095304489136 sec\n",
      "[ 1.7713228   1.4890993  -1.4523885   0.11344511]\n",
      "generator loss: 0.18510675 discriminator loss:  -0.4062869\n",
      "Time for epoch 6 is 10.159914016723633 sec\n",
      "[ 2.0671592   1.7392192  -1.3528737   0.36751267]\n",
      "generator loss: 0.2995221 discriminator loss:  -0.43001193\n",
      "Time for epoch 7 is 9.508867979049683 sec\n",
      "[ 2.3325555  2.0300498 -1.1113856  0.6464563]\n",
      "generator loss: 0.336553 discriminator loss:  -0.40458256\n",
      "Time for epoch 8 is 9.365824937820435 sec\n",
      "[ 2.5980563  2.3097155 -0.8355042  0.8863811]\n",
      "generator loss: 0.3772732 discriminator loss:  -0.40459812\n",
      "Time for epoch 9 is 9.42086386680603 sec\n",
      "[ 2.8529198   2.5593927  -0.57522166  1.173721  ]\n",
      "generator loss: 0.39184013 discriminator loss:  -0.38007224\n",
      "Time for epoch 10 is 10.104347944259644 sec\n",
      "[ 3.0969856   2.7749066  -0.29494327  1.4661894 ]\n",
      "generator loss: 0.44572484 discriminator loss:  -0.40847996\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "step_size = 0.01\n",
    "\n",
    "wgan = WGAN(dim_x=p+1, target=\"regression\")\n",
    "wgan.train(data_reg, epochs=epochs, batch_size=batch_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan.train(data, epochs=10, batch_size=32, step_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct test version of model with self defined layers\n",
    "# def build_model():\n",
    "#     a = tf.keras.Input(shape=(4,))\n",
    "#     out = LocationAdd(input_dim=4)(a+5)\n",
    "#     model = tf.keras.Model(inputs=a, outputs=out)\n",
    "#     return model\n",
    "# model = build_model()\n",
    "# model2 = build_model()\n",
    "# print(model.trainable_variables)\n",
    "# print(model2.trainable_variables)\n",
    "# model.compile(optimizer='rmsprop', loss=tf.keras.losses.MeanSquaredError())\n",
    "# model.fit(x=data,y=data, batch_size=1, epochs=100)\n",
    "# print(model.trainable_variables)\n",
    "# print(model2.trainable_variables)\n",
    "\n",
    "## tf.keras.layers.add can make variables not trainable, below is not correct\n",
    "# a = tf.keras.Input(shape=(4,))\n",
    "# b = tf.Variable(initial_value=tf.random_normal_initializer()(shape=(4,)), trainable=True)\n",
    "# out = tf.keras.layers.add([a+5,b])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
